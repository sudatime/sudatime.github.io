<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Elasticsearch的安装</title>
    <url>/essay/install-elasticsearch.html</url>
    <content><![CDATA[<h1 id="docker安装elasticsearch"><a href="#docker安装elasticsearch" class="headerlink" title="docker安装elasticsearch"></a>docker安装elasticsearch</h1><p>详细介绍了docker下安装elasticsearch、kibana以及ik分词器的步骤</p>
<p>注意：要保持es、kibana、ik分词器版本一致</p>
<a id="more"></a>

<h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><p>centos7:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">cat /etc/os-release </span><br><span class="line"></span><br><span class="line">NAME=<span class="string">&quot;CentOS Linux&quot;</span></span><br><span class="line">VERSION=<span class="string">&quot;7 (Core)&quot;</span></span><br><span class="line">ID=<span class="string">&quot;centos&quot;</span></span><br><span class="line">ID_LIKE=<span class="string">&quot;rhel fedora&quot;</span></span><br><span class="line">VERSION_ID=<span class="string">&quot;7&quot;</span></span><br><span class="line">PRETTY_NAME=<span class="string">&quot;CentOS Linux 7 (Core)&quot;</span></span><br><span class="line">ANSI_COLOR=<span class="string">&quot;0;31&quot;</span></span><br><span class="line">CPE_NAME=<span class="string">&quot;cpe:/o:centos:centos:7&quot;</span></span><br><span class="line">HOME_URL=<span class="string">&quot;https://www.centos.org/&quot;</span></span><br><span class="line">BUG_REPORT_URL=<span class="string">&quot;https://bugs.centos.org/&quot;</span></span><br><span class="line"></span><br><span class="line">CENTOS_MANTISBT_PROJECT=<span class="string">&quot;CentOS-7&quot;</span></span><br><span class="line">CENTOS_MANTISBT_PROJECT_VERSION=<span class="string">&quot;7&quot;</span></span><br><span class="line">REDHAT_SUPPORT_PRODUCT=<span class="string">&quot;centos&quot;</span></span><br><span class="line">REDHAT_SUPPORT_PRODUCT_VERSION=<span class="string">&quot;7&quot;</span></span><br></pre></td></tr></table></figure>
<p>docker版本:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker -v</span><br><span class="line">Docker version 20.10.3, build 48d30b5</span><br></pre></td></tr></table></figure>
<p>elasticsearch版本:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">elasticsearch   7.10.1</span><br></pre></td></tr></table></figure>
<p>kibana版本:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kibana          7.10.1</span><br></pre></td></tr></table></figure>
<h2 id="下载镜像"><a href="#下载镜像" class="headerlink" title="下载镜像"></a>下载镜像</h2><ul>
<li>elasticsearch</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker pull elasticsearch:7.10.1</span><br></pre></td></tr></table></figure>
<ul>
<li>kibana</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker pull kibana:7.10.1</span><br></pre></td></tr></table></figure>
<h2 id="方式一："><a href="#方式一：" class="headerlink" title="方式一："></a>方式一：</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># elk: 自定义网络名称 需要和下面的相同</span></span><br><span class="line">docker network create elk</span><br></pre></td></tr></table></figure>
<h3 id="elasticsearch安装："><a href="#elasticsearch安装：" class="headerlink" title="elasticsearch安装："></a>elasticsearch安装：</h3><ul>
<li>创建绑定目录</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 配置目录</span></span><br><span class="line">mkdir -p /usr/local/developer/elasticsearch/config</span><br><span class="line"><span class="meta">#</span><span class="bash"> 数据目录</span></span><br><span class="line">mkdir -p /usr/local/developer/elasticsearch/data</span><br><span class="line"><span class="meta">#</span><span class="bash"> 插件目录</span></span><br><span class="line">mkdir -p /usr/local/developer/elasticsearch/plugins</span><br></pre></td></tr></table></figure>
<ul>
<li>配置文件 elasticsearch.yml</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vim /usr/local/developer/elasticsearch/config/elasticsearch.yml</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> ======================== Elasticsearch Configuration =========================</span></span><br><span class="line"><span class="meta">#</span></span><br><span class="line"><span class="bash"><span class="comment"># <span class="doctag">NOTE:</span> Elasticsearch comes with reasonable defaults for most settings.</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Before you <span class="built_in">set</span> out to tweak and tune the configuration, make sure you</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> understand what are you trying to accomplish and the consequences.</span></span><br><span class="line"><span class="meta">#</span></span><br><span class="line"><span class="bash"><span class="comment"># The primary way of configuring a node is via this file. This template lists</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> the most important settings you may want to configure <span class="keyword">for</span> a production cluster.</span></span><br><span class="line"><span class="meta">#</span></span><br><span class="line"><span class="bash"><span class="comment"># Please see the documentation for further information on configuration options:</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> &lt;http://www.elastic.co/guide/en/elasticsearch/reference/current/setup-configuration.html&gt;</span></span><br><span class="line"><span class="meta">#</span></span><br><span class="line"><span class="bash"><span class="comment"># ---------------------------------- Cluster -----------------------------------</span></span></span><br><span class="line"><span class="meta">#</span></span><br><span class="line"><span class="bash"><span class="comment"># Use a descriptive name for your cluster:</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 集群名称，默认是elasticsearch</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> cluster.name: my-application</span></span><br><span class="line"><span class="meta">#</span></span><br><span class="line"><span class="bash"><span class="comment"># ------------------------------------ Node ------------------------------------</span></span></span><br><span class="line"><span class="meta">#</span></span><br><span class="line"><span class="bash"><span class="comment"># Use a descriptive name for the node:</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 节点名称，默认从elasticsearch-2.4.3/lib/elasticsearch-2.4.3.jar!config/names.txt中随机选择一个名称</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> node.name: node-1</span></span><br><span class="line"><span class="meta">#</span></span><br><span class="line"><span class="bash"><span class="comment"># Add custom attributes to the node:</span></span></span><br><span class="line"><span class="meta">#</span></span><br><span class="line"><span class="bash"><span class="comment"># node.rack: r1</span></span></span><br><span class="line"><span class="meta">#</span></span><br><span class="line"><span class="bash"><span class="comment"># ----------------------------------- Paths ------------------------------------</span></span></span><br><span class="line"><span class="meta">#</span></span><br><span class="line"><span class="bash"><span class="comment"># Path to directory where to store the data (separate multiple locations by comma):</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 可以指定es的数据存储目录，默认存储在es_home/data目录下</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> path.data: /path/to/data</span></span><br><span class="line"><span class="meta">#</span></span><br><span class="line"><span class="bash"><span class="comment"># Path to log files:</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 可以指定es的日志存储目录，默认存储在es_home/logs目录下</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> path.logs: /path/to/logs</span></span><br><span class="line"><span class="meta">#</span></span><br><span class="line"><span class="bash"><span class="comment"># ----------------------------------- Memory -----------------------------------</span></span></span><br><span class="line"><span class="meta">#</span></span><br><span class="line"><span class="bash"><span class="comment"># Lock the memory on startup:</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 锁定物理内存地址，防止elasticsearch内存被交换出去,也就是避免es使用swap交换分区</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> bootstrap.memory_lock: <span class="literal">true</span></span></span><br><span class="line"><span class="meta">#</span></span><br><span class="line"><span class="bash"><span class="comment">#</span></span></span><br><span class="line"><span class="meta">#</span></span><br><span class="line"><span class="bash"><span class="comment"># 确保ES_HEAP_SIZE参数设置为系统可用内存的一半左右</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Make sure that the `ES_HEAP_SIZE` environment variable is <span class="built_in">set</span> to about half the memory</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> available on the system and that the owner of the process is allowed to use this <span class="built_in">limit</span>.</span></span><br><span class="line"><span class="meta">#</span></span><br><span class="line"><span class="bash"><span class="comment"># 当系统进行内存交换的时候，es的性能很差</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Elasticsearch performs poorly when the system is swapping the memory.</span></span><br><span class="line"><span class="meta">#</span></span><br><span class="line"><span class="bash"><span class="comment"># ---------------------------------- Network -----------------------------------</span></span></span><br><span class="line"><span class="meta">#</span></span><br><span class="line"><span class="bash"><span class="comment">#</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 为es设置ip绑定，默认是127.0.0.1，也就是默认只能通过127.0.0.1 或者localhost才能访问</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> es1.x版本默认绑定的是0.0.0.0 所以不需要配置，但是es2.x版本默认绑定的是127.0.0.1，需要配置</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Set the <span class="built_in">bind</span> address to a specific IP (IPv4 or IPv6):</span></span><br><span class="line"><span class="meta">#</span></span><br><span class="line"><span class="bash">network.host: 0.0.0.0</span></span><br><span class="line"><span class="meta">#</span></span><br><span class="line"><span class="bash"><span class="comment">#</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 为es设置自定义端口，默认是9200</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 注意：在同一个服务器中启动多个es节点的话，默认监听的端口号会自动加1：例如：9200，9201，9202...</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Set a custom port <span class="keyword">for</span> HTTP:</span></span><br><span class="line"><span class="meta">#</span></span><br><span class="line"><span class="bash">http.port: 9200</span></span><br><span class="line"><span class="meta">#</span></span><br><span class="line"><span class="bash"><span class="comment"># For more information, see the documentation at:</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> &lt;http://www.elastic.co/guide/en/elasticsearch/reference/current/modules-network.html&gt;</span></span><br><span class="line"><span class="meta">#</span></span><br><span class="line"><span class="bash"><span class="comment"># --------------------------------- Discovery ----------------------------------</span></span></span><br><span class="line"><span class="meta">#</span></span><br><span class="line"><span class="bash"><span class="comment"># 当启动新节点时，通过这个ip列表进行节点发现，组建集群</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 默认节点列表：</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 127.0.0.1，表示ipv4的回环地址。</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> [::1]，表示ipv6的回环地址</span></span><br><span class="line"><span class="meta">#</span></span><br><span class="line"><span class="bash"><span class="comment"># 在es1.x中默认使用的是组播(multicast)协议，默认会自动发现同一网段的es节点组建集群，</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 在es2.x中默认使用的是单播(unicast)协议，想要组建集群的话就需要在这指定要发现的节点信息了。</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 注意：如果是发现其他服务器中的es服务，可以不指定端口[默认9300]，如果是发现同一个服务器中的es服务，就需要指定端口了。</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Pass an initial list of hosts to perform discovery when new node is started:</span></span><br><span class="line"><span class="meta">#</span></span><br><span class="line"><span class="bash"><span class="comment"># The default list of hosts is [&quot;127.0.0.1&quot;, &quot;[::1]&quot;]</span></span></span><br><span class="line"><span class="meta">#</span></span><br><span class="line"><span class="bash"><span class="comment"># discovery.zen.ping.unicast.hosts: [&quot;host1&quot;, &quot;host2&quot;]</span></span></span><br><span class="line"><span class="meta">#</span></span><br><span class="line"><span class="bash"><span class="comment">#</span></span></span><br><span class="line"><span class="meta">#</span></span><br><span class="line"><span class="bash"><span class="comment">#</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 通过配置这个参数来防止集群脑裂现象 (集群总节点数量/2)+1</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Prevent the <span class="string">&quot;split brain&quot;</span> by configuring the majority of nodes (total number of nodes / 2 + 1):</span></span><br><span class="line"><span class="meta">#</span></span><br><span class="line"><span class="bash"><span class="comment"># discovery.zen.minimum_master_nodes: 3</span></span></span><br><span class="line"><span class="meta">#</span></span><br><span class="line"><span class="bash"><span class="comment"># For more information, see the documentation at:</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> &lt;http://www.elastic.co/guide/en/elasticsearch/reference/current/modules-discovery.html&gt;</span></span><br><span class="line"><span class="meta">#</span></span><br><span class="line"><span class="bash"><span class="comment"># ---------------------------------- Gateway -----------------------------------</span></span></span><br><span class="line"><span class="meta">#</span></span><br><span class="line"><span class="bash"><span class="comment"># Block initial recovery after a full cluster restart until N nodes are started:</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 一个集群中的N个节点启动后,才允许进行数据恢复处理，默认是1</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> gateway.recover_after_nodes: 3</span></span><br><span class="line"><span class="meta">#</span></span><br><span class="line"><span class="bash"><span class="comment"># For more information, see the documentation at:</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> &lt;http://www.elastic.co/guide/en/elasticsearch/reference/current/modules-gateway.html&gt;</span></span><br><span class="line"><span class="meta">#</span></span><br><span class="line"><span class="bash"><span class="comment"># ---------------------------------- Various -----------------------------------</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 在一台服务器上禁止启动多个es服务</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Disable starting multiple nodes on a single system:</span></span><br><span class="line"><span class="meta">#</span></span><br><span class="line"><span class="bash"><span class="comment"># node.max_local_storage_nodes: 1</span></span></span><br><span class="line"><span class="meta">#</span></span><br><span class="line"><span class="bash"><span class="comment"># 设置是否可以通过正则或者_all删除或者关闭索引库，默认true表示必须需要显式指定索引库名称</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 生产环境建议设置为<span class="literal">true</span>，删除索引库的时候必须显式指定，否则可能会误删索引库中的索引库。</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Require explicit names when deleting indices:</span></span><br><span class="line"><span class="meta">#</span></span><br><span class="line"><span class="bash"><span class="comment"># action.destructive_requires_name: true</span></span></span><br></pre></td></tr></table></figure>


<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker run -itd --name=myelasticsearchname --network elk -p 9200:9200 -p 9300:9300 -e <span class="string">&quot;discovery.type=single-node&quot;</span> -v /usr/<span class="built_in">local</span>/developer/elasticsearch/config/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml -v /usr/<span class="built_in">local</span>/developer/elasticsearch/data:/usr/share/elasticsearch/data -v /usr/<span class="built_in">local</span>/developer/elasticsearch/plugins:/usr/share/elasticsearch/plugins elasticsearch:7.10.1</span><br><span class="line"><span class="comment"># -v 绑定了本地目录和es的内部文件</span></span><br></pre></td></tr></table></figure>
<h3 id="kibana安装"><a href="#kibana安装" class="headerlink" title="kibana安装"></a>kibana安装</h3><ul>
<li>创建绑定目录</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 配置目录</span></span><br><span class="line">mkdir -p /usr/local/developer/kibana/config</span><br></pre></td></tr></table></figure>
<ul>
<li>配置文件 kibana.yml</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vim /usr/local/developer/kibana/config/kibana.yml</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># ** THIS IS AN AUTO-GENERATED FILE **</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Default Kibana configuration for docker target</span></span><br><span class="line">server.name: kibana</span><br><span class="line">server.host: <span class="string">&quot;0&quot;</span></span><br><span class="line">elasticsearch.hosts: [ <span class="string">&quot;http://myelasticsearchname:9200&quot;</span> ]</span><br><span class="line">monitoring.ui.container.elasticsearch.enabled: <span class="literal">true</span></span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker run -d --name kibana --network elk -p 5601:5601 -v /usr/<span class="built_in">local</span>/developer/kibana/config/kibana.yml:/usr/share/kibana/config/kibana.yml kibana:7.10.1</span><br></pre></td></tr></table></figure>
<h2 id="方式二（不推荐link）："><a href="#方式二（不推荐link）：" class="headerlink" title="方式二（不推荐link）："></a>方式二（不推荐link）：</h2><h3 id="elasticsearch安装"><a href="#elasticsearch安装" class="headerlink" title="elasticsearch安装"></a>elasticsearch安装</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 下载elasticsearch的image文件</span></span><br><span class="line">docker pull elasticsearch:7.10.1</span><br><span class="line"><span class="comment"># 运行es</span></span><br><span class="line">docker run -id --name=es -p 9200:9200 -p 9300:9300 -e <span class="string">&quot;discovery.type=single-node&quot;</span> elasticsearch:7.10.1</span><br></pre></td></tr></table></figure>
<h3 id="kibana安装-1"><a href="#kibana安装-1" class="headerlink" title="kibana安装"></a>kibana安装</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 下载kibana的image文件</span></span><br><span class="line">docker pull kibana:7.10.1</span><br><span class="line"><span class="comment"># 运行kibana并让kibana连接到es容器</span></span><br><span class="line">docker run -itd --link es:elasticsearch -p 5601:5601 kibana:7.10.1</span><br></pre></td></tr></table></figure>
<p>访问：127.0.0.1:5601 即可</p>
<h2 id="疑难杂症"><a href="#疑难杂症" class="headerlink" title="疑难杂症"></a>疑难杂症</h2><ul>
<li>elasticsearch或kibana启动不成功：</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 到elasticsearch 和 kibana的安装目录</span></span><br><span class="line">chmod -R 777 path</span><br><span class="line"><span class="meta">#</span><span class="bash"> 例如本文的</span></span><br><span class="line">chmod -R 777 /usr/local/developer/</span><br></pre></td></tr></table></figure>
<h1 id="安装IK分词器"><a href="#安装IK分词器" class="headerlink" title="安装IK分词器"></a>安装IK分词器</h1><p>github地址：<a href="https://github.com/medcl/elasticsearch-analysis-ik">https://github.com/medcl/elasticsearch-analysis-ik</a></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># ik分词器为zip文件，需要解压</span></span><br><span class="line">yum install unzip </span><br><span class="line"><span class="comment"># 解压到指定路径</span></span><br><span class="line">unzip elasticsearch-analysis-ik-7.10.1.zip -d ./ik/</span><br><span class="line"><span class="comment"># 复制到容器内部</span></span><br><span class="line">docker cp ik/ es:/usr/share/elasticsearch/plugins/analysis-ik/</span><br><span class="line"><span class="comment"># 进入容器内部</span></span><br><span class="line">docker <span class="built_in">exec</span> -it es /bin/bash</span><br><span class="line"><span class="comment"># 进入刚刚复制到的文件路径</span></span><br><span class="line"><span class="built_in">cd</span> /usr/share/elasticsearch/plugins/analysis-ik</span><br><span class="line"><span class="comment"># 将该文件夹下的config文件全部复制到es的配置文件下</span></span><br><span class="line">cp /usr/share/elasticsearch/plugins/analysis-ik/config/*  /usr/share/elasticsearch/config/</span><br><span class="line"><span class="comment"># 退出容器</span></span><br><span class="line"><span class="built_in">exit</span></span><br><span class="line"><span class="comment"># 重启es服务</span></span><br><span class="line">docker restart es</span><br></pre></td></tr></table></figure>
<h2 id="验证一下："><a href="#验证一下：" class="headerlink" title="验证一下："></a>验证一下：</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">GET /_analyze</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">&quot;analyzer&quot;</span>: <span class="string">&quot;ik_max_word&quot;</span>,</span><br><span class="line">  <span class="string">&quot;text&quot;</span>: <span class="string">&quot;今天天气真好！&quot;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 执行结果</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">&quot;tokens&quot;</span> : [</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="string">&quot;token&quot;</span> : <span class="string">&quot;今天天气&quot;</span>,</span><br><span class="line">      <span class="string">&quot;start_offset&quot;</span> : 0,</span><br><span class="line">      <span class="string">&quot;end_offset&quot;</span> : 4,</span><br><span class="line">      <span class="string">&quot;type&quot;</span> : <span class="string">&quot;CN_WORD&quot;</span>,</span><br><span class="line">      <span class="string">&quot;position&quot;</span> : 0</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="string">&quot;token&quot;</span> : <span class="string">&quot;今天&quot;</span>,</span><br><span class="line">      <span class="string">&quot;start_offset&quot;</span> : 0,</span><br><span class="line">      <span class="string">&quot;end_offset&quot;</span> : 2,</span><br><span class="line">      <span class="string">&quot;type&quot;</span> : <span class="string">&quot;CN_WORD&quot;</span>,</span><br><span class="line">      <span class="string">&quot;position&quot;</span> : 1</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="string">&quot;token&quot;</span> : <span class="string">&quot;天天&quot;</span>,</span><br><span class="line">      <span class="string">&quot;start_offset&quot;</span> : 1,</span><br><span class="line">      <span class="string">&quot;end_offset&quot;</span> : 3,</span><br><span class="line">      <span class="string">&quot;type&quot;</span> : <span class="string">&quot;CN_WORD&quot;</span>,</span><br><span class="line">      <span class="string">&quot;position&quot;</span> : 2</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="string">&quot;token&quot;</span> : <span class="string">&quot;天气&quot;</span>,</span><br><span class="line">      <span class="string">&quot;start_offset&quot;</span> : 2,</span><br><span class="line">      <span class="string">&quot;end_offset&quot;</span> : 4,</span><br><span class="line">      <span class="string">&quot;type&quot;</span> : <span class="string">&quot;CN_WORD&quot;</span>,</span><br><span class="line">      <span class="string">&quot;position&quot;</span> : 3</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="string">&quot;token&quot;</span> : <span class="string">&quot;真好&quot;</span>,</span><br><span class="line">      <span class="string">&quot;start_offset&quot;</span> : 4,</span><br><span class="line">      <span class="string">&quot;end_offset&quot;</span> : 6,</span><br><span class="line">      <span class="string">&quot;type&quot;</span> : <span class="string">&quot;CN_WORD&quot;</span>,</span><br><span class="line">      <span class="string">&quot;position&quot;</span> : 4</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>




<h2 id="备注"><a href="#备注" class="headerlink" title="备注"></a>备注</h2><p>方式一参考文档：<a href="http://codingdict.com/questions/59071">http://codingdict.com/questions/59071</a></p>
<p>关于在容器内运行命令时的含义<code>localhost</code>或<code>127.0.0.1</code>含义存在一些误解。因为每个容器都有自己的网络，所以<code>localhost</code>它不是您真正的主机系统，而是容器本身。因此，当您运行kibana并将<code>ELASTICSEARCH_URL</code>变量指向<code>localhost:9200</code>kibana进程时，将在kibana容器中查找当然不是在其中运行的elasticsearch。</p>
<p>您已经引入了一些在启动容器时引用的自定义网络。在同一网络中运行的所有容器都可以通过其<code>exposed</code>端口上的名称相互引用（请参阅Dockerfiles）。在为elasticsearch容器命名时<code>elasticsearch_2_4</code>，可以将elasticsearch<br>的http端点引用为<code>http://elasticsearch_2_4:9200</code>。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker run -d --network mynetwork -e ELASTICSEARCH_URL&#x3D;http:&#x2F;&#x2F;elasticsearch_2_4:9200 -p 5601:5601 kibana:4.6</span><br></pre></td></tr></table></figure>
<p>只要您不需要直接访问elasticsearch实例，您甚至可以忽略将端口9200和9300映射到您的主机。</p>
<p>除了建议自己启动所有容器之外，我还建议使用<code>docker- compose</code>来管理所有服务和参数。您还应该考虑将本地文件夹作为卷安装，以使数据持久化。这可能是您的撰写文件。<code>networks</code>如果需要外部网络，请添加，否则此设置只会为您创建一个网络。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">version: &quot;2&quot;</span><br><span class="line">services:</span><br><span class="line">  elasticsearch:</span><br><span class="line">    image: elasticsearch:2.4</span><br><span class="line">    ports:</span><br><span class="line">      - &quot;9200:9200&quot;</span><br><span class="line">    volumes:</span><br><span class="line">      - .&#x2F;esdata&#x2F;:&#x2F;usr&#x2F;share&#x2F;elasticsearch&#x2F;data&#x2F;</span><br><span class="line">  kibana:</span><br><span class="line">    image: kibana:4.6</span><br><span class="line">    ports:</span><br><span class="line">      - &quot;5601:5601&quot;</span><br><span class="line">    environment:</span><br><span class="line">      - ELASTICSEARCH_URL&#x3D;http:&#x2F;&#x2F;elasticsearch:9200</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>elasticsearch</category>
      </categories>
      <tags>
        <tag>elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title>Maven打包jar带上依赖</title>
    <url>/essay/9e5f4284.html</url>
    <content><![CDATA[<p>maven 插件，打包jar的时候能够带上依赖。</p>
<a id="more"></a>

<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">build</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">plugins</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-assembly-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">appendAssemblyId</span>&gt;</span>false<span class="tag">&lt;/<span class="name">appendAssemblyId</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">descriptorRefs</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">descriptorRef</span>&gt;</span>jar-with-dependencies<span class="tag">&lt;/<span class="name">descriptorRef</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">descriptorRefs</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">archive</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">manifest</span>&gt;</span></span><br><span class="line">                        <span class="comment">&lt;!-- 此处指定main方法入口的class --&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">mainClass</span>&gt;</span>com.teacher.Main<span class="tag">&lt;/<span class="name">mainClass</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;/<span class="name">manifest</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">archive</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">executions</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">execution</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">id</span>&gt;</span>make-assembly<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">phase</span>&gt;</span>package<span class="tag">&lt;/<span class="name">phase</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">goals</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">goal</span>&gt;</span>assembly<span class="tag">&lt;/<span class="name">goal</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;/<span class="name">goals</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">execution</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">executions</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">plugins</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">build</span>&gt;</span></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>maven</category>
      </categories>
  </entry>
  <entry>
    <title>Redis分布式锁</title>
    <url>/essay/cc4d73b2.html</url>
    <content><![CDATA[<p>随着业务发展的需要，原单体单机部署的系统被演化成分布式集群系统后，由于分布式系统多线程、多进程并且分布在不同机器上，这将使原单机部署情况下的并发控制锁策略失效，单纯的Java API并不能提供分布式锁的能力。为了解决这个问题就需要一种跨JVM的互斥机制来控制共享资源的访问，这就是分布式锁要解决的问题！</p>
<a id="more"></a>

<h1 id="分布式锁"><a href="#分布式锁" class="headerlink" title="分布式锁"></a>分布式锁</h1><p>分布式锁主流的实现方案：</p>
<ol>
<li>基于数据库实现分布式锁</li>
<li>基于缓存（Redis等）</li>
<li>基于Zookeeper</li>
</ol>
<p>每一种分布式锁解决方案都有各自的优缺点：<br>性能：redis最高<br>可靠性：zookeeper最高</p>
<h2 id="使用Redis实现分布式锁"><a href="#使用Redis实现分布式锁" class="headerlink" title="使用Redis实现分布式锁"></a>使用Redis实现分布式锁</h2><p>redis : 命令</p>
<p>set sku:1:info “OK” NX PX 10000</p>
<p>EX second ：设置键的过期时间为 second 秒。 SET key value EX second 效果等同于 SETEX key second value 。</p>
<p>PX millisecond ：设置键的过期时间为 millisecond 毫秒。 SET key value PX millisecond 效果等同于 PSETEX key millisecond value 。</p>
<p>NX ：只在键不存在时，才对键进行设置操作。 SET key value NX 效果等同于 SETNX key value 。</p>
<p>XX ：只在键已经存在时，才对键进行设置操作。</p>
<p><img src="/essay/cc4d73b2/1.png"></p>
<ol>
<li>多个客户端同时获取锁（setnx）</li>
<li>获取成功，执行业务逻辑{从db获取数据，放入缓存}，执行完成释放锁（del）</li>
<li>其他客户端等待重试</li>
</ol>
<p><img src="/essay/cc4d73b2/2.png"></p>
<h3 id="编写代码"><a href="#编写代码" class="headerlink" title="编写代码"></a>编写代码</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@GetMapping(&quot;testLock&quot;)</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testLock</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="comment">//1获取锁，setne</span></span><br><span class="line">    Boolean lock = redisTemplate.opsForValue().setIfAbsent(<span class="string">&quot;lock&quot;</span>, <span class="string">&quot;111&quot;</span>);</span><br><span class="line">    <span class="comment">//2获取锁成功、查询num的值</span></span><br><span class="line">    <span class="keyword">if</span>(lock)&#123;</span><br><span class="line">        Object value = redisTemplate.opsForValue().get(<span class="string">&quot;num&quot;</span>);</span><br><span class="line">        <span class="comment">//2.1判断num为空return</span></span><br><span class="line">        <span class="keyword">if</span>(StringUtils.isEmpty(value))&#123;</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//2.2有值就转成成int</span></span><br><span class="line">        <span class="keyword">int</span> num = Integer.parseInt(value+<span class="string">&quot;&quot;</span>);</span><br><span class="line">        <span class="comment">//2.3把redis的num加1</span></span><br><span class="line">        redisTemplate.opsForValue().set(<span class="string">&quot;num&quot;</span>, ++num);</span><br><span class="line">        <span class="comment">//2.4释放锁，del</span></span><br><span class="line">        redisTemplate.delete(<span class="string">&quot;lock&quot;</span>);</span><br><span class="line"></span><br><span class="line">    &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">        <span class="comment">//3获取锁失败、每隔0.1秒再获取</span></span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            Thread.sleep(<span class="number">100</span>);</span><br><span class="line">            testLock();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="新的问题：锁的释放"><a href="#新的问题：锁的释放" class="headerlink" title="新的问题：锁的释放"></a>新的问题：锁的释放</h2><p>问题：setnx刚好获取到锁，业务逻辑出现异常，导致锁无法释放<br>解决：设置过期时间，自动释放锁。</p>
<h3 id="编写代码-1"><a href="#编写代码-1" class="headerlink" title="编写代码"></a>编写代码</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//1获取锁，setne  3s过期</span></span><br><span class="line">Boolean lock = redisTemplate.opsForValue()</span><br><span class="line">    .setIfAbsent(<span class="string">&quot;lock&quot;</span>, <span class="string">&quot;111&quot;</span>,<span class="number">3</span>, TimeUnit.SECONDS);</span><br></pre></td></tr></table></figure>
<h2 id="新的问题：误删其他服务的锁"><a href="#新的问题：误删其他服务的锁" class="headerlink" title="新的问题：误删其他服务的锁"></a>新的问题：误删其他服务的锁</h2><p><img src="/essay/cc4d73b2/3.png"><img src="/essay/cc4d73b2/4.png"></p>
<h3 id="编写代码-2"><a href="#编写代码-2" class="headerlink" title="编写代码"></a>编写代码</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@GetMapping(&quot;/testLock&quot;)</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testLock</span><span class="params">()</span></span>&#123;</span><br><span class="line">        String uuid = UUID.randomUUID().toString();</span><br><span class="line">        <span class="comment">//1获取锁，setne</span></span><br><span class="line">        Boolean lock = redisTemplate.opsForValue().setIfAbsent(<span class="string">&quot;lock&quot;</span>, uuid,<span class="number">3</span>, TimeUnit.SECONDS);</span><br><span class="line">        <span class="comment">//2获取锁成功、查询num的值</span></span><br><span class="line">        <span class="keyword">if</span>(lock)&#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;成功获取锁&quot;</span>);</span><br><span class="line">            Object value = redisTemplate.opsForValue().get(<span class="string">&quot;num&quot;</span>);</span><br><span class="line">            <span class="comment">//2.1判断num为空return</span></span><br><span class="line">            <span class="keyword">if</span>(StringUtils.isEmpty(value))&#123;</span><br><span class="line">                <span class="keyword">return</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">//2.2有值就转成成int</span></span><br><span class="line">            <span class="keyword">int</span> num = Integer.parseInt(value+<span class="string">&quot;&quot;</span>);</span><br><span class="line">            <span class="comment">//2.3把redis的num加1</span></span><br><span class="line">            redisTemplate.opsForValue().set(<span class="string">&quot;num&quot;</span>, ++num);</span><br><span class="line">            String strLock = (String) redisTemplate.opsForValue().get(<span class="string">&quot;lock&quot;</span>);</span><br><span class="line">            <span class="keyword">if</span> (uuid.equals(strLock)) &#123;</span><br><span class="line">                <span class="comment">//2.4释放锁，del</span></span><br><span class="line">                redisTemplate.delete(<span class="string">&quot;lock&quot;</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">            <span class="comment">//3获取锁失败、每隔0.1秒再获取</span></span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                Thread.sleep(<span class="number">100</span>);</span><br><span class="line">                testLock();</span><br><span class="line">            &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<h2 id="新的问题：删除操作缺乏原子性"><a href="#新的问题：删除操作缺乏原子性" class="headerlink" title="新的问题：删除操作缺乏原子性"></a>新的问题：删除操作缺乏原子性</h2><p> <img src="/essay/cc4d73b2/5.png"></p>
<p><img src="/essay/cc4d73b2/6.png"></p>
<h3 id="编写代码-3"><a href="#编写代码-3" class="headerlink" title="编写代码"></a>编写代码</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@GetMapping(&quot;/testLock&quot;)</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testLock</span><span class="params">()</span></span>&#123;</span><br><span class="line">        String uuid = UUID.randomUUID().toString();</span><br><span class="line">        <span class="comment">//1获取锁，setne</span></span><br><span class="line">        Boolean lock = redisTemplate.opsForValue().setIfAbsent(<span class="string">&quot;lock&quot;</span>, uuid,<span class="number">3</span>, TimeUnit.SECONDS);</span><br><span class="line">        <span class="comment">//2获取锁成功、查询num的值</span></span><br><span class="line">        <span class="keyword">if</span>(lock)&#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;成功获取锁&quot;</span>);</span><br><span class="line">            Object value = redisTemplate.opsForValue().get(<span class="string">&quot;num&quot;</span>);</span><br><span class="line">            <span class="comment">//2.1判断num为空return</span></span><br><span class="line">            <span class="keyword">if</span>(StringUtils.isEmpty(value))&#123;</span><br><span class="line">                <span class="keyword">return</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">//2.2有值就转成成int</span></span><br><span class="line">            <span class="keyword">int</span> num = Integer.parseInt(value+<span class="string">&quot;&quot;</span>);</span><br><span class="line">            <span class="comment">//2.3把redis的num加1</span></span><br><span class="line">            redisTemplate.opsForValue().set(<span class="string">&quot;num&quot;</span>, ++num);</span><br><span class="line">            String strLock = (String) redisTemplate.opsForValue().get(<span class="string">&quot;lock&quot;</span>);</span><br><span class="line">            lockService.doDeleteKey(<span class="string">&quot;lock&quot;</span>, strLock);</span><br><span class="line">            System.out.println(<span class="string">&quot;已删除锁&quot;</span>);</span><br><span class="line">            System.out.println(<span class="string">&quot;num ===&gt;&quot;</span> + num);</span><br><span class="line"></span><br><span class="line">        &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">            <span class="comment">//3获取锁失败、每隔0.1秒再获取</span></span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                Thread.sleep(<span class="number">100</span>);</span><br><span class="line">                System.out.println(<span class="string">&quot;获取失败，再来一次&quot;</span>);</span><br><span class="line">                testLock();</span><br><span class="line">            &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">// service代码</span></span><br><span class="line"><span class="meta">@Transactional</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">doDeleteKey</span><span class="params">(String key, String uuid)</span> </span>&#123;</span><br><span class="line">        Long result = (Long) redisTemplate.execute(script, Arrays.asList(key), uuid);</span><br><span class="line">        <span class="keyword">if</span> (result == <span class="keyword">null</span>) &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;删除键失败或键已经过期&quot;</span>);</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (result == <span class="number">1</span>) &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;删除键成功&quot;</span>);</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;条件不匹配&quot;</span>);</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<h3 id="lua脚本"><a href="#lua脚本" class="headerlink" title="lua脚本"></a>lua脚本</h3><figure class="highlight lua"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> redis.call(<span class="string">&#x27;get&#x27;</span>, KEYS[<span class="number">1</span>]) == ARGV[<span class="number">1</span>] <span class="keyword">then</span></span><br><span class="line">    <span class="keyword">return</span> redis.call(<span class="string">&#x27;del&#x27;</span>, KEYS[<span class="number">1</span>]);</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>redis</category>
      </categories>
  </entry>
  <entry>
    <title>Redis和Memcached</title>
    <url>/essay/1ed8e456.html</url>
    <content><![CDATA[<ul>
<li>Redis : Redis是一款内存高速缓存数据库。Redis全称为:Remote Dictionary Server (远程数据服务),使用C语言编写,Redis是一个key-value存储系统(键值存储系统),支持丰富的数据类型。</li>
<li>Memcached：是一个免费开源的、高性能的、具有分布式内存对象的缓存系统，它通过减轻数据库负载加速动态Web应用；</li>
</ul>
<p>那么，同样是可以作为缓存服务，他们有什么区别呢？</p>
<a id="more"></a>

<h1 id="特性"><a href="#特性" class="headerlink" title="特性"></a>特性</h1><h2 id="Redis特性"><a href="#Redis特性" class="headerlink" title="Redis特性"></a>Redis特性</h2><ul>
<li>单进程单线程模型</li>
<li>丰富的数据类型</li>
<li>操作具有原子性</li>
<li>持久化</li>
<li>高并发读写</li>
<li>支持lua脚本</li>
</ul>
<h2 id="Memcached特性"><a href="#Memcached特性" class="headerlink" title="Memcached特性"></a>Memcached特性</h2><ul>
<li>协议简单，使用的是基于文本行的协议</li>
<li>不支持数据的持久化，服务器关闭之后数据全部丢失</li>
<li>Memcached简洁而强大，便于快速开发，上手较为容易</li>
<li>互不通信的Memcached之间具有分布特征 </li>
<li>没有安全机制</li>
</ul>
<h1 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h1><h2 id="Redis"><a href="#Redis" class="headerlink" title="Redis"></a>Redis</h2><ul>
<li>缓存系统（“热点”数据：高频读、低频写）</li>
<li>计数器</li>
<li>消息队列系统</li>
<li>排行榜、社交网络和实时系统</li>
<li>分布式锁等</li>
</ul>
<h2 id="Memcached"><a href="#Memcached" class="headerlink" title="Memcached"></a>Memcached</h2><ul>
<li>变化频繁，查询频繁，重点是不需要入库（不支持持久化）</li>
<li>变化不频繁，但查询频繁的数据</li>
<li>读多写少</li>
</ul>
<h1 id="特性对比"><a href="#特性对比" class="headerlink" title="特性对比"></a>特性对比</h1><table>
<thead>
<tr>
<th align="center"></th>
<th align="center">Redis</th>
<th align="center">Memcached</th>
</tr>
</thead>
<tbody><tr>
<td align="center">线程模型</td>
<td align="center">单进程单线程</td>
<td align="center">单进程多线程</td>
</tr>
<tr>
<td align="center">OPS/TPS</td>
<td align="center">10w+/&lt;10w</td>
<td align="center">10w+/10w+</td>
</tr>
<tr>
<td align="center">数据支持类型</td>
<td align="center">Key-value、set、hash、list、zset等</td>
<td align="center">Key-value</td>
</tr>
<tr>
<td align="center">持久化支持</td>
<td align="center">支持</td>
<td align="center">不支持</td>
</tr>
<tr>
<td align="center">能否集群</td>
<td align="center">能</td>
<td align="center">能</td>
</tr>
<tr>
<td align="center">支持数据备份</td>
<td align="center">支持</td>
<td align="center">不支持（但可用第三方工具）</td>
</tr>
<tr>
<td align="center">数据一致性</td>
<td align="center">支持事务</td>
<td align="center">轻量级锁CAS机制</td>
</tr>
<tr>
<td align="center">List排序支持</td>
<td align="center">支持</td>
<td align="center">不支持</td>
</tr>
<tr>
<td align="center">缓存策略</td>
<td align="center">LRU、FIFO、LFU</td>
<td align="center">LRU</td>
</tr>
<tr>
<td align="center">Jcache支持</td>
<td align="center">支持</td>
<td align="center">支持</td>
</tr>
<tr>
<td align="center">单条数据约束</td>
<td align="center">不同数据结构有不同的约束规则</td>
<td align="center">默认值：key最大长度250个字符 Value容量&lt;=1M</td>
</tr>
</tbody></table>
<h1 id="集群对比"><a href="#集群对比" class="headerlink" title="集群对比"></a>集群对比</h1><p>redis集群，不管是redis中的哨兵还是cluster集群，服务与服务直接是可以有数据的同步的，master的节点数据会通过slaveof的配置参数进行同步。</p>
<p>memcached也是可以支持集群的，但他的集群仅仅体现再数据的分库中。虽然memcached内存有限制可以用多个memcached来存去解决。但是memcached节点之间是不会进行任何通信的，更别说什么master与slave机制了，他本身也不支持持久化，服务重启数据就丢了，所以不存在高可用。</p>
<h1 id="共同点以及区别"><a href="#共同点以及区别" class="headerlink" title="共同点以及区别"></a>共同点以及区别</h1><ul>
<li><p><strong>共同点</strong> ：</p>
<ol>
<li>都是基于内存的数据库，一般都用来当做缓存使用。</li>
<li>都有过期策略。</li>
<li>两者的性能都非常高。</li>
</ol>
<p><strong>区别</strong> ：</p>
<ol>
<li><strong>Redis 支持更丰富的数据类型（支持更复杂的应用场景）</strong>。Redis 不仅仅支持简单的 k/v 类型的数据，同时还提供 list，set，zset，hash 等数据结构的存储。Memcached 只支持最简单的 k/v 数据类型。</li>
<li><strong>Redis 支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用,而 Memcached 把数据全部存在内存之中。</strong></li>
<li><strong>Redis 有灾难恢复机制。</strong> 因为可以把缓存中的数据持久化到磁盘上。</li>
<li><strong>Redis 在服务器内存使用完之后，可以将不用的数据放到磁盘上。但是，Memcached 在服务器内存使用完之后，就会直接报异常。</strong></li>
<li><strong>Memcached 没有原生的集群模式，需要依靠客户端来实现往集群中分片写入数据；但是 Redis 目前是原生支持 cluster 模式的。</strong></li>
<li><strong>Memcached 是多线程，非阻塞 IO 复用的网络模型；Redis 使用单线程的多路 IO 复用模型。</strong> （Redis 6.0 引入了多线程 IO ）</li>
<li><strong>Redis 支持发布订阅模型、Lua 脚本、事务等功能，而 Memcached 不支持。并且，Redis 支持更多的编程语言。</strong></li>
<li><strong>Memcached 过期数据的删除策略只用了惰性删除，而 Redis 同时使用了惰性删除与定期删除。</strong></li>
</ol>
</li>
</ul>
<p>tips: 虽然redis是单线程的，但是高并发下redis的性能比memcached要高，原因是因为memcached多线程模型引入了缓存一致性和锁，加锁带来了性能损耗。</p>
]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title>Redis持久化</title>
    <url>/essay/119ed1dc.html</url>
    <content><![CDATA[<p>Redis支持两种持久化操作：分别是<strong>快照（snapshotting，RDB）</strong>和<strong>只追加文件（append-only file, AOF）</strong>。</p>
<a id="more"></a>

<h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><h2 id="快照（snapshotting）持久化（RDB）"><a href="#快照（snapshotting）持久化（RDB）" class="headerlink" title="快照（snapshotting）持久化（RDB）"></a>快照（snapshotting）持久化（RDB）</h2><p>Redis 可以通过创建快照来获得存储在内存里面的数据在某个时间点上的副本。Redis 创建快照之后，可以对快照进行备份，可以将快照复制到其他服务器从而创建具有相同数据的服务器副本（Redis 主从结构，主要用来提高 Redis 性能），还可以将快照留在原地以便重启服务器的时候使用。</p>
<p>快照持久化是 Redis 默认采用的持久化方式，在 Redis.conf 配置文件中默认有此下配置：</p>
<figure class="highlight text"><table><tr><td class="code"><pre><span class="line">save 900 1           #在900秒(15分钟)之后，如果至少有1个key发生变化，Redis就会自动触发BGSAVE命令创建快照。</span><br><span class="line"></span><br><span class="line">save 300 10          #在300秒(5分钟)之后，如果至少有10个key发生变化，Redis就会自动触发BGSAVE命令创建快照。</span><br><span class="line"></span><br><span class="line">save 60 10000        #在60秒(1分钟)之后，如果至少有10000个key发生变化，Redis就会自动触发BGSAVE命令创建快照。</span><br></pre></td></tr></table></figure>
<p>缺点：耗时，耗性能(fork+io 操作)，易丢失数据。</p>
<h2 id="AOF（append-only-file）持久化"><a href="#AOF（append-only-file）持久化" class="headerlink" title="AOF（append-only file）持久化"></a>AOF（append-only file）持久化</h2><p>与快照持久化相比，AOF 持久化的实时性更好，因此已成为主流的持久化方案。默认情况下 Redis 没有开启 AOF（append only file）方式的持久化，可以通过 appendonly 参数开启：</p>
<figure class="highlight text"><table><tr><td class="code"><pre><span class="line">appendonly yes</span><br></pre></td></tr></table></figure>
<p>开启 AOF 持久化后每执行一条会更改 Redis 中的数据的命令，Redis 就会将该命令写入到内存缓存 <code>server.aof_buf</code> 中，然后再根据 <code>appendfsync</code> 配置来决定何时将其同步到硬盘中的 AOF 文件。</p>
<p>AOF 文件的保存位置和 RDB 文件的位置相同，都是通过 dir 参数设置的，默认的文件名是 <code>appendonly.aof</code>。</p>
<p>在 Redis 的配置文件中存在三种不同的 AOF 持久化方式，它们分别是：</p>
<figure class="highlight text"><table><tr><td class="code"><pre><span class="line">appendfsync always    #每次有数据修改发生时都会写入AOF文件,这样会严重降低Redis的速度</span><br><span class="line">appendfsync everysec  #每秒钟同步一次，显示地将多个写命令同步到硬盘</span><br><span class="line">appendfsync no        #让操作系统决定何时进行同步</span><br></pre></td></tr></table></figure>
<p>为了兼顾数据和写入性能，用户可以考虑 <code>appendfsync everysec</code> 选项 ，让 Redis 每秒同步一次 AOF 文件，Redis 性能几乎没受到任何影响。而且这样即使出现系统崩溃，用户最多只会丢失一秒之内产生的数据。当硬盘忙于执行写入操作的时候，Redis 还会优雅的放慢自己的速度以便适应硬盘的最大写入速度。</p>
<p>缺点：体积大，恢复速度慢。</p>
<h1 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h1><h2 id="Redis-4-0-对于持久化机制的优化"><a href="#Redis-4-0-对于持久化机制的优化" class="headerlink" title="Redis 4.0 对于持久化机制的优化"></a>Redis 4.0 对于持久化机制的优化</h2><p>Redis 4.0 开始支持 RDB 和 AOF 的混合持久化（默认关闭，可以通过配置项 <code>aof-use-rdb-preamble</code> 开启）。</p>
<p>如果把混合持久化打开，AOF 重写的时候就直接把 RDB 的内容写到 AOF 文件开头。这样做的好处是可以结合 RDB 和 AOF 的优点, 快速加载同时避免丢失过多的数据。当然缺点也是有的， AOF 里面的 RDB 部分是压缩格式不再是 AOF 格式，可读性较差。</p>
<h2 id="AOF-重写"><a href="#AOF-重写" class="headerlink" title="AOF 重写"></a>AOF 重写</h2><p>AOF 重写可以产生一个新的 AOF 文件，这个新的 AOF 文件和原有的 AOF 文件所保存的数据库状态一样，但体积更小。</p>
<p>AOF 重写是一个有歧义的名字，该功能是通过读取数据库中的键值对来实现的，程序无须对现有 AOF 文件进行任何读入、分析或者写入操作。</p>
<p>在执行 BGREWRITEAOF 命令时，Redis 服务器会维护一个 AOF 重写缓冲区，该缓冲区会在子进程创建新 AOF 文件期间，记录服务器执行的所有写命令。当子进程完成创建新 AOF 文件的工作之后，服务器会将重写缓冲区中的所有内容追加到新 AOF 文件的末尾，使得新的 AOF 文件保存的数据库状态与现有的数据库状态一致。最后，服务器用新的 AOF 文件替换旧的 AOF 文件，以此来完成 AOF 文件重写操作。</p>
]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title>docker搭建es集群</title>
    <url>/essay/85dd3af8.html</url>
    <content><![CDATA[<p>使用docker来在同一主机搭建es集群</p>
<a id="more"></a>

<h1 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h1><p>docker版本</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">root@dev-host:~# docker -v</span><br><span class="line">Docker version 20.10.12, build e91ed57</span><br></pre></td></tr></table></figure>
<p>elasticsearch版本:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">elasticsearch   7.3.0</span><br></pre></td></tr></table></figure>
<p>kibana版本:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kibana          7.3.0</span><br></pre></td></tr></table></figure>
<h2 id="下载镜像"><a href="#下载镜像" class="headerlink" title="下载镜像"></a>下载镜像</h2><ul>
<li>elasticsearch</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker pull elasticsearch:7.3.0</span><br></pre></td></tr></table></figure>
<ul>
<li>kibana</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker pull kibana:7.3.0</span><br></pre></td></tr></table></figure>
<h2 id="自定义网络"><a href="#自定义网络" class="headerlink" title="自定义网络"></a>自定义网络</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> elk: 自定义网络名称 需要和下面的--network相同</span></span><br><span class="line">docker network create elk</span><br></pre></td></tr></table></figure>
<h1 id="ES集群安装"><a href="#ES集群安装" class="headerlink" title="ES集群安装"></a>ES集群安装</h1><h2 id="创建绑定目录"><a href="#创建绑定目录" class="headerlink" title="创建绑定目录"></a>创建绑定目录</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 配置目录</span></span><br><span class="line">mkdir -p /usr/local/developer/elasticsearch/config</span><br><span class="line"><span class="meta">#</span><span class="bash"> 数据目录</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> node 1</span></span><br><span class="line">mkdir -p /usr/local/developer/elasticsearch/node1/data</span><br><span class="line"><span class="meta">#</span><span class="bash"> node 2</span></span><br><span class="line">mkdir -p /usr/local/developer/elasticsearch/node2/data</span><br><span class="line"><span class="meta">#</span><span class="bash"> node 3</span></span><br><span class="line">mkdir -p /usr/local/developer/elasticsearch/node3/data</span><br></pre></td></tr></table></figure>
<h2 id="设定目录权限"><a href="#设定目录权限" class="headerlink" title="设定目录权限"></a>设定目录权限</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">chmod -R 777 /usr/local/developer/elasticsearch/</span><br></pre></td></tr></table></figure>
<p>docker启动es会报错</p>
<blockquote>
<p>max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144]</p>
</blockquote>
<p>修改配置</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vim /etc/sysctl.conf</span><br><span class="line"><span class="meta">#</span><span class="bash"> 添加</span></span><br><span class="line">vm.max_map_count=262144</span><br><span class="line"><span class="meta">#</span><span class="bash"> 启用配置</span></span><br><span class="line">sysctl -p</span><br></pre></td></tr></table></figure>
<h2 id="es配置文件"><a href="#es配置文件" class="headerlink" title="es配置文件"></a>es配置文件</h2><blockquote>
<p>es1.yml</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cluster.name: elasticsearch-cluster</span><br><span class="line">node.name: es-node1</span><br><span class="line">network.bind_host: 0.0.0.0</span><br><span class="line">network.publish_host: 192.168.200.129 # 虚拟机地址</span><br><span class="line">http.port: 9200</span><br><span class="line">transport.tcp.port: 9300</span><br><span class="line">http.cors.enabled: true</span><br><span class="line">http.cors.allow-origin: &quot;*&quot;</span><br><span class="line">node.master: true</span><br><span class="line">node.data: true</span><br><span class="line"><span class="meta">#</span><span class="bash"> 这里根据实际情况修改 另外两个节点的ip</span></span><br><span class="line">discovery.seed_hosts: [&quot;192.168.200.129:9301&quot;, &quot;192.168.200.129:9302&quot;]</span><br><span class="line">discovery.zen.minimum_master_nodes: 2</span><br><span class="line">cluster.initial_master_nodes: [&quot;es-node1&quot;]</span><br><span class="line">xpack.security.enabled: true</span><br><span class="line">xpack.security.authc.accept_default_password: true</span><br><span class="line">xpack.security.transport.ssl.enabled: true</span><br><span class="line"><span class="meta">#</span><span class="bash">xpack.security.transport.ssl.verification_mode: certificate</span></span><br><span class="line"><span class="meta">#</span><span class="bash">xpack.security.transport.ssl.keystore.path: /usr/share/elasticsearch/config/elastic-certificates.p12</span></span><br><span class="line"><span class="meta">#</span><span class="bash">xpack.security.transport.ssl.truststore.path: /usr/share/elasticsearch/config/elastic-certificates.p12</span></span><br><span class="line">http.cors.allow-headers: Authorization,X-Requested-With,Content-Length,Content-Type</span><br></pre></td></tr></table></figure>
<blockquote>
<p>es2.yml</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cluster.name: elasticsearch-cluster</span><br><span class="line">node.name: es-node2</span><br><span class="line">network.bind_host: 0.0.0.0</span><br><span class="line">network.publish_host: 192.168.200.129 # 虚拟机地址</span><br><span class="line">http.port: 9201</span><br><span class="line">transport.tcp.port: 9301</span><br><span class="line">http.cors.enabled: true</span><br><span class="line">http.cors.allow-origin: &quot;*&quot;</span><br><span class="line">node.master: true</span><br><span class="line">node.data: true</span><br><span class="line"><span class="meta">#</span><span class="bash"> 这里根据实际情况修改</span></span><br><span class="line">discovery.seed_hosts: [&quot;192.168.200.129:9300&quot;, &quot;192.168.200.129:9301&quot;]</span><br><span class="line">discovery.zen.minimum_master_nodes: 2</span><br><span class="line">cluster.initial_master_nodes: [&quot;es-node1&quot;]</span><br><span class="line">xpack.security.enabled: true</span><br><span class="line">xpack.security.authc.accept_default_password: true</span><br><span class="line">xpack.security.transport.ssl.enabled: true</span><br><span class="line"><span class="meta">#</span><span class="bash">xpack.security.transport.ssl.verification_mode: certificate</span></span><br><span class="line"><span class="meta">#</span><span class="bash">xpack.security.transport.ssl.keystore.path: /usr/share/elasticsearch/config/elastic-certificates.p12</span></span><br><span class="line"><span class="meta">#</span><span class="bash">xpack.security.transport.ssl.truststore.path: /usr/share/elasticsearch/config/elastic-certificates.p12</span></span><br><span class="line">http.cors.allow-headers: Authorization,X-Requested-With,Content-Length,Content-Type</span><br></pre></td></tr></table></figure>
<blockquote>
<p>es3.yml</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cluster.name: elasticsearch-cluster</span><br><span class="line">node.name: es-node3</span><br><span class="line">network.bind_host: 0.0.0.0</span><br><span class="line">network.publish_host: 192.168.200.129 #虚拟机地址</span><br><span class="line">http.port: 9202</span><br><span class="line">transport.tcp.port: 9302</span><br><span class="line">http.cors.enabled: true</span><br><span class="line">http.cors.allow-origin: &quot;*&quot;</span><br><span class="line">node.master: true</span><br><span class="line">node.data: true</span><br><span class="line"><span class="meta">#</span><span class="bash"> 这里根据实际情况修改</span></span><br><span class="line">discovery.seed_hosts: [&quot;192.168.200.129:9300&quot;, &quot;192.168.200.129:9302&quot;]</span><br><span class="line">discovery.zen.minimum_master_nodes: 2</span><br><span class="line">cluster.initial_master_nodes: [&quot;es-node1&quot;]</span><br><span class="line">xpack.security.enabled: true</span><br><span class="line">xpack.security.authc.accept_default_password: true</span><br><span class="line">xpack.security.transport.ssl.enabled: true</span><br><span class="line"><span class="meta">#</span><span class="bash">xpack.security.transport.ssl.verification_mode: certificate</span></span><br><span class="line"><span class="meta">#</span><span class="bash">xpack.security.transport.ssl.keystore.path: /usr/share/elasticsearch/config/elastic-certificates.p12</span></span><br><span class="line"><span class="meta">#</span><span class="bash">xpack.security.transport.ssl.truststore.path: /usr/share/elasticsearch/config/elastic-certificates.p12</span></span><br><span class="line">http.cors.allow-headers: Authorization,X-Requested-With,Content-Length,Content-Type</span><br></pre></td></tr></table></figure>
<h2 id="启动ES"><a href="#启动ES" class="headerlink" title="启动ES"></a>启动ES</h2><ul>
<li><p>命令</p>
</li>
<li><p>node1</p>
</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker run -e ES_JAVA_OPTS=&quot;-Xms256m -Xmx256m&quot; --network elk -d -p 9200:9200 -p 9300:9300 -v /usr/local/developer/elasticsearch/config/es1.yml:/usr/share/elasticsearch/config/elasticsearch.yml -v /usr/local/developer/elasticsearch/node1/data:/usr/share/elasticsearch/data --name ES01 elasticsearch:7.3.0</span><br></pre></td></tr></table></figure>
<ul>
<li>node2</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker run -e ES_JAVA_OPTS=&quot;-Xms256m -Xmx256m&quot; --network elk -d -p 9201:9201 -p 9301:9301 -v /usr/local/developer/elasticsearch/config/es2.yml:/usr/share/elasticsearch/config/elasticsearch.yml -v /usr/local/developer/elasticsearch/node2/data:/usr/share/elasticsearch/data --name ES02 elasticsearch:7.3.0</span><br></pre></td></tr></table></figure>
<ul>
<li>node3</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker run -e ES_JAVA_OPTS=&quot;-Xms256m -Xmx256m&quot; --network elk -d -p 9202:9202 -p 9302:9302 -v /usr/local/developer/elasticsearch/config/es3.yml:/usr/share/elasticsearch/config/elasticsearch.yml -v /usr/local/developer/elasticsearch/node3/data:/usr/share/elasticsearch/data --name ES03 elasticsearch:7.3.0</span><br></pre></td></tr></table></figure>
<h1 id="kibana安装"><a href="#kibana安装" class="headerlink" title="kibana安装"></a>kibana安装</h1><h2 id="创建绑定目录-1"><a href="#创建绑定目录-1" class="headerlink" title="创建绑定目录"></a>创建绑定目录</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 配置目录</span></span><br><span class="line">mkdir -p /usr/local/developer/kibana/config</span><br></pre></td></tr></table></figure>
<h2 id="配置文件-kibana-yml"><a href="#配置文件-kibana-yml" class="headerlink" title="配置文件 kibana.yml"></a>配置文件 kibana.yml</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vim /usr/local/developer/kibana/config/kibana.yml</span><br><span class="line">server.name: kibana</span><br><span class="line">server.host: &quot;0&quot;</span><br><span class="line">elasticsearch.hosts: [ &quot;http://ES01:9200&quot;,&quot;http://ES02:9201&quot;,&quot;http://ES03:9202&quot; ]</span><br><span class="line">xpack.monitoring.ui.container.elasticsearch.enabled: true</span><br><span class="line">elasticsearch.username: &quot;kibana&quot;</span><br><span class="line">elasticsearch.password: &quot;kibana&quot;</span><br><span class="line">xpack.security.enabled: true</span><br><span class="line">xpack.security.encryptionKey: &quot;c77effba756146d382ebc79b279fd694&quot;</span><br><span class="line">i18n.locale: &quot;zh-CN&quot;</span><br></pre></td></tr></table></figure>
<h2 id="启动kibana"><a href="#启动kibana" class="headerlink" title="启动kibana"></a>启动kibana</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker run -d --name kibana --network elk -p 5601:5601 -v /usr/local/developer/kibana/config/kibana.yml:/usr/share/kibana/config/kibana.yml kibana:7.3.0</span><br></pre></td></tr></table></figure>
<h1 id="开启es安全认证"><a href="#开启es安全认证" class="headerlink" title="开启es安全认证"></a>开启es安全认证</h1><ul>
<li>注意：这个操作只在node1进行</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker exec -it ES01 bash</span><br><span class="line">bin/elasticsearch-certutil ca</span><br></pre></td></tr></table></figure>
<p>执行完会生成 <code>elastic-stack-ca.p12</code> 文件</p>
<p><img src="/essay/85dd3af8/image-20220308195109647.png"></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">bin/elasticsearch-certutil cert --ca elastic-stack-ca.p12</span><br></pre></td></tr></table></figure>
<p>执行完会生成 <code>elastic-certificates.p12</code> 文件</p>
<p><img src="/essay/85dd3af8/image-20220308195208105.png"></p>
<p>移动到config下面</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mv elastic-certificates.p12 config/</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd config/</span><br></pre></td></tr></table></figure>
<p>配置权限</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">chmod 777 elastic-certificates.p12</span><br></pre></td></tr></table></figure>
<p>分配用户组</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">chown elasticsearch elastic-certificates.p12</span><br></pre></td></tr></table></figure>
<p><img src="/essay/85dd3af8/image-20220308195432533.png"></p>
<p>退出容器</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">exit</span><br></pre></td></tr></table></figure>
<p>从容器复制CA证书到本地</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker cp ES01:/usr/share/elasticsearch/config/elastic-certificates.p12 /usr/local/developer/elasticsearch/</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd &#x2F;usr&#x2F;local&#x2F;developer&#x2F;elasticsearch&#x2F;</span><br></pre></td></tr></table></figure>
<p><img src="/essay/85dd3af8/image-20220308195737471.png"></p>
<p>复制到其他node的config中</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker cp elastic-certificates.p12 ES02:/usr/share/elasticsearch/config/</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker cp elastic-certificates.p12 ES03:/usr/share/elasticsearch/config/</span><br></pre></td></tr></table></figure>
<p>解开之前所有的es配置文件的注释</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">xpack.security.transport.ssl.verification_mode: certificate</span><br><span class="line">xpack.security.transport.ssl.keystore.path: /usr/share/elasticsearch/config/elastic-certificates.p12</span><br><span class="line">xpack.security.transport.ssl.truststore.path: /usr/share/elasticsearch/config/elastic-certificates.p12</span><br></pre></td></tr></table></figure>
<p>全部修改完了后重启es</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker restart ES01</span><br><span class="line">docker restart ES02</span><br><span class="line">docker restart ES03</span><br></pre></td></tr></table></figure>
<p>重启es后要生成密码，进入es容器</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker exec -it ES01 bash</span><br><span class="line"><span class="meta">#</span><span class="bash"> 指定master节点的ip</span></span><br><span class="line"> bin/elasticsearch-setup-passwords interactive -u &#x27;http://192.168.200.129:9200&#x27;</span><br></pre></td></tr></table></figure>
<p>这里会让配置好多密码，挨个配置</p>
<p><img src="/essay/85dd3af8/image-20220308200526445.png"></p>
<p>配置成功后</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">exit</span><br></pre></td></tr></table></figure>


]]></content>
      <categories>
        <category>elasticsearch</category>
      </categories>
  </entry>
  <entry>
    <title>intern详解</title>
    <url>/essay/792ee381.html</url>
    <content><![CDATA[<h1 id="深入解析String-intern"><a href="#深入解析String-intern" class="headerlink" title="深入解析String#intern"></a>深入解析String#intern</h1><p>在 JAVA 语言中有8中基本类型和一种比较特殊的类型<code>String</code>。这些类型为了使他们在运行过程中速度更快，更节省内存，都提供了一种常量池的概念。常量池就类似一个JAVA系统级别提供的缓存。</p>
<p>8种基本类型的常量池都是系统协调的，<code>String</code>类型的常量池比较特殊。它的主要使用方法有两种：</p>
<ul>
<li>直接使用双引号声明出来的<code>String</code>对象会直接存储在常量池中。</li>
<li>如果不是用双引号声明的<code>String</code>对象，可以使用<code>String</code>提供的<code>intern</code>方法。intern 方法会从字符串常量池中查询当前字符串是否存在，若不存在就会将当前字符串放入常量池中</li>
</ul>
<a id="more"></a>

<h2 id="思考一："><a href="#思考一：" class="headerlink" title="思考一："></a>思考一：</h2><blockquote>
<p>new String(“ab”)会创建几个对象？</p>
</blockquote>
<p>先贴代码：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">      String str = <span class="keyword">new</span> String(<span class="string">&quot;ab&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>首先先看字节码指令</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"> 0 new <span class="comment">#2 &lt;java/lang/String&gt;</span></span><br><span class="line"> 3 dup</span><br><span class="line"> 4 ldc <span class="comment">#3 &lt;ab&gt;</span></span><br><span class="line"> 6 invokespecial <span class="comment">#4 &lt;java/lang/String.&lt;init&gt;&gt;</span></span><br><span class="line"> 9 astore_1</span><br><span class="line">10 <span class="built_in">return</span></span><br></pre></td></tr></table></figure>
<p>对象1：new 关键字在堆空间创建的String对象。</p>
<p>对象2：ldc指令（load constant）从字符串常量池加载的对象“ab”</p>
<h2 id="思考二："><a href="#思考二：" class="headerlink" title="思考二："></a>思考二：</h2><blockquote>
<p>new String(“a”) + new String(“b”)呢？</p>
</blockquote>
<p>先贴代码：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">     String str = <span class="keyword">new</span> String(<span class="string">&quot;a&quot;</span>) + <span class="keyword">new</span> String(<span class="string">&quot;b&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>首先先看字节码指令</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"> 0 new <span class="comment">#2 &lt;java/lang/StringBuilder&gt;</span></span><br><span class="line"> 3 dup</span><br><span class="line"> 4 invokespecial <span class="comment">#3 &lt;java/lang/StringBuilder.&lt;init&gt;&gt;</span></span><br><span class="line"> 7 new <span class="comment">#4 &lt;java/lang/String&gt;</span></span><br><span class="line">10 dup</span><br><span class="line">11 ldc <span class="comment">#5 &lt;a&gt;</span></span><br><span class="line">13 invokespecial <span class="comment">#6 &lt;java/lang/String.&lt;init&gt;&gt;</span></span><br><span class="line">16 invokevirtual <span class="comment">#7 &lt;java/lang/StringBuilder.append&gt;</span></span><br><span class="line">19 new <span class="comment">#4 &lt;java/lang/String&gt;</span></span><br><span class="line">22 dup</span><br><span class="line">23 ldc <span class="comment">#8 &lt;b&gt;</span></span><br><span class="line">25 invokespecial <span class="comment">#6 &lt;java/lang/String.&lt;init&gt;&gt;</span></span><br><span class="line">28 invokevirtual <span class="comment">#7 &lt;java/lang/StringBuilder.append&gt;</span></span><br><span class="line">31 invokevirtual <span class="comment">#9 &lt;java/lang/StringBuilder.toString&gt;</span></span><br><span class="line">34 astore_1</span><br><span class="line">35 <span class="built_in">return</span></span><br></pre></td></tr></table></figure>
<p>对象1：new StringBuilder()  在第1条指令中new声明</p>
<p>对象2：new String(“a”) 在第4条指令中new声明</p>
<p>对象3：字符串常量池中的”a” 第6条指令 ldc #5 <a></a></p>
<p>对象4：new String(“b”) 在第9条指令中new声明</p>
<p>对象5：字符串常量池中的”b” 第11条指令 ldc #8 <b></b></p>
<p>深入剖析一下：</p>
<p>先看看StringBuilder的源码，找到toString方法。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> String <span class="title">toString</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// Create a copy, don&#x27;t share the array</span></span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> String(value, <span class="number">0</span>, count);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>对象6：</p>
<p>在字节码第14条指令中，StringBuilder会将拼接之后的String数据toString一次，</p>
<p>其底层实现就是在堆中new了一个“ab”对象。所以这是第6个对象。</p>
<p>注意：==字符串常量池中并没有“ab”这个对象；==</p>
<h2 id="第一份代码："><a href="#第一份代码：" class="headerlink" title="第一份代码："></a>第一份代码：</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">    String s = <span class="keyword">new</span> String(<span class="string">&quot;1&quot;</span>);</span><br><span class="line">    s.intern();</span><br><span class="line">    String s2 = <span class="string">&quot;1&quot;</span>;</span><br><span class="line">    System.out.println(s == s2);</span><br><span class="line"></span><br><span class="line">    String s3 = <span class="keyword">new</span> String(<span class="string">&quot;1&quot;</span>) + <span class="keyword">new</span> String(<span class="string">&quot;1&quot;</span>);</span><br><span class="line">    s3.intern();</span><br><span class="line">    String s4 = <span class="string">&quot;11&quot;</span>;</span><br><span class="line">    System.out.println(s3 == s4);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>打印结果是</p>
<ul>
<li>jdk6 下<code>false false</code></li>
<li>jdk7 下<code>false true</code></li>
</ul>
<p>然后将<code>s3.intern();</code>语句下调一行，放到<code>String s4 = &quot;11&quot;;</code>后面。将<code>s.intern();</code> 放到<code>String s2 = &quot;1&quot;;</code>后面。是什么结果呢？</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">    String s = <span class="keyword">new</span> String(<span class="string">&quot;1&quot;</span>);</span><br><span class="line">    String s2 = <span class="string">&quot;1&quot;</span>;</span><br><span class="line">    s.intern();</span><br><span class="line">    System.out.println(s == s2);</span><br><span class="line"></span><br><span class="line">    String s3 = <span class="keyword">new</span> String(<span class="string">&quot;1&quot;</span>) + <span class="keyword">new</span> String(<span class="string">&quot;1&quot;</span>);</span><br><span class="line">    String s4 = <span class="string">&quot;11&quot;</span>;</span><br><span class="line">    s3.intern();</span><br><span class="line">    System.out.println(s3 == s4);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>打印结果为：</p>
<ul>
<li>jdk6 下<code>false false</code></li>
<li>jdk7 下<code>false false</code></li>
</ul>
<h3 id="jdk6中的解释："><a href="#jdk6中的解释：" class="headerlink" title="jdk6中的解释："></a>jdk6中的解释：</h3><p><img src="/essay/792ee381/1-jdk6.png"></p>
<p>注：图中绿色线条代表 string 对象的内容指向。 黑色线条代表地址指向。</p>
<p>如上图所示。首先说一下 jdk6中的情况，在 jdk6中上述的所有打印都是 false 的，因为 jdk6中的常量池是放在 Perm 区中的，Perm 区和正常的 JAVA Heap 区域是完全分开的。上面说过如果是使用引号声明的字符串都是会直接在字符串常量池中生成，而 new 出来的 String 对象是放在 JAVA Heap 区域。所以拿一个 JAVA Heap 区域的对象地址和字符串常量池的对象地址进行比较肯定是不相同的，即使调用<code>String.intern</code>方法也是没有任何关系的。</p>
<h3 id="jdk7中的解释："><a href="#jdk7中的解释：" class="headerlink" title="jdk7中的解释："></a>jdk7中的解释：</h3><p>在 Jdk6 以及以前的版本中，字符串的常量池是放在堆的 Perm 区的，Perm 区是一个类静态的区域，主要存储一些加载类的信息，常量池，方法片段等内容，默认大小只有4m，一旦常量池中大量使用 intern 是会直接产生<code>java.lang.OutOfMemoryError: PermGen space</code>错误的。 所以在 jdk7 的版本中，字符串常量池已经从 Perm 区移到正常的 Java Heap 区域了。</p>
<table>
<thead>
<tr>
<th>JDK1.6及以前</th>
<th>有永久代，静态变量存储在永久代上</th>
</tr>
</thead>
<tbody><tr>
<td>JDK1.7</td>
<td>有永久代，但已经逐步 “去永久代”，字符串常量池，静态变量移除，保存在堆中</td>
</tr>
<tr>
<td>JDK1.8</td>
<td>无永久代，类型信息，字段，方法，常量保存在本地内存的元空间，但字符串常量池、静态变量仍然在堆中。</td>
</tr>
</tbody></table>
<p><img src="/essay/792ee381/1-jdk7.png"></p>
<ul>
<li>在第一段代码中，先看 s3和s4字符串。<code>String s3 = new String(&quot;1&quot;) + new String(&quot;1&quot;);</code>，这句代码中现在生成了2最终个对象，是字符串常量池中的“1” 和 JAVA Heap 中的 s3引用指向的对象。中间还有2个匿名的<code>new String(&quot;1&quot;)</code>我们不去讨论它们。此时s3引用对象内容是”11”，但此时常量池中是没有 “11”对象的。</li>
<li>接下来<code>s3.intern();</code>这一句代码，是将 s3中的“11”字符串放入 String 常量池中，因为此时常量池中不存在“11”字符串，因此常规做法是跟 jdk6 图中表示的那样，在常量池中生成一个 “11” 的对象，关键点是 jdk7 中常量池不在 Perm 区域了，这块做了调整。常量池中不需要再存储一份对象了，可以直接存储堆中的引用。这份引用指向 s3 引用的对象。 也就是说引用地址是相同的。</li>
<li>最后<code>String s4 = &quot;11&quot;;</code> 这句代码中”11”是显示声明的，因此会直接去常量池中创建，创建的时候发现已经有这个对象了，此时也就是指向 s3 引用对象的一个引用。所以 s4 引用就指向和 s3 一样了。因此最后的比较 <code>s3 == s4</code> 是 true。</li>
<li>再看 s 和 s2 对象。 <code>String s = new String(&quot;1&quot;);</code> 第一句代码，生成了2个对象。常量池中的“1” 和 JAVA Heap 中的字符串对象。<code>s.intern();</code> 这一句是 s 对象去常量池中寻找后发现 “1” 已经在常量池里了。</li>
<li>接下来<code>String s2 = &quot;1&quot;;</code> 这句代码是生成一个 s2的引用指向常量池中的“1”对象。 结果就是 s 和 s2 的引用地址明显不同。图中画的很清晰。</li>
</ul>
<p><img src="/essay/792ee381/2-jdk7.png"></p>
<ul>
<li>来看第二段代码，从上边第二幅图中观察。第一段代码和第二段代码的改变就是 <code>s3.intern();</code> 的顺序是放在<code>String s4 = &quot;11&quot;;</code>后了。这样，首先执行<code>String s4 = &quot;11&quot;;</code>声明 s4 的时候常量池中是不存在“11”对象的，执行完毕后，“11“对象是 s4 声明产生的新对象。然后再执行<code>s3.intern();</code>时，常量池中“11”对象已经存在了，因此 s3 和 s4 的引用是不同的。</li>
<li>第二段代码中的 s 和 s2 代码中，<code>s.intern();</code>，这一句往后放也不会有什么影响了，因为对象池中在执行第一句代码<code>String s = new String(&quot;1&quot;);</code>的时候已经生成“1”对象了。下边的s2声明都是直接从常量池中取地址引用的。 s 和 s2 的引用地址是不会相等的。</li>
</ul>
<h2 id="小结-："><a href="#小结-：" class="headerlink" title="小结 ："></a>小结 ：</h2><p>从上述的例子代码可以看出 jdk7 版本对 intern 操作和常量池都做了一定的修改。主要包括2点：</p>
<ul>
<li>将String常量池 从 Perm 区移动到了 Java Heap区</li>
<li><code>String#intern</code> 方法时，==如果存在堆中的对象，会直接保存对象的引用，而不会重新创建对象。==</li>
</ul>
]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>String</tag>
      </tags>
  </entry>
  <entry>
    <title>mybatisplus配置文件</title>
    <url>/essay/mybatisplus-config.html</url>
    <content><![CDATA[<p>mybatisplus3.0.5配置文件</p>
<a id="more"></a>

<h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><p>mybatisplus 3.0.5</p>
<h2 id="依赖"><a href="#依赖" class="headerlink" title="依赖"></a>依赖</h2><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.baomidou<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>mybatis-plus-boot-starter<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.0.5<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.baomidou<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>mybatis-plus<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.0.5<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>


<h2 id="yml配置文件"><a href="#yml配置文件" class="headerlink" title="yml配置文件"></a>yml配置文件</h2><figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Mybatis-Plus 配置</span></span><br><span class="line"><span class="attr">mybatis-plus:</span></span><br><span class="line">  <span class="comment">#  mapper-locations: classpath:/mapper/*Mapper.xml</span></span><br><span class="line">  <span class="comment">#实体扫描，多个package用逗号或者分号分隔</span></span><br><span class="line">  <span class="attr">typeAliasesPackage:</span> <span class="string">com.mybatis.demo.domain</span></span><br><span class="line">  <span class="attr">global-config:</span></span><br><span class="line">    <span class="attr">db-config:</span></span><br><span class="line">      <span class="attr">id-type:</span> <span class="string">none</span></span><br><span class="line">      <span class="attr">table-underline:</span> <span class="literal">false</span></span><br><span class="line">    <span class="attr">refresh:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">configuration:</span></span><br><span class="line">    <span class="attr">map-underscore-to-camel-case:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">cache-enabled:</span> <span class="literal">true</span> <span class="comment">#配置的缓存的全局开关</span></span><br><span class="line">    <span class="attr">lazyLoadingEnabled:</span> <span class="literal">true</span> <span class="comment">#延时加载的开关</span></span><br><span class="line">    <span class="attr">multipleResultSetsEnabled:</span> <span class="literal">true</span> <span class="comment">#开启延时加载，否则按需加载属性</span></span><br><span class="line">    <span class="attr">log-impl:</span> <span class="string">org.apache.ibatis.logging.stdout.StdOutImpl</span> <span class="comment">#打印sql语句,调试用</span></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>后端</category>
        <category>mybatis</category>
      </categories>
      <tags>
        <tag>mybatis</tag>
      </tags>
  </entry>
  <entry>
    <title>mysql性能优化</title>
    <url>/essay/d9f1b207.html</url>
    <content><![CDATA[<h1 id="MySQL性能优化"><a href="#MySQL性能优化" class="headerlink" title="MySQL性能优化"></a>MySQL性能优化</h1><p>优化有风险，涉足需谨慎！</p>
<a id="more"></a>

<h2 id="优化介绍"><a href="#优化介绍" class="headerlink" title="优化介绍"></a>优化介绍</h2><h3 id="优化要考虑的问题"><a href="#优化要考虑的问题" class="headerlink" title="优化要考虑的问题"></a>优化要考虑的问题</h3><h4 id="优化可能带来的问题"><a href="#优化可能带来的问题" class="headerlink" title="优化可能带来的问题"></a>优化可能带来的问题</h4><ul>
<li>优化不总是对一个单纯的环境进行，还很可能是一个复杂的已投产的系统！</li>
<li>优化手段有很大的风险，一定要意识到和预见到！</li>
<li>任何的技术可以解决一个问题，但必然存在带来一个问题的风险！</li>
<li>对于优化来说调优而带来的问题,控制在可接受的范围内才是有成果。</li>
<li>保持现状或出现更差的情况都是失败！</li>
</ul>
<h4 id="优化的需求"><a href="#优化的需求" class="headerlink" title="优化的需求"></a>优化的需求</h4><ul>
<li>稳定性和业务可持续性,通常比性能更重要！</li>
<li>优化不可避免涉及到变更，变更就有风险！</li>
<li>优化使性能变好，维持和变差是等概率事件！</li>
<li>优化应该是各部门协同，共同参与的工作，任何单一部门都不能对数据库进行优化！</li>
</ul>
<p><strong>不要为了优化而去优化，优化工作,是由业务需要驱使的</strong></p>
<h4 id="优化由谁参与"><a href="#优化由谁参与" class="headerlink" title="优化由谁参与"></a>优化由谁参与</h4><p>在进行数据库优化时，应由数据库管理员、业务部门代表、应用程序架构师、应用程序设计人员、应用程序开发人员、硬件及系统管理员、存储管理员等，业务相关人员共同参与。</p>
<h3 id="优化的思路"><a href="#优化的思路" class="headerlink" title="优化的思路"></a>优化的思路</h3><h4 id="优化的方向"><a href="#优化的方向" class="headerlink" title="优化的方向"></a>优化的方向</h4><p>在数据库优化上有两个主要方向：即安全与性能。</p>
<ul>
<li>安全 —&gt; 数据安全性</li>
<li>性能 —&gt; 数据的高性能访问</li>
</ul>
<h4 id="优化的维度"><a href="#优化的维度" class="headerlink" title="优化的维度"></a>优化的维度</h4><img src="/essay/d9f1b207/weidu.jpg" style="zoom:80%;">

<p><strong>硬件：</strong> CPU、内存、存储、网络设备等</p>
<p><strong>系统配置：</strong> 服务器系统、数据库服务参数等</p>
<p><strong>数据库表结构：</strong> 高可用、分库分表、读写分离、存储引擎、表设计等</p>
<p><strong>Sql及索引：</strong> sql语句、索引使用等</p>
<ul>
<li>从优化成本进行考虑：硬件&gt;系统配置&gt;数据库表结构&gt;SQL及索引</li>
<li>从优化效果进行考虑：硬件&lt;系统配置&lt;数据库表结构&lt;SQL及索引</li>
</ul>
<h4 id="优化的工具"><a href="#优化的工具" class="headerlink" title="优化的工具"></a>优化的工具</h4><p><strong>检查问题常用工具</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">msyqladmin      #mysql客户端，可进行管理操作  </span><br><span class="line">mysqlshow       #功能强大的查看shell命令  </span><br><span class="line">show [SESSION | GLOBAL] variables   #查看数据库参数信息  </span><br><span class="line">SHOW [SESSION | GLOBAL] STATUS      #查看数据库的状态信息  </span><br><span class="line">SHOW ENGINE INNODB STATUS Innodb    #引擎的所有状态  </span><br><span class="line">information_schema  #获取元数据的方法</span><br><span class="line">SHOW PROCESSLIST    #查看当前所有连接session状态  </span><br><span class="line">explain     #获取查询语句的执行计划</span><br><span class="line">how index   #查看表的索引信息  </span><br><span class="line">slow-log    #记录慢查询语句  </span><br><span class="line">mysqldumpslow   #分析slowlog文件的 </span><br></pre></td></tr></table></figure>
<p><strong>不常用但好用的工具</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">zabbix      #监控主机、系统、数据库（部署zabbix监控平台）</span><br><span class="line">mysqlslap   #分析慢日志</span><br><span class="line">sysbench    #压力测试工具</span><br><span class="line">workbench   #管理、备份、监控、分析、优化工具（比较费资源）</span><br><span class="line">pt-query-digest #分析慢日志</span><br><span class="line">mysql profiling #统计数据库整体状态工具</span><br><span class="line">Performance Schema mysql    #性能状态统计的数据</span><br></pre></td></tr></table></figure>
<h4 id="数据库使用优化思路"><a href="#数据库使用优化思路" class="headerlink" title="数据库使用优化思路"></a>数据库使用优化思路</h4><p>一般情况下，我们进行数据库层面的优化就可以了</p>
<p><strong>应急调优的思路：</strong></p>
<p>针对突然的业务办理卡顿，无法进行正常的业务处理！需要立马解决的场景！</p>
<ol>
<li>show processlist（查看链接session状态）</li>
<li>explain(分析查询计划)，show index from table（分析索引）</li>
<li>通过执行计划判断，索引问题（有没有、合不合理）或者语句本身问题</li>
<li>show status like ‘%lock%’; # 查询锁状态</li>
<li>SESSION_ID; # 杀掉有问题的session</li>
</ol>
<p><strong>常规调优的思路：</strong></p>
<p>针对业务周期性的卡顿，例如在每天10-11点业务特别慢，但是还能够使用，过了这段时间就好了。</p>
<ol>
<li>查看slowlog，分析slowlog，分析出查询慢的语句。</li>
<li>按照一定优先级，进行一个一个的排查所有慢语句。</li>
<li>分析top sql，进行explain调试，查看语句执行时间。</li>
<li>调整索引或语句本身。</li>
</ol>
<h2 id="查询优化"><a href="#查询优化" class="headerlink" title="查询优化"></a>查询优化</h2><h3 id="查询流程"><a href="#查询流程" class="headerlink" title="查询流程"></a>查询流程</h3><p>① 客户端将查询发送到服务器；</p>
<p>② 服务器检查查询缓存，如果找到了，就从缓存中返回结果，否则进行下一步。</p>
<p>③ 服务器解析，预处理。</p>
<p>④ 查询优化器优化查询</p>
<p>⑤ 生成执行计划，执行引擎调用存储引擎API执行查询</p>
<p>⑥服务器将结果发送回客户端。</p>
<img src="/essay/d9f1b207/query.jpg" style="zoom:80%;">

<p><strong>查询缓存</strong> 在解析一个查询语句之前，如果查询缓存是打开的，那么MySQL会优先检查这个查询是否命中查询缓存中的数据，如果命中缓存直接从缓存中拿到结果并返回给客户端。这种情况下，查询不会被解析，不用生成执行计划，不会被执行。</p>
<p><strong>语法解析和预处理器</strong> MySQL通过关键字将SQL语句进行解析，并生成一棵对应的“解析树”。MySQL解析器将使用MySQL语法规则验证和解析查询。</p>
<p><strong>查询优化器</strong> 语法书被校验合法后由优化器转成查询计划，一条语句可以有很多种执行方式，最后返回相同的结果。优化器的作用就是找到这其中最好的执行计划。</p>
<p><strong>查询执行引擎</strong> 在解析和优化阶段，MySQL将生成查询对应的执行计划，MySQL的查询执行引擎则根据这个执行计划来完成整个查询。最常使用的也是比较最多的引擎是MyISAM引擎和InnoDB引擎。mysql5.5开始的默认存储引擎已经变更为innodb了。</p>
<p><strong>EXPLAIN 分析查询，通过定位分析性能的瓶颈，才能更好的优化数据库系统的性能</strong></p>
<h3 id="查询优化-1"><a href="#查询优化-1" class="headerlink" title="查询优化"></a>查询优化</h3><h4 id="慢查询"><a href="#慢查询" class="headerlink" title="慢查询"></a>慢查询</h4><ul>
<li><strong>慢查询日志开启</strong></li>
</ul>
<p>在配置文件my.cnf或my.ini中在[mysqld]一行下面加入两个配置参数</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">log-slow-queries&#x3D;&#x2F;data&#x2F;mysqldata&#x2F;slow-query.log</span><br><span class="line">long_query_time&#x3D;5</span><br></pre></td></tr></table></figure>
<p>log-slow-queries参数为慢查询日志存放的位置，一般这个目录要有mysql的运行帐号的可写权限，一般都将这个目录设置为mysql的数据存放目录；</p>
<p>long_query_time=5中的5表示查询超过五秒才记录；</p>
<p>还可以在my.cnf或者my.ini中添加log-queries-not-using-indexes参数，表示记录下没有使用索引的查询。</p>
<ul>
<li><strong>慢查询分析</strong></li>
</ul>
<p>我们可以通过打开log文件查看得知哪些SQL执行效率低下 ，从日志中，可以发现查询时间超过5 秒的SQL，而小于5秒的没有出现在此日志中。</p>
<p>如果慢查询日志中记录内容很多，可以使用mysqldumpslow工具（MySQL客户端安装自带）来对慢查询日志进行分类汇总。mysqldumpslow对日志文件进行了分类汇总，显示汇总后摘要结果。</p>
<p>进入log的存放目录，运行：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@mysql_data]# mysqldumpslow slow-query.log</span><br><span class="line">Reading mysql slow query log fromslow-query.log</span><br><span class="line">Count: 2 Time&#x3D;11.00s (22s) Lock&#x3D;0.00s (0s)Rows&#x3D;1.0 (2), root[root]@mysql</span><br><span class="line">select count(N) from t_user; </span><br></pre></td></tr></table></figure>
<p>mysqldumpslow命令</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;path&#x2F;mysqldumpslow -s c -t 10&#x2F;database&#x2F;mysql&#x2F;slow-query.log</span><br></pre></td></tr></table></figure>
<p>这会输出记录次数最多的10条SQL语句，其中：</p>
<p>-s, 是表示按照何种方式排序，c、t、l、r分别是按照记录次数、时间、查询时间、返回的记录数来排序，ac、at、al、ar，表示相应的倒叙</p>
<p>-t, 是top n的意思，即为返回前面多少条的数据；</p>
<p>-g, 后边可以写一个正则匹配模式，大小写不敏感的；</p>
<p>例如：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;path&#x2F;mysqldumpslow -s r -t 10&#x2F;database&#x2F;mysql&#x2F;slow-log</span><br></pre></td></tr></table></figure>
<p>得到返回记录集最多的10个查询。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;path&#x2F;mysqldumpslow -s t -t 10 -g “leftjoin” &#x2F;database&#x2F;mysql&#x2F;slow-log</span><br></pre></td></tr></table></figure>
<p>得到按照时间排序的前10条里面含有左连接的查询语句。</p>
<p>使用mysqldumpslow命令可以非常明确的得到各种我们需要的查询语句，对MySQL查询语句的监控、分析、优化是MySQL优化非常重要的一步。开启慢查询日志后，由于日志记录操作，在一定程度上会占用CPU资源影响mysql的性能，但是可以阶段性开启来定位性能瓶颈。</p>
<h4 id="EXPLAIN"><a href="#EXPLAIN" class="headerlink" title="EXPLAIN"></a>EXPLAIN</h4><p>EXPLAIN可以帮助开发人员分析SQL问题，EXPLAIN显示了MySQL如何使用使用SQL执行计划，可以帮助开发人员写出更优化的查询语句。使用方法，在select语句前加上Explain就可以了：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">EXPLAIN SELECT * FROM products</span><br></pre></td></tr></table></figure>
<p><strong>1) id</strong></p>
<p>SELECT识别符。这是SELECT查询序列号。这个不重要</p>
<p><strong>2) select_type</strong></p>
<p>表示SELECT语句的类型。</p>
<ol>
<li>simple:简单select（不使用union或子查询）。</li>
<li>primary:最外面的select。</li>
<li>union:union中的第二个或后面的select语句。</li>
<li>dependent union:union中的第二个或后面的select语句，取决于外面的查询。</li>
<li>union result:union的结果。</li>
<li>subquery:子查询中的第一个select。</li>
<li>dependent subquery:子查询中的第一个select，取决于外面的查询。</li>
<li>derived:导出表的select（from子句的子查询）。</li>
</ol>
<p><strong>3) table</strong></p>
<p>显示这查询的数据是关于哪张表的。</p>
<p><strong>4) type</strong></p>
<p>区间索引，这是重要的列，显示连接使用了何种类型。从最好到最差的连接类型为：</p>
<p>system &gt; const &gt; eq_ref &gt; ref &gt; ref_or_null &gt; index_merge &gt; unique_subquery &gt; index_subquery &gt; range &gt; index &gt; ALL</p>
<p>一般来说，得保证查询至少达到range级别,最好能达到ref。</p>
<ol>
<li><strong>system</strong>：表仅有一行，这是const类型的特列，平时不会出现，这个也可以忽略不计。</li>
<li><strong>const</strong>：数据表最多只有一个匹配行，因为只匹配一行数据，所以很快</li>
<li><strong>eq_ref</strong>：mysql手册是这样说的:”对于每个来自于前面的表的行组合，从该表中读取一行。这可能是最好的联接类型，除了const类型。它用在一个索引的所有部分被联接使用并且索引是UNIQUE或PRIMARY KEY”。eq_ref可以用于使用=比较带索引的列。</li>
<li><strong>ref</strong>：查询条件索引既不是UNIQUE也不是PRIMARY KEY的情况。ref可用于=或&lt;或&gt;操作符的带索引的列。</li>
<li><strong>ref_or_null</strong>：该联接类型如同ref，但是添加了MySQL可以专门搜索包含NULL值的行。在解决子查询中经常使用该联接类型的优化。</li>
<li><strong>index_merge</strong>：该联接类型表示使用了索引合并优化方法。在这种情况下，key列包含了使用的索引的清单，key_len包含了使用的索引的最长的关键元素。</li>
<li><strong>unique_subquery</strong>：该类型替换了下面形式的IN子查询的ref: value IN (SELECT primary_key FROM single_table WHERE some_expr) unique_subquery是一个索引查找函数,可以完全替换子查询,效率更高。</li>
<li><strong>index_subquery</strong>：该联接类型类似于unique_subquery。可以替换IN子查询,但只适合下列形式的子查询中的非唯一索引: value IN (SELECT key_column FROM single_table WHERE some_expr)</li>
<li><strong>range</strong>：只检索给定范围的行,使用一个索引来选择行。</li>
<li><strong>index</strong>：该联接类型与ALL相同,除了只有索引树被扫描。这通常比ALL快,因为索引文件通常比数据文件小。</li>
<li><strong>ALL</strong>：对于每个来自于先前的表的行组合,进行完整的表扫描。（性能最差）</li>
</ol>
<p><strong>5)possible_keys</strong></p>
<p>指出MySQL能使用哪个索引在该表中找到行。如果是空的，没有相关的索引。这时要提高性能，可通过检验WHERE子句，看是否引用某些字段，或者检查字段不是适合索引。</p>
<p><strong>6) key</strong></p>
<p>实际使用到的索引。如果为NULL，则没有使用索引。如果为primary的话，表示使用了主键。</p>
<p><strong>7) key_len</strong></p>
<p>最长的索引宽度。如果键是NULL，长度就是NULL。在不损失精确性的情况下，长度越短越好。</p>
<p><strong>8) ref</strong></p>
<p>显示使用哪个列或常数与key一起从表中选择行。</p>
<p><strong>9) rows</strong></p>
<p>显示MySQL认为它执行查询时必须检查的行数。</p>
<p><strong>10) Extra</strong></p>
<p>执行状态说明，该列包含MySQL解决查询的详细信息</p>
<ul>
<li>Distinct:MySQL发现第1个匹配行后,停止为当前的行组合搜索更多的行。</li>
<li>Not exists:MySQL能够对查询进行LEFT JOIN优化,发现1个匹配LEFT JOIN标准的行后,不再为前面的的行组合在该表内检查更多的行。</li>
<li>range checked for each record (index map: #):MySQL没有发现好的可以使用的索引,但发现如果来自前面的表的列值已知,可能部分索引可以使用。</li>
<li>Using filesort:MySQL需要额外的一次传递,以找出如何按排序顺序检索行。</li>
<li>Using index:从只使用索引树中的信息而不需要进一步搜索读取实际的行来检索表中的列信息。</li>
<li>Using temporary:为了解决查询,MySQL需要创建一个临时表来容纳结果。</li>
<li>Using where:WHERE 子句用于限制哪一个行匹配下一个表或发送到客户。</li>
<li>Using sort_union(…), Using union(…), Using intersect(…):这些函数说明如何为index_merge联接类型合并索引扫描。</li>
<li>Using index for group-by:类似于访问表的Using index方式,Using index for group-by表示MySQL发现了一个索引,可以用来查 询GROUP BY或DISTINCT查询的所有列,而不要额外搜索硬盘访问实际的表。</li>
</ul>
<h2 id="索引优化"><a href="#索引优化" class="headerlink" title="索引优化"></a>索引优化</h2><h3 id="索引的类型"><a href="#索引的类型" class="headerlink" title="索引的类型"></a>索引的类型</h3><ol>
<li><p><strong>主键索引 PRIMARY KEY</strong></p>
<p>它是一种特殊的唯一索引，不允许有空值。一般是在建表的时候同时创建主键索引。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">PRIMARY KEY (&#96;id&#96;)</span><br></pre></td></tr></table></figure></li>
<li><p><strong>唯一索引 UNIQUE</strong></p>
<p>唯一索引列的值必须唯一，但允许有空值。如果是组合索引，则列值的组合必须唯一。可以在创建表的时候指定，也可以修改表结构。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">UNIQUE KEY &#96;num&#96; (&#96;number&#96;) USING BTREE</span><br></pre></td></tr></table></figure></li>
<li><p><strong>普通索引 INDEX</strong></p>
<p>这是最基本的索引，它没有任何限制。可以在创建表的时候指定，也可以修改表结构</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">KEY &#96;num&#96; (&#96;number&#96;) USING BTREE</span><br></pre></td></tr></table></figure></li>
<li><p><strong>组合索引 INDEX</strong></p>
<p>索引分单列索引和组合索引(联合索引)。单列索引，即一个索引只包含单个列，一个表可以有多个单列索引，但这不是组合索引。组合索引，即一个索引包含多个列。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">KEY &#96;num&#96; (&#96;number&#96;,&#96;name&#96;) USING BTREE</span><br></pre></td></tr></table></figure>
<p>注意，组合索引前面索引必须要先使用，后面的索引才能使用。</p>
</li>
<li><p><strong>全文索引 FULLTEXT</strong></p>
<p>全文索引（也称全文检索）是目前搜索引擎使用的一种关键技术。它能够利用分词技术等多种算法智能分析出文本文字中关键字词的频率及重要性，然后按照一定的算法规则智能地筛选出我们想要的搜索结果。</p>
</li>
</ol>
<h3 id="索引的存储结构"><a href="#索引的存储结构" class="headerlink" title="索引的存储结构"></a>索引的存储结构</h3><h4 id="BTree索引"><a href="#BTree索引" class="headerlink" title="BTree索引"></a>BTree索引</h4><p><strong>MySQL中普遍使用B+Tree做索引，也就是BTREE。</strong></p>
<p><strong>特点：</strong></p>
<ul>
<li>BTREE索引以B+树的结构存储数据</li>
<li>BTREE索引能够加快数据的查询速度</li>
<li>BTREE索引更适合进行行范围查找</li>
</ul>
<p><strong>使用的场景：</strong></p>
<ol>
<li>全值匹配的查询，例如根据订单号查询 order_sn=’98764322119900’</li>
<li>联合索引时会遵循最左前缀匹配的原则,即最左优先</li>
<li>匹配列前缀查询，例如：order_sn like ‘9876%’</li>
<li>匹配范围值的查找，例如：order_sn &gt; ‘98764322119900’</li>
<li>只访问索引的查询</li>
</ol>
<h4 id="哈希索引"><a href="#哈希索引" class="headerlink" title="哈希索引"></a>哈希索引</h4><p>Hash索引在MySQL中使用的并不是很多，目前主要是Memory存储引擎使用，在Memory存储引擎中将Hash索引作为默认的索引类型。所谓Hash索引，实际上就是通过一定的Hash算法，将需要索引的键值进行Hash运算，然后将得到的Hash值存入一个Hash表中。然后每次需要检索的时候，都会将检索条件进行相同算法的Hash运算，然后再和Hash表中的Hash值进行比较并得出相应的信息。</p>
<p>特点：</p>
<ul>
<li>Hash索引仅仅只能满足“=”,“IN”和“&lt;=&gt;”查询，不能使用范围查询；</li>
<li>Hash索引无法被利用来避免数据的排序操作；</li>
<li>Hash索引不能利用部分索引键查询；</li>
<li>Hash索引在任何时候都不能避免表扫描；</li>
<li>Hash索引遇到大量Hash值相等的情况后性能并不一定就会比B-Tree索引高；</li>
</ul>
<h4 id="Full-text全文索引"><a href="#Full-text全文索引" class="headerlink" title="Full-text全文索引"></a>Full-text全文索引</h4><p>Full-text索引也就是我们常说的全文索引，MySQL中仅有MyISAM和InnoDB存储引擎支持。</p>
<p>对于文本的大对象，或者较大的CHAR类型的数据，如果使用普通索引，那么匹配文本前几个字符还是可行的，但是想要匹配文本中间的几个单词，那么就要使用LIKE %word%来匹配，这样需要很长的时间来处理，响应时间会大大增加，这种情况，就可使用时FULLTEXT索引了，在生成Full-text索引时，会为文本生成一份单词的清单，在索引时根据这个单词的清单来索引。</p>
<p>注意：</p>
<ul>
<li>对于较大的数据集，把数据添加到一个没有Full-text索引的表，然后添加Full-text索引的速度比把数据添加到一个已经有Full-text索引的表快。</li>
<li>针对较大的数据，生成全文索引非常的消耗时间和空间。</li>
<li>5.6版本前的MySQL自带的全文索引只能用于MyISAM存储引擎，如果是其它数据引擎，那么全文索引不会生效。5.6版本和之后InnoDB存储引擎开始支持全文索引。</li>
<li>在MySQL中，全文索引支队英文有用，目前对中文还不支持。5.7版本之后通过使用ngram插件开始支持中文。</li>
<li>在MySQL中，如果检索的字符串太短则无法检索得到预期的结果，检索的字符串长度至少为4字节。</li>
</ul>
<h3 id="索引的使用"><a href="#索引的使用" class="headerlink" title="索引的使用"></a>索引的使用</h3><p>虽然索引能够为查找带来速度上的提升，但是也会对性能有一些损失。</p>
<ul>
<li>索引会增加写操作的成本</li>
<li>太多的索引会增加查询优化器的选择时间</li>
</ul>
<p>当创建索引带来的好处多过于消耗的时候，才是最优的选择~</p>
<p><strong>使用索引的场景</strong></p>
<ul>
<li>主键自动建立唯一索引；</li>
<li>经常作为查询条件在WHERE或者ORDER BY 语句中出现的列要建立索引；</li>
<li>作为排序的列要建立索引；</li>
<li>查询中与其他表关联的字段，外键关系建立索引</li>
<li>高并发条件下倾向建立组合索引；</li>
<li>用于聚合函数的列可以建立索引，例如使用count(number)时，number列就要建立索引</li>
</ul>
<p><strong>不使用索引的场景</strong></p>
<ul>
<li>有大量重复的列不单独建立索引</li>
<li>表记录太少不要建立索引，因为没有太大作用。</li>
<li>不会作为查询的列不要建立索引</li>
</ul>
<h2 id="存储优化"><a href="#存储优化" class="headerlink" title="存储优化"></a>存储优化</h2><h3 id="存储引擎介绍"><a href="#存储引擎介绍" class="headerlink" title="存储引擎介绍"></a>存储引擎介绍</h3><h4 id="InnoDB存储引擎"><a href="#InnoDB存储引擎" class="headerlink" title="InnoDB存储引擎"></a>InnoDB存储引擎</h4><p><strong>特点：</strong></p>
<ol>
<li><p>InnoDB存储引擎提供了具有提交、回滚和崩溃恢复能力的事务安全。相比较MyISAM存储引擎，InnoDB写的处理效率差一点并且会占用更多的磁盘空间保留数据和索引。</p>
</li>
<li><p>提供了对数据库事务ACID（原子性Atomicity、一致性Consistency、隔离性Isolation、持久性Durability）的支持，实现了SQL标准的四种隔离级别。</p>
</li>
<li><p>设计目标就是处理大容量的数据库系统，MySQL运行时InnoDB会在内存中建立缓冲池，用于缓冲数据和索引。</p>
</li>
<li><p>执行“select count(*) from table”语句时需要扫描全表，因为使用innodb引擎的表不会保存表的具体行数，所以需要扫描整个表才能计算多少行。</p>
</li>
<li><p>InnoDB引擎是行锁，粒度更小，所以写操作不会锁定全表，在并发较高时，使用InnoDB会提升效率。即存在大量UPDATE/INSERT操作时，效率较高。</p>
</li>
<li><p>InnoDB清空数据量大的表时，是非常缓慢，这是因为InnoDB必须处理表中的每一行，根据InnoDB的事务设计原则，首先需要把“删除动作”写入“事务日志”，然后写入实际的表。所以，清空大表的时候，最好直接drop table然后重建。即InnoDB一行一行删除，不会重建表。</p>
</li>
</ol>
<p><strong>使用场景：</strong></p>
<ol>
<li>经常UPDETE/INSERT的表，使用处理多并发的写请求</li>
<li>支持事务，必选InnoDB。</li>
<li>可以从灾难中恢复（日志+事务回滚）</li>
<li>外键约束、列属性AUTO_INCREMENT支持</li>
</ol>
<h4 id="MyISAM存储引擎"><a href="#MyISAM存储引擎" class="headerlink" title="MyISAM存储引擎"></a><strong>MyISAM</strong>存储引擎</h4><p><strong>特点：</strong></p>
<ol>
<li><p>MyISAM不支持事务，不支持外键，SELECT/INSERT为主的应用可以使用该引擎。</p>
</li>
<li><p>每个MyISAM在存储成3个文件，扩展名分别是：</p>
</li>
</ol>
<p>　　1) frm：存储表定义（表结构等信息）</p>
<p>　　2) MYD(MYData)，存储数据</p>
<p>　　3) MYI(MYIndex)，存储索引</p>
<ol>
<li><p>不同MyISAM表的索引文件和数据文件可以放置到不同的路径下。</p>
</li>
<li><p>MyISAM类型的表提供修复的工具，可以用CHECK TABLE语句来检查MyISAM表健康，并用REPAIR TABLE语句修复一个损坏的MyISAM表。</p>
</li>
<li><p>在MySQL5.6以前，只有MyISAM支持Full-text全文索引</p>
</li>
</ol>
<p><strong>使用场景：</strong></p>
<ol>
<li>经常SELECT/INSERT的表，插入不频繁，查询非常频繁</li>
<li>不支持事务</li>
<li>做很多count 的计算。</li>
</ol>
<h4 id="MyISAM和Innodb区别"><a href="#MyISAM和Innodb区别" class="headerlink" title="MyISAM和Innodb区别"></a>MyISAM和Innodb区别</h4><p>nnoDB和MyISAM是许多人在使用MySQL时最常用的两个存储引擎，这两个存储引擎各有优劣，视具体应用而定。基本的差别为：MyISAM类型不支持事务处理，而InnoDB类型支持。MyISAM类型强调的是性能，其执行速度比InnoDB类型更快，而InnoDB提供事务支持已经外部键等高级数据库功能。</p>
<p><strong>具体实现的差别：</strong></p>
<ul>
<li><p>MyISAM是非事务安全型的，而InnoDB是事务安全型的。</p>
</li>
<li><p>MyISAM锁的粒度是表级，而InnoDB支持行级锁定。</p>
</li>
<li><p>MyISAM不支持外键，而InnoDB支持外键</p>
</li>
<li><p>MyISAM相对简单，所以在效率上要优于InnoDB，小型应用可以考虑使用MyISAM。</p>
</li>
<li><p>InnoDB表比MyISAM表更安全。</p>
</li>
</ul>
<h3 id="存储优化-1"><a href="#存储优化-1" class="headerlink" title="存储优化"></a>存储优化</h3><h4 id="禁用索引"><a href="#禁用索引" class="headerlink" title="禁用索引"></a>禁用索引</h4><p>对于使用索引的表，插入记录时，MySQL会对插入的记录建立索引。如果插入大量数据，建立索引会降低插入数据速度。为了解决这个问题，可以在批量插入数据之前禁用索引，数据插入完成后再开启索引。</p>
<p>禁用索引的语句： </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ALTER TABLE table_name DISABLE KEYS </span><br></pre></td></tr></table></figure>
<p>开启索引语句： </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ALTER TABLE table_name ENABLE KEYS</span><br></pre></td></tr></table></figure>
<p>MyISAM对于空表批量插入数据，则不需要进行操作，因为MyISAM引擎的表是在导入数据后才建立索引。</p>
<h4 id="禁用唯一性检查"><a href="#禁用唯一性检查" class="headerlink" title="禁用唯一性检查"></a>禁用唯一性检查</h4><p>唯一性校验会降低插入记录的速度，可以在插入记录之前禁用唯一性检查，插入数据完成后再开启。</p>
<p>禁用唯一性检查的语句：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SET UNIQUE_CHECKS &#x3D; 0; </span><br></pre></td></tr></table></figure>
<p>开启唯一性检查的语句：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SET UNIQUE_CHECKS &#x3D; 1;</span><br></pre></td></tr></table></figure>
<h4 id="批量插入数据"><a href="#批量插入数据" class="headerlink" title="批量插入数据"></a>批量插入数据</h4><p>插入数据时，可以使用一条INSERT语句插入一条数据，也可以插入多条数据。</p>
<h4 id="禁止自动提交"><a href="#禁止自动提交" class="headerlink" title="禁止自动提交"></a>禁止自动提交</h4><p>插入数据之前执行禁止事务的自动提交，数据插入完成后再恢复，可以提高插入速度。</p>
<p>禁用：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SET autocommit &#x3D; 0;</span><br></pre></td></tr></table></figure>
<p> 开启：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SET autocommit &#x3D; 1;</span><br></pre></td></tr></table></figure>
<h2 id="数据库结构优化"><a href="#数据库结构优化" class="headerlink" title="数据库结构优化"></a>数据库结构优化</h2><h3 id="优化表结构"><a href="#优化表结构" class="headerlink" title="优化表结构"></a>优化表结构</h3><ul>
<li>尽量将表字段定义为NOT NULL约束，这时由于在MySQL中含有空值的列很难进行查询优化，NULL值会使索引以及索引的统计信息变得很复杂。</li>
<li>对于只包含特定类型的字段，可以使用enum、set 等数据类型。</li>
<li>数值型字段的比较比字符串的比较效率高得多，字段类型尽量使用最小、最简单的数据类型。例如IP地址可以使用int类型。</li>
<li>尽量使用TINYINT、SMALLINT、MEDIUM_INT作为整数类型而非INT，如果非负则加上UNSIGNED。但对整数类型指定宽度，比如INT(11)，没有任何用，因为指定的类型标识范围已经确定。</li>
<li>VARCHAR的长度只分配真正需要的空间</li>
<li>尽量使用TIMESTAMP而非DATETIME，但TIMESTAMP只能表示1970 - 2038年，比DATETIME表示的范围小得多，而且TIMESTAMP的值因时区不同而不同。</li>
<li>单表不要有太多字段，建议在20以内</li>
<li>合理的加入冗余字段可以提高查询速度。</li>
</ul>
<h3 id="表拆分"><a href="#表拆分" class="headerlink" title="表拆分"></a>表拆分</h3><h4 id="垂直拆分"><a href="#垂直拆分" class="headerlink" title="垂直拆分"></a>垂直拆分</h4><p>垂直拆分按照字段进行拆分，其实就是把组成一行的多个列分开放到不同的表中，这些表具有不同的结构，拆分后的表具有更少的列。例如用户表中的一些字段可能经常访问，可以把这些字段放进一张表里。另外一些不经常使用的信息就可以放进另外一张表里。</p>
<p>插入的时候使用事务，也可以保证两表的数据一致。缺点也很明显，由于拆分出来的两张表存在一对一的关系，需要使用冗余字段，而且需要join操作。但是我们可以在使用的时候可以分别取两次，这样的来说既可以避免join操作，又可以提高效率。</p>
<h4 id="水平拆分"><a href="#水平拆分" class="headerlink" title="水平拆分"></a>水平拆分</h4><p>水平拆分按照行进行拆分，常见的就是分库分表。以用户表为例，可以取用户ID，然后对ID取10的余数，将用户均匀的分配进这 0-9这10个表中。查找的时候也按照这种规则，又快又方便。</p>
<p>有些表业务关联比较强，那么可以使用按时间划分的。例如每天的数据量很大，需要每天新建一张表。这种业务类型就是需要高速插入，但是对于查询的效率不太关心。表越大，插入数据所需要索引维护的时间也就越长。</p>
<h3 id="表分区"><a href="#表分区" class="headerlink" title="表分区"></a>表分区</h3><p>分区适用于例如日志记录，查询少。一般用于后台的数据报表分析。对于这些数据汇总需求，需要很多日志表去做数据聚合，我们能够容忍1s到2s的延迟，只要数据准确能够满足需求就可以。</p>
<p>MySQL主要支持4种模式的分区：range分区、list预定义列表分区，hash 分区，key键值分区。</p>
<p>录入使用key键值分区：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">CREATE TABLE &#96;test2&#96; (</span><br><span class="line">  &#96;id&#96; int(20) NOT NULL AUTO_INCREMENT COMMENT &#39;ID&#39;,</span><br><span class="line">  &#96;name&#96; varchar(100) DEFAULT NULL COMMENT &#39;名称&#39;,</span><br><span class="line">  &#96;state&#96; int(1) DEFAULT NULL COMMENT &#39;状态&#39;,</span><br><span class="line">  PRIMARY KEY (&#96;id&#96;)</span><br><span class="line">) ENGINE&#x3D;InnoDB DEFAULT CHARSET&#x3D;utf8</span><br><span class="line">PARTITION BY KEY (id)</span><br><span class="line">PARTITIONS 10;</span><br></pre></td></tr></table></figure>
<h3 id="读写分离"><a href="#读写分离" class="headerlink" title="读写分离"></a>读写分离</h3><p>大型网站会有大量的并发访问，如果还是传统的数据存储方案，只是靠一台服务器处理，如此多的数据库连接、读写操作，数据库必然会崩溃，数据丢失的话，后果更是不堪设想。这时候，我们需要考虑如何降低单台服务器的使用压力，提升整个数据库服务的承载能力。</p>
<p>我们发现一般情况对数据库而言都是“读多写少”，也就说对数据库读取数据的压力比较大，这样分析可以采用数据库集群的方案。其中一个是主库，负责写入数据，我们称为写库；其它都是从库，负责读取数据，我们称为读库。这样可以缓解一台服务器的访问压力。</p>
<p>MySql自带主从复制功能，我们可以使用主从复制的主库作为写库，从库和主库进行数据同步，那么可以使用多个从库作为读库，已完成读写分离的效果。</p>
<h3 id="数据库集群"><a href="#数据库集群" class="headerlink" title="数据库集群"></a>数据库集群</h3><p>如果访问量非常大，虽然使用读写分离能够缓解压力，但是一旦写操作一台服务器都不能承受了，这个时候我们就需要考虑使用多台服务器实现写操作。</p>
<p>例如可以使用MyCat搭建MySql集群，对ID求3的余数，这样可以把数据分别存放到3台不同的服务器上，由MyCat负责维护集群节点的使用。</p>
<h2 id="硬件优化"><a href="#硬件优化" class="headerlink" title="硬件优化"></a>硬件优化</h2><p>服务器硬件的性能瓶颈，直接决定MySQL数据库的运行速度和效率。</p>
<p>可以从以下几个方面考虑：</p>
<h3 id="内存"><a href="#内存" class="headerlink" title="内存"></a>内存</h3><p>足够大的内存，是提高MySQL数据库性能的方法之一。内存的IO比硬盘快的多，可以增加系统的缓冲区容量，使数据在内存停留的时间更长，以减少磁盘的IO。服务器内存建议不要小于2GB，推荐使用4GB以上的物理内存。</p>
<h3 id="磁盘"><a href="#磁盘" class="headerlink" title="磁盘"></a>磁盘</h3><p>MySQL每秒钟都在进行大量、复杂的查询操作，对磁盘的读写量可想而知。所以，通常认为磁盘I/O是制约MySQL性能的最大因素之一，对于日均访问量在100万PV以上的系统，由于磁盘I/O的制约，MySQL的性能会非常低下 考虑以下几种解决方案：</p>
<ul>
<li>使用SSD或者PCIe SSD设备，至少获得数百倍甚至万倍的IOPS提升；</li>
<li>购置阵列卡，可明显提升IOPS</li>
<li>尽可能选用RAID-10，而非RAID-5</li>
<li>使用机械盘的话，尽可能选择高转速的，例如选用15000RPM，而不是7200RPM的盘</li>
</ul>
<h3 id="CPU"><a href="#CPU" class="headerlink" title="CPU"></a>CPU</h3><p>CPU仅仅只能决定运算速度，及时是运算速度都还取决于与内存之间的总线带宽以及内存本身的速度。但是一般情况下，我们都需要选择计算速度较快的CPU。</p>
<p>关闭节能模式。操作系统和CPU硬件配合，系统不繁忙的时候，为了节约电能和降低温度，它会将CPU降频。这对环保人士和抵制地球变暖来说是一个福音，但是对MySQL来说，可能是一个灾难。为了保证MySQL能够充分利用CPU的资源，建议设置CPU为最大性能模式。</p>
<h3 id="网络"><a href="#网络" class="headerlink" title="网络"></a>网络</h3><p>应该尽可能选择网络延时低，吞吐量高的设备。</p>
<ul>
<li>网络延时：不同的网络设备其延时会有差异，延时自然是越小越好。</li>
<li>吞吐量：对于数据库集群来说，各个节点之间的网络吞吐量可能直接决定集群的处理能力。</li>
</ul>
<h2 id="缓存优化"><a href="#缓存优化" class="headerlink" title="缓存优化"></a>缓存优化</h2><h3 id="查询缓存"><a href="#查询缓存" class="headerlink" title="查询缓存"></a>查询缓存</h3><p>query_cache_size：作用于整个 MySQL，主要用来缓存MySQL中的ResultSet，也就是一条SQL语句执行的结果集，所以仅仅只能针对select语句。查询缓存从MySQL 5.7.20开始已被弃用，并在MySQL 8.0中被删除。</p>
<p>当我们打开了 Query Cache功能，MySQL在接受到一条select语句的请求后，如果该语句满足Query Cache的要求，MySQL会直接根据预先设定好的HASH算法将接受到的select语句以字符串方式进行hash，然后到Query Cache中直接查找是否已经缓存。如果已经在缓存中，该select请求就会直接将数据返回，从而省略了后面所有的步骤(如SQL语句的解析，优化器优化以及向存储引擎请求数据等)，极大的提高性能。</p>
<p>当然，Query Cache也有一个致命的缺陷，那就是当某个表的数据有任何任何变化，都会导致所有引用了该表的select语句在Query Cache中的缓存数据失效。所以，当我们的数据变化非常频繁的情况下，使用Query Cache可能会得不偿失。</p>
<p>如果缓存命中率非常高的话，有测试表明在极端情况下可以提高效率238%，而在糟糕时，QC会降低系统13%的处理能力。</p>
<p>通过以下命令查看缓存相关变量</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">show variables like &#39;%query_cache%&#39;;</span><br></pre></td></tr></table></figure>
<ul>
<li>have_query_cache：表示此版本mysql是否支持缓存</li>
<li>query_cache_limit ：缓存最大值</li>
<li>query_cache_size：缓存大小</li>
<li>query_cache_type：off 表示不缓存，on表示缓存所有结果。</li>
</ul>
<h3 id="全局缓存"><a href="#全局缓存" class="headerlink" title="全局缓存"></a>全局缓存</h3><p>数据库属于IO密集型的应用程序，其主职责就是数据的管理及存储工作。而我们知道，从内存中读取一个数据库的时间是微秒级别，而从一块普通硬盘上读取一个 IO是在毫秒级别，二者相差3个数量级。所以，要优化数据库，首先第一步需要优化的就是IO，尽可能将磁盘IO转化为内存IO,也就是使用缓存</p>
<p>启动MySQL时就要分配并且总是存在的全局缓存，可以在MySQL的my.conf或者my.ini文件的[mysqld]组中配置。查询缓存属于全局缓存。</p>
<p>目前有：</p>
<p>key_buffer_size(默认值：402653184,即384M)、</p>
<p>innodb_buffer_pool_size(默认值：134217728即：128M)、</p>
<p>innodb_additional_mem_pool_size（默认值：8388608即：8M）、</p>
<p>innodb_log_buffer_size(默认值：8388608即：8M)、</p>
<p>query_cache_size(默认值：33554432即：32M)</p>
<h4 id="1）-key-buffer-size"><a href="#1）-key-buffer-size" class="headerlink" title="1） key_buffer_size"></a>1） key_buffer_size</h4><p>用于索引块的缓冲区大小，增加它可得到更好处理的索引(对所有读和多重写)，对MyISAM表性能影响最大的一个参数。如果你使它太大，系统将开始换页并且真的变慢了。</p>
<p>严格说是它决定了数据库索引处理的速度，尤其是索引读的速度。对于内存在4GB左右的服务器该参数可设置为256M或384M.</p>
<h4 id="2）-innodb-buffer-pool-size"><a href="#2）-innodb-buffer-pool-size" class="headerlink" title="2） innodb_buffer_pool_size"></a>2） innodb_buffer_pool_size</h4><p>主要针对InnoDB表性能影响最大的一个参数。功能与Key_buffer_size一样。InnoDB占用的内存，除innodb_buffer_pool_size用于存储页面缓存数据外，另外正常情况下还有大约8%的开销，主要用在每个缓存页帧的描述、adaptive hash等数据结构，如果不是安全关闭，启动时还要恢复的话，还要另开大约12%的内存用于恢复，两者相加就有差不多21%的开销。</p>
<h4 id="3）-innodb-additional-mem-pool-size"><a href="#3）-innodb-additional-mem-pool-size" class="headerlink" title="3） innodb_additional_mem_pool_size"></a>3） innodb_additional_mem_pool_size</h4><p>设置了InnoDB存储引擎用来存放数据字典信息以及一些内部数据结构的内存空间大小，所以当我们一个MySQL Instance中的数据库对象非常多的时候，是需要适当调整该参数的大小以确保所有数据都能存放在内存中提高访问效率的。</p>
<h4 id="4）-innodb-log-buffer-size"><a href="#4）-innodb-log-buffer-size" class="headerlink" title="4） innodb_log_buffer_size"></a>4） innodb_log_buffer_size</h4><p>这是InnoDB存储引擎的事务日志所使用的缓冲区。类似于Binlog Buffer。InnoDB在写事务日志的时候，为了提高性能，也是先将信息写入Innofb Log Buffer中，当满足innodb_flush_log_trx_commit参数所设置的相应条件(或者日志缓冲区写满)之后，才会将日志写到文件(或者同步到磁盘)中。可以通过innodb_log_buffer_size 参数设置其可以使用的最大内存空间。</p>
<p>InnoDB 将日志写入日志磁盘文件前的缓冲大小。理想值为 1M 至 8M。大的日志缓冲允许事务运行时不需要将日志保存入磁盘而只到事务被提交(commit)。因此，如果有大的事务处理，设置大的日志缓冲可以减少磁盘I/O。这个参数实际上还和另外的flush参数相关。一般来说不建议超过32MB。</p>
<h3 id="局部缓存"><a href="#局部缓存" class="headerlink" title="局部缓存"></a>局部缓存</h3><p>除了全局缓冲，MySql还会为每个连接发放连接缓冲。个连接到MySQL服务器的线程都需要有自己的缓冲。大概需要立刻分配256K，甚至在线程空闲时，它们使用默认的线程堆栈，网络缓存等。事务开始之后，则需要增加更多的空间。运行较小的查询可能仅给指定的线程增加少量的内存消耗，然而如果对数据表做复杂的操作例如扫描、排序或者需要临时表，则需分配大约read_buffer_size，</p>
<p>sort_buffer_size，read_rnd_buffer_size，tmp_table_size大小的内存空间. 不过它们只是在需要的时候才分配，并且在那些操作做完之后就释放了。</p>
<h4 id="1）-read-buffer-size"><a href="#1）-read-buffer-size" class="headerlink" title="1） read_buffer_size"></a>1） read_buffer_size</h4><p>是MySql读入缓冲区大小。对表进行顺序扫描的请求将分配一个读入缓冲区，MySql会为它分配一段内存缓冲区。read_buffer_size变量控制这一缓冲区的大小。如果对表的顺序扫描请求非常频繁，并且你认为频繁扫描进行得太慢，可以通过增加该变量值以及内存缓冲区大小提高其性能.</p>
<h4 id="2）-sort-buffer-size"><a href="#2）-sort-buffer-size" class="headerlink" title="2） sort_buffer_size"></a>2） sort_buffer_size</h4><p>是MySql执行排序使用的缓冲大小。如果想要增加ORDER BY的速度，首先看是否可以让MySQL使用索引而不是额外的排序阶段。如果不能，可以尝试增加sort_buffer_size变量的大小</p>
<h4 id="3）-read-rnd-buffer-size"><a href="#3）-read-rnd-buffer-size" class="headerlink" title="3） read_rnd_buffer_size"></a>3） read_rnd_buffer_size</h4><p>是MySql的随机读缓冲区大小。当按任意顺序读取行时(例如，按照排序顺序)，将分配一个随机读缓存区。进行排序查询时，MySql会首先扫描一遍该缓冲，以避免磁盘搜索，提高查询速度，如果需要排序大量数据，可适当调高该值。但MySql会为每个客户连接发放该缓冲空间，所以应尽量适当设置该值，以避免内存开销过大。</p>
<h4 id="4）-tmp-table-size"><a href="#4）-tmp-table-size" class="headerlink" title="4） tmp_table_size"></a>4） tmp_table_size</h4><p>是MySql的heap （堆积）表缓冲大小。所有联合在一个DML指令内完成，并且大多数联合甚至可以不用临时表即可以完成。大多数临时表是基于内存的(HEAP)表。具有大的记录长度的临时表 (所有列的长度的和)或包含BLOB列的表存储在硬盘上。</p>
<p>如果某个内部heap（堆积）表大小超过tmp_table_size，MySQL可以根据需要自动将内存中的heap表改为基于硬盘的MyISAM表。还可以通过设置tmp_table_size选项来增加临时表的大小。也就是说，如果调高该值，MySql同时将增加heap表的大小，可达到提高联接查询速度的效果。</p>
<h4 id="5）-record-buffer"><a href="#5）-record-buffer" class="headerlink" title="5） record_buffer:"></a>5） record_buffer:</h4><p>record_buffer每个进行一个顺序扫描的线程为其扫描的每张表分配这个大小的一个缓冲区。如果你做很多顺序扫描，你可能想要增加该值。</p>
<h3 id="其它缓存"><a href="#其它缓存" class="headerlink" title="其它缓存"></a>其它缓存</h3><h4 id="1）-table-cache"><a href="#1）-table-cache" class="headerlink" title="1） table_cache"></a>1） table_cache</h4><p>TABLE_CACHE(5.1.3及以后版本又名TABLE_OPEN_CACHE)，table_cache指定表高速缓存的大小。每当MySQL访问一个表时，如果在表缓冲区中还有空间，该表就被打开并放入其中，这样可以更快地访问表内容。</p>
<p>不能盲目地把table_cache设置成很大的值。如果设置得太高，可能会造成文件描述符不足，从而造成性能不稳定或者连接失败。</p>
<h4 id="2）-thread-cache-size"><a href="#2）-thread-cache-size" class="headerlink" title="2） thread_cache_size"></a>2） thread_cache_size</h4><p>服务器线程缓存，默认的thread_cache_size=8，,这个值表示可以重新利用保存在缓存中线程的数量,当断开连接时如果缓存中还有空间,那么客户端的线程将被放到缓存中,如果线程重新被请求，那么请求将从缓存中读取,如果缓存中是空的或者是新的请求，那么这个线程将被重新创建,如果有很多新的线程，</p>
<p>增加这个值可以改善系统性能.通过比较Connections 和 Threads_created 状态的变量，可以看到这个变量的作用。</p>
<h2 id="服务器优化"><a href="#服务器优化" class="headerlink" title="服务器优化"></a>服务器优化</h2><h3 id="MySQL参数"><a href="#MySQL参数" class="headerlink" title="MySQL参数"></a>MySQL参数</h3><p>通过优化MySQL的参数可以提高资源利用率，从而达到提高MySQL服务器性能的目的。MySQL的配置参数都在my.conf或者my.ini文件的[mysqld]组中，常用的参数如下：</p>
<h4 id="1）-back-log"><a href="#1）-back-log" class="headerlink" title="1） back_log"></a>1） back_log</h4><p>在MySQL暂时停止回答新请求之前的短时间内多少个请求可以被存在堆栈中（每个连接256kb，占用：125M）。也就是说，如果MySql的连接数据达到max_connections时，新来的请求将会被存在堆栈中，以等待某一连接释放资源，该堆栈的数量即back_log，如果等待连接的数量超过back_log，将不被授予连接资源。</p>
<h4 id="2）-wait-timeout"><a href="#2）-wait-timeout" class="headerlink" title="2） wait_timeout"></a>2） wait_timeout</h4><p>当MySQL连接闲置超过一定时间后将会被强行关闭。MySQL默认的wait-timeout值为8个小时。</p>
<p>设置这个值是非常有意义的，比如你的网站有大量的MySQL链接请求（每个MySQL连接都是要内存资源开销的），由于你的程序的原因有大量的连接请求空闲啥事也不干，白白占用内存资源，或者导致MySQL超过最大连接数从来无法新建连接导致“Too many connections”的错误。在设置之前你可以查看一下你的MYSQL的状态（可用showprocesslist)，如果经常发现MYSQL中有大量的Sleep进程，则需要修改wait-timeout值了。</p>
<h4 id="3）-max-connections"><a href="#3）-max-connections" class="headerlink" title="3） max_connections"></a>3） max_connections</h4><p>是指MySql的最大连接数，如果服务器的并发连接请求量比较大，建议调高此值，以增加并行连接数量，当然这建立在机器能支撑的情况下，因为如果连接数越多，介于MySql会为每个连接提供连接缓冲区，就会开销越多的内存，所以要适当调整该值，不能盲目提高设值。</p>
<p>MySQL服务器允许的最大连接数16384</p>
<h4 id="4）-max-user-connections"><a href="#4）-max-user-connections" class="headerlink" title="4） max_user_connections"></a>4） max_user_connections</h4><p>是指每个数据库用户的最大连接针对某一个账号的所有客户端并行连接到MYSQL服务的最大并行连接数。简单说是指同一个账号能够同时连接到mysql服务的最大连接数。设置为0表示不限制。</p>
<h4 id="5）-thread-concurrency"><a href="#5）-thread-concurrency" class="headerlink" title="5） thread_concurrency"></a>5） thread_concurrency</h4><p>的值的正确与否, 对mysql的性能影响很大, 在多个cpu(或多核)的情况下，错误设置了thread_concurrency的值, 会导致mysql不能充分利用多cpu(或多核), 出现同一时刻只能一个cpu(或核)在工作的情况。thread_concurrency应设为CPU核数的2倍。</p>
<h4 id="6）-skip-name-resolve"><a href="#6）-skip-name-resolve" class="headerlink" title="6） skip-name-resolve"></a>6） skip-name-resolve</h4><p>禁止MySQL对外部连接进行DNS解析，使用这一选项可以消除MySQL进行DNS解析的时间。但需要注意，如果开启该选项，则所有远程主机连接授权都要使用IP地址方式，否则MySQL将无法正常处理连接请求！</p>
<h4 id="7）-default-storage-engine"><a href="#7）-default-storage-engine" class="headerlink" title="7） default-storage-engine"></a>7） default-storage-engine</h4><p>default-storage-engine=InnoDB(设置InnoDB类型，另外还可以设置MyISAM类型)设置创建数据库及表默认存储类型</p>
<h2 id="Linux系统优化"><a href="#Linux系统优化" class="headerlink" title="Linux系统优化"></a>Linux系统优化</h2><p>一般情况，我们都会使用Linux来进行MySQL的安装和部署，Linux系统在使用的时候，也需要进行相关的配置，以提高MySQL的使用性能，这里列举以下几点：</p>
<ul>
<li>避免使用Swap交换分区，因为交换时是从硬盘读取的，速度很慢。</li>
<li>将操作系统和数据分区分开，不仅仅是逻辑上，还包括物理上，因为操作系统的读写会影响数据库的性能。</li>
<li>把MySQL临时空间和复制日志与数据放到不同的分区，数据库后台从磁盘进行读写时会影响数据库的性能。</li>
<li>避免使用软件磁盘阵列。</li>
<li>在Linux中设置swappiness的值为0，因为在数据库服务器中不需要缓存文件。</li>
<li>使用 noatime 和 nodirtime 挂载文件系统，因为不需要对数据库文件修改时间。</li>
<li>使用 XFS 文件系统，一种比ext3更快、更小的文件系统。</li>
<li>调整 XFS 文件系统日志和缓冲变量 – 为了最高性能标准。</li>
<li>使用64位的操作系统，这会支持更大的内存。</li>
<li>删除服务器上未使用的安装包和守护进程，节省系统的资源占用。</li>
<li>把使用MySQL的host和你的MySQL host放到一个hosts文件中。</li>
</ul>
]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title>Netty</title>
    <url>/essay/1c6ba3e2.html</url>
    <content><![CDATA[<p>Netty是一个异步事件驱动的网络应用框架，用于快速开发可维护的高性能服务器和客户端。</p>
<a id="more"></a>

<h1 id="IO编程"><a href="#IO编程" class="headerlink" title="IO编程"></a>IO编程</h1><h2 id="传统IO编程"><a href="#传统IO编程" class="headerlink" title="传统IO编程"></a>传统IO编程</h2><p>每个客户端连接过来后，服务端都会启动一个线程去处理该客户端的请求。阻塞I/O的通信模型示意图如下：</p>
<img src="/essay/1c6ba3e2/传统io.png" style="zoom:80%;">

<p>在传统的IO模型中，每个连接创建成功之后都需要一个线程来维护，每个线程包含一个while死循环。<br>如果在用户数量较少的情况下运行是没有问题的，但是对于用户数量比较多的业务来说，服务端可能需要支撑成千上万的连接，IO模型可能就不太合适了。</p>
<p>如果有1万个连接就对应1万个线程，继而1万个while死循环，这种模型存在以下问题：</p>
<ul>
<li>当客户端越多，就会创建越多的处理线程。线程是操作系统中非常宝贵的资源，同一时刻有大量的线程处于阻塞状态是非常严重的资源浪费。并且如果务器遭遇洪峰流量冲击，例如双十一活动，线程池会瞬间被耗尽，导致服务器瘫痪。</li>
<li>因为是阻塞式通信，线程爆炸之后操作系统频繁进行线程切换，应用性能急剧下降。</li>
<li>IO编程中数据读写是以字节流为单位，效率不高。</li>
</ul>
<h2 id="NIO"><a href="#NIO" class="headerlink" title="NIO"></a>NIO</h2><p>NIO，也叫做new-IO或者non-blocking-IO，可理解为非阻塞IO。NIO编程模型中，新来一个连接不再创建一个新的线程，而是可以把这条连接直接绑定到某个固定的线程，然后这条连接所有的读写都由这个线程来负责</p>
<img src="/essay/1c6ba3e2/nio.png" style="zoom:80%;">

<p>在NIO模型中，可以把这么多的while死循环变成一个死循环，这个死循环由一个线程控制。这就是NIO模型中选择器（Selector）的作用，一条连接来了之后，现在不创建一个while死循环去监听是否有数据可读了，而是直接把这条连接注册到选择器上，通过检查这个选择器，就可以批量监测出有数据可读的连接，进而读取数据。</p>
<h3 id="NIO三大组件"><a href="#NIO三大组件" class="headerlink" title="NIO三大组件"></a>NIO三大组件</h3><ul>
<li><p>通道（Channel）<br>是传统IO中的Stream(流)的升级版。Stream是单向的、读写分离（inputstream和outputstream），Channel是双向的，既可以进行读操作，又可以进行写操作。</p>
</li>
<li><p>缓冲（Buffer）</p>
<p>Buffer可以理解为一块内存区域，可以写入数据，并且在之后读取它。</p>
</li>
<li><p>选择器（Selector）<br>选择器可以实现一个单独的线程来监控多个注册在她上面的信道（Channel），通过一定的选择机制，实现多路复用的效果。</p>
</li>
</ul>
<h3 id="NIO相对于IO的优势"><a href="#NIO相对于IO的优势" class="headerlink" title="NIO相对于IO的优势"></a>NIO相对于IO的优势</h3><ol>
<li>IO是面向流的，每次都是从操作系统底层一个字节一个字节地读取数据，并且数据只能从一端读取到另一端，不能前后移动流中的数据。NIO则是面向缓冲区的，每次可以从这个缓冲区里面读取一块的数据，并且可以在需要时在缓冲区中前后移动。</li>
<li>IO是阻塞的，这意味着，当一个线程读取数据或写数据时，该线程被阻塞，直到有一些数据被读取，或数据完全写入，在此期间该线程不能干其他任何事情。而NIO是非阻塞的，不需要一直等待操作完成才能干其他事情，而是在等待的过程中可以同时去做别的事情，所以能最大限度地使用服务器的资源。</li>
<li>NIO引入了IO多路复用器selector。selector是一个提供channel注册服务的线程，可以同时对接多个Channel，并在线程池中为channel适配、选择合适的线程来处理channel。由于NIO模型中线程数量大大降低，线程切换效率因此也大幅度提高。</li>
</ol>
<h1 id="Netty"><a href="#Netty" class="headerlink" title="Netty"></a>Netty</h1><h2 id="netty不使用原生NIO原因"><a href="#netty不使用原生NIO原因" class="headerlink" title="netty不使用原生NIO原因"></a>netty不使用原生NIO原因</h2><p>下面是使用Netty不使用JDK原生NIO的一些原因：</p>
<ul>
<li>使用JDK自带的NIO需要了解太多的概念，编程复杂</li>
<li>Netty底层IO模型随意切换，而这一切只需要做微小的改动，就可以直接从NIO模型变身为IO模型</li>
<li>Netty自带的拆包解包，异常检测等机制，可以从NIO的繁重细节中脱离出来，只需要关心业务逻辑</li>
<li>Netty解决了JDK的很多包括空轮询在内的bug</li>
<li>Netty底层对线程，selector做了很多细小的优化，精心设计的线程模型做到非常高效的并发处理</li>
<li>自带各种协议栈让你处理任何一种通用协议都几乎不用亲自动手</li>
<li>Netty社区活跃，遇到问题随时邮件列表或者issue</li>
<li>Netty已经历各大rpc框架，消息中间件，分布式通信中间件线上的广泛验证，健壮性无比强大</li>
</ul>
<h2 id="代码展示"><a href="#代码展示" class="headerlink" title="代码展示"></a>代码展示</h2><ul>
<li>maven依赖</li>
</ul>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">groupId</span>&gt;</span>io.netty<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>netty-all<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">version</span>&gt;</span>4.1.42.Final<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>
<ul>
<li>服务端</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">NettyServer</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 用于接受客户端的连接以及为已接受的连接创建子通道，一般用于服务端。</span></span><br><span class="line">        ServerBootstrap serverBootstrap = <span class="keyword">new</span> ServerBootstrap();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 包含有多个EventLoop的实例，用来管理 event Loop 的组件，</span></span><br><span class="line">        <span class="comment">// 可以理解为一个线程池，内部维护了一组线程。</span></span><br><span class="line">        <span class="comment">// 处理新的连接</span></span><br><span class="line">        NioEventLoopGroup boos = <span class="keyword">new</span> NioEventLoopGroup();</span><br><span class="line">        <span class="comment">// 处理数据</span></span><br><span class="line">        NioEventLoopGroup worker = <span class="keyword">new</span> NioEventLoopGroup();</span><br><span class="line"></span><br><span class="line">        serverBootstrap</span><br><span class="line">                .group(boos, worker)</span><br><span class="line">                <span class="comment">// 对网络套接字的I/O操作，例如读、写、连接、绑定</span></span><br><span class="line">                <span class="comment">// 等操作进行适配和封装的组件。</span></span><br><span class="line">                .channel(NioServerSocketChannel.class)</span><br><span class="line">                <span class="comment">// 用于对刚创建的channel进行初始化，</span></span><br><span class="line">                <span class="comment">// 将ChannelHandler添加到channel的ChannelPipeline处理链路中。</span></span><br><span class="line">                .childHandler(<span class="keyword">new</span> ChannelInitializer&lt;NioSocketChannel&gt;() &#123;</span><br><span class="line">                    <span class="comment">// 初始化channel的方法</span></span><br><span class="line">                    <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">initChannel</span><span class="params">(NioSocketChannel ch)</span> </span>&#123;</span><br><span class="line">                        <span class="comment">//流水线车间，当组件从流水线头部进入，流水线上的工人按顺序对组件进行加工</span></span><br><span class="line">                        <span class="comment">//到达流水线尾部时商品组装完成。</span></span><br><span class="line">                        <span class="comment">// 流水线相当于ChannelPipeline，</span></span><br><span class="line">                        <span class="comment">// 流水线工人相当于ChannelHandler，源头的组件当做event。</span></span><br><span class="line">                        ch.pipeline().addLast(<span class="keyword">new</span> StringDecoder());</span><br><span class="line">                        ch.pipeline().addLast(<span class="keyword">new</span> SimpleChannelInboundHandler&lt;String&gt;() &#123;</span><br><span class="line">                            <span class="meta">@Override</span></span><br><span class="line">                            <span class="comment">//自己指定流水线工作可以干什么事</span></span><br><span class="line">                            <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">channelRead0</span><span class="params">(ChannelHandlerContext ctx, String msg)</span> </span>&#123;</span><br><span class="line">                                System.out.println(msg);</span><br><span class="line">                            &#125;</span><br><span class="line">                        &#125;);</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;)</span><br><span class="line">                .bind(<span class="number">8000</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>客户端：</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">NettyClient</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">        Bootstrap bootstrap = <span class="keyword">new</span> Bootstrap();</span><br><span class="line">        NioEventLoopGroup group = <span class="keyword">new</span> NioEventLoopGroup();</span><br><span class="line"></span><br><span class="line">        bootstrap.group(group)</span><br><span class="line">                .channel(NioSocketChannel.class)</span><br><span class="line">                .handler(<span class="keyword">new</span> ChannelInitializer&lt;Channel&gt;() &#123;</span><br><span class="line">                    <span class="meta">@Override</span></span><br><span class="line">                    <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">initChannel</span><span class="params">(Channel ch)</span> </span>&#123;</span><br><span class="line">                        ch.pipeline().addLast(<span class="keyword">new</span> StringEncoder());</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;);</span><br><span class="line"></span><br><span class="line">        Channel channel = bootstrap.connect(<span class="string">&quot;127.0.0.1&quot;</span>, <span class="number">8000</span>).channel();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">            channel.writeAndFlush(<span class="string">&quot;测试数据&quot;</span>);</span><br><span class="line">            Thread.sleep(<span class="number">2000</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="Netty的事件驱动"><a href="#Netty的事件驱动" class="headerlink" title="Netty的事件驱动"></a>Netty的事件驱动</h2><p>Netty使用事件驱动的方式作为底层架构，包括：</p>
<ul>
<li>事件队列（event queue）：接收事件的入口。</li>
<li>分发器（event mediator）：将不同的事件分发到不同的业务逻辑单元。</li>
<li>事件通道（event channel）：分发器与处理器之间的联系渠道。</li>
<li>事件处理器（event processor）：实现业务逻辑，处理完成后会发出事件，触发下一步操作。</li>
</ul>
<img src="/essay/1c6ba3e2/netty事件驱动.png" style="zoom:75%;">

<h2 id="核心组件"><a href="#核心组件" class="headerlink" title="核心组件"></a>核心组件</h2><p>Netty 的功能特性图：</p>
<img src="/essay/1c6ba3e2/netty功能特性图.png" style="zoom:75%;">

<p>Netty 功能特性：</p>
<ul>
<li>传输服务，支持 BIO 和 NIO。</li>
<li>容器集成：支持 OSGI、JBossMC、Spring、Guice 容器。</li>
<li>协议支持：HTTP、Protobuf、二进制、文本、WebSocket 等，支持自定义协议。</li>
</ul>
<p>BIO和NIO的区别：</p>
<table>
<thead>
<tr>
<th align="center">场景</th>
<th align="center">BIO</th>
<th align="center">NIO</th>
</tr>
</thead>
<tbody><tr>
<td align="center">有新连接请求时</td>
<td align="center">开一个新的线程处理</td>
<td align="center">使用多路复用原理，一个线程处理</td>
</tr>
<tr>
<td align="center">适用场景</td>
<td align="center">连接数小且固定</td>
<td align="center">连接数特别多，连接比较短（轻操作）的场景</td>
</tr>
</tbody></table>
<p>Netty框架包含如下的组件：</p>
<ul>
<li>ServerBootstrap ：用于接受客户端的连接以及为已接受的连接创建子通道，一般用于服务端。</li>
<li>Bootstrap：不接受新的连接，并且是在父通道类完成一些操作，一般用于客户端的。</li>
<li>Channel：对网络套接字的I/O操作，例如读、写、连接、绑定等操作进行适配和封装的组件。</li>
<li>EventLoop：处理所有注册其上的channel的I/O操作。通常情况一个</li>
<li>EventLoop可为多个channel提供服务。</li>
<li>EventLoopGroup：包含有多个EventLoop的实例，用来管理 event Loop 的组件，可以理解为一个线程池，内部维护了一组线程。</li>
<li>ChannelHandler和ChannelPipeline：例如一个流水线车间，当组件从流水线头部进入，穿越流水线，流水线上的工人按顺序对组件进行加工，到达流水线尾部时商品组装完成。流水线相当于ChannelPipeline ，流水线工人相当于ChannelHandler ，源头的组件当做event。</li>
<li>ChannelInitializer：用于对刚创建的channel进行初始化，将ChannelHandler<br>添加到channel的ChannelPipeline处理链路中。</li>
<li>ChannelFuture：与jdk中线程的Future接口类似，即实现并行处理的效果。可<br>以在操作执行成功或失败时自动触发监听器中的事件处理方法。</li>
</ul>
]]></content>
      <categories>
        <category>后端</category>
      </categories>
      <tags>
        <tag>netty</tag>
      </tags>
  </entry>
  <entry>
    <title>next主题下中文标题跳转失效</title>
    <url>/essay/80ff7aac.html</url>
    <content><![CDATA[<p>next 7.8版本发布于2020年4月1日，很久没更新 </p>
<p>该bug导致中文标题无法跳转，但是英文标题可以</p>
<a id="more"></a>

<h2 id="环境："><a href="#环境：" class="headerlink" title="环境："></a>环境：</h2><p>hexo 5.0</p>
<p>next 7.8</p>
<h2 id="原因"><a href="#原因" class="headerlink" title="原因:"></a>原因:</h2><p><img src="/essay/80ff7aac/title_bug.png"></p>
<p>由上图可知，utils中的一行代码出了问题，导致后面的一系列出了问题</p>
<p>于是我先是去搜索了一下这个问题，但是并没有人写过相关内容</p>
<p>最终 在官方代码最新的commit中，我看到了这样的一个提交。</p>
<p><img src="/essay/80ff7aac/utils.png"></p>
<p>但是即使将此次提交变动的代码修改之后也不可以，会出现另一个错误。</p>
<h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案:"></a>解决方案:</h2><p>将下面这个链接的整个代码全部复制，粘贴到<code>\themes\next\source\js\utils.js</code>中，问题完美解决</p>
<p>访问官方的<a href="https://github.com/theme-next/hexo-theme-next/blob/master/source/js/utils.js">github仓库</a>获取最新的utils.js代码</p>
]]></content>
      <categories>
        <category>next</category>
        <category>bug</category>
      </categories>
      <tags>
        <tag>next</tag>
      </tags>
  </entry>
  <entry>
    <title>nginx实现负载均衡</title>
    <url>/essay/nginx-config.html</url>
    <content><![CDATA[<p>Nginx可以配置代理多台服务器，当一台服务器宕机之后，仍能保持系统可用。记录一下nginx负载均衡的实现，配置文件如下：</p>
<a id="more"></a>

<ol>
<li>在http节点下，添加upstream节点。</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">upstream abc &#123; </span><br><span class="line">   server localhost:7080; </span><br><span class="line">   server localhost:8980; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ol start="2">
<li>将server节点下的location节点中的proxy_pass配置为：http:// + upstream名称，即</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">location &#x2F; &#123; </span><br><span class="line">    root  html; </span><br><span class="line">    &#x2F;&#x2F;http:&#x2F;&#x2F; + upstream名称</span><br><span class="line">    proxy_pass http:&#x2F;&#x2F;abc; </span><br><span class="line">    index  index.html index.htm; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>upstream按照轮询（默认）方式进行负载，每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。虽然这种方式简便、成本低廉。但缺点是：可靠性低和负载分配不均衡。适用于图片服务器集群和纯静态页面服务器集群。除此之外，upstream还有其它的分配策略，分别如下：</p>
<ol>
<li>weight（权重）</li>
</ol>
<p>指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况。如下所示，10.0.0.88的访问比率要比10.0.0.77的访问比率高一倍。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">upstream linuxidc&#123; </span><br><span class="line">      server 10.0.0.77 weight&#x3D;5; </span><br><span class="line">      server 10.0.0.88 weight&#x3D;10; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ol start="2">
<li>ip_hash（访问ip）</li>
</ol>
<p>每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">upstream favresin&#123; </span><br><span class="line">      ip_hash; </span><br><span class="line">      server 10.0.0.10:8080; </span><br><span class="line">      server 10.0.0.11:8080; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ol start="3">
<li><p>fair（第三方）</p>
<p>按后端服务器的响应时间来分配请求，响应时间短的优先分配。与weight分配策略类似。</p>
</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"> upstream abc&#123;   </span><br><span class="line">   server 10.0.0.10:8080; </span><br><span class="line">   server 10.0.0.11:8080; </span><br><span class="line">   fair; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ol start="4">
<li>url_hash（第三方）</li>
</ol>
<p>按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，后端服务器为缓存时比较有效。</p>
<p>注意：在upstream中加入hash语句，server语句中不能写入weight等其他的参数，hash_method是使用的hash算法。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"> upstream abc&#123; </span><br><span class="line">   server 10.0.0.10:7777; </span><br><span class="line">   server 10.0.0.11:8888; </span><br><span class="line">   hash $request_uri; </span><br><span class="line">   hash_method crc32; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>upstream还可以为每个设备设置状态值，这些状态值的含义分别如下：</p>
<p>down 表示单前的server暂时不参与负载.</p>
<p>weight 默认为1.weight越大，负载的权重就越大。</p>
<p>max_fails ：允许请求失败的次数默认为1.当超过最大次数时，返回proxy_next_upstream 模块定义的错误.</p>
<p>fail_timeout : max_fails次失败后，暂停的时间。</p>
<p>backup： 其它所有的非backup机器down或者忙的时候，请求backup机器。所以这台机器压力会最轻。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">upstream bakend&#123; #定义负载均衡设备的Ip及设备状态 </span><br><span class="line"> ip_hash; </span><br><span class="line">   server 10.0.0.11:9090 down; </span><br><span class="line">   server 10.0.0.11:8080 weight&#x3D;2; </span><br><span class="line">   server 10.0.0.11:6060; </span><br><span class="line">   server 10.0.0.11:7070 backup; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>后端</category>
        <category>nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title>redisTemplate操作lua脚本</title>
    <url>/essay/f475ebb1.html</url>
    <content><![CDATA[<p>简单介绍使用RedisTemplate操作lua脚本对redis进行数据修改的操作</p>
<a id="more"></a>

<h1 id="lua脚本"><a href="#lua脚本" class="headerlink" title="lua脚本"></a>lua脚本</h1><figure class="highlight lua"><table><tr><td class="code"><pre><span class="line"><span class="keyword">local</span> userId = KEYS[<span class="number">1</span>];</span><br><span class="line"><span class="keyword">local</span> prodId = KEYS[<span class="number">2</span>];</span><br><span class="line"><span class="keyword">local</span> qtKey = <span class="string">&quot;sk:&quot;</span> .. prodId .. <span class="string">&quot;:qt&quot;</span>;</span><br><span class="line"><span class="keyword">local</span> usersKey = <span class="string">&quot;sk:&quot;</span> .. prodId .. <span class="string">&quot;:user&quot;</span>;</span><br><span class="line"><span class="keyword">local</span> userExists = redis.call(<span class="string">&quot;sismember&quot;</span>, usersKey, userId);</span><br><span class="line"><span class="keyword">if</span> <span class="built_in">tonumber</span>(userExists) == <span class="number">1</span> <span class="keyword">then</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">2</span>; <span class="comment">---自行约定返回值结果</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">local</span> num = redis.call(<span class="string">&quot;get&quot;</span>, qtKey);</span><br><span class="line"><span class="keyword">if</span> <span class="built_in">tonumber</span>(num) &lt;= <span class="number">0</span> <span class="keyword">then</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">    redis.call(<span class="string">&quot;decr&quot;</span>, qtKey);</span><br><span class="line">    redis.call(<span class="string">&quot;sadd&quot;</span>, usersKey, userId);</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="keyword">return</span> <span class="number">1</span>;</span><br></pre></td></tr></table></figure>
<h1 id="Service层"><a href="#Service层" class="headerlink" title="Service层"></a>Service层</h1><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Autowired</span></span><br><span class="line">   <span class="keyword">private</span> RedisTemplate redisTemplate;</span><br><span class="line"></span><br><span class="line">   <span class="keyword">private</span> DefaultRedisScript&lt;Long&gt; script;</span><br><span class="line"></span><br><span class="line">   <span class="meta">@PostConstruct</span></span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">init</span><span class="params">()</span> </span>&#123;</span><br><span class="line">       script = <span class="keyword">new</span> DefaultRedisScript&lt;&gt;();</span><br><span class="line">       <span class="comment">//返回值为Long</span></span><br><span class="line">       script.setResultType(Long.class);</span><br><span class="line">       script.setScriptSource(</span><br><span class="line">           <span class="comment">// 从resource目录下面加载</span></span><br><span class="line">           <span class="keyword">new</span> ResourceScriptSource(<span class="keyword">new</span> ClassPathResource(<span class="string">&quot;lua/skill.lua&quot;</span>))</span><br><span class="line">       );</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   <span class="meta">@Transactional</span></span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">doSeckillByScript</span><span class="params">(String uid, String proId)</span> </span>&#123;</span><br><span class="line">       List&lt;String&gt; keys = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">       keys.add(uid);</span><br><span class="line">       keys.add(proId);</span><br><span class="line">       <span class="comment">//KEYS[1] KEYS[2]，是要操作的键，可以指定多个，在lua脚本中通过KEYS[1], KEYS[2]获取</span></span><br><span class="line">       <span class="comment">//ARGV[1] ARGV[2]，参数，在lua脚本中通过ARGV[1], ARGV[2]获取</span></span><br><span class="line">       <span class="comment">// 第三个参数给ARGV[1] ARGV[2]... 取值的</span></span><br><span class="line">       Long result = (Long) redisTemplate.execute(script, keys);</span><br><span class="line">       <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure>
<h1 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h1><p><code>DefaultRedisScript</code>的返回值须是Long类型的，如果换成Integer类型的会报错。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">java.lang.IllegalStateException: null</span><br><span class="line">at io.lettuce.core.output.CommandOutput.set(CommandOutput.java:85) ~[lettuce-core-5.1.8.RELEASE.jar:na]</span><br><span class="line">	at io.lettuce.core.protocol.RedisStateMachine.safeSet(RedisStateMachine.java:357) ~[lettuce-core-5.1.8.RELEASE.jar:na]</span><br><span class="line">	at io.lettuce.core.protocol.RedisStateMachine.decode(RedisStateMachine.java:138) ~[lettuce-core-5.1.8.RELEASE.jar:na]</span><br><span class="line">	at io.lettuce.core.protocol.CommandHandler.decode(CommandHandler.java:708) ~[lettuce-core-5.1.8.RELEASE.jar:na]</span><br><span class="line">	at io.lettuce.core.protocol.CommandHandler.decode0(CommandHandler.java:672) ~[lettuce-core-5.1.8.RELEASE.jar:na]</span><br><span class="line">	at io.lettuce.core.protocol.CommandHandler.decode(CommandHandler.java:667) ~[lettuce-core-5.1.8.RELEASE.jar:na]</span><br><span class="line">	at io.lettuce.core.protocol.CommandHandler.decode(CommandHandler.java:587) ~[lettuce-core-5.1.8.RELEASE.jar:na]</span><br><span class="line">	at io.lettuce.core.protocol.CommandHandler.channelRead(CommandHandler.java:556</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>lua</tag>
      </tags>
  </entry>
  <entry>
    <title>valine改为本地加载</title>
    <url>/essay/802f7ce0.html</url>
    <content><![CDATA[<h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><p>主题next7.8  valine 1.4.14</p>
<h2 id="找到模板源文件"><a href="#找到模板源文件" class="headerlink" title="找到模板源文件"></a>找到模板源文件</h2><p>通过以下路径找到</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">\themes\next\layout\_third-party\comments\valine.swig</span><br></pre></td></tr></table></figure>
<a id="more"></a>

<p>打开代码</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;%- set valine_uri &#x3D; theme.vendors.valine or &#39;&#x2F;&#x2F;unpkg.com&#x2F;valine&#x2F;dist&#x2F;Valine.min.js&#39; %&#125;</span><br></pre></td></tr></table></figure>
<p>从第一行代码可以看出，它是通过网络加载，然后用<code>NexT.utils</code>来进行获取参数  <del>我们可以不用管，直接删掉</del></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">NexT.utils.getScript(&#39;&#123;&#123; valine_uri &#125;&#125;&#39;, () &#x3D;&gt; &#123;</span><br><span class="line">    var GUEST &#x3D; [&#39;nick&#39;, &#39;mail&#39;, &#39;link&#39;];</span><br><span class="line">    var guest &#x3D; &#39;&#123;&#123; theme.valine.guest_info &#125;&#125;&#39;;</span><br><span class="line">    guest &#x3D; guest.split(&#39;,&#39;).filter(item &#x3D;&gt; &#123;</span><br><span class="line">      return GUEST.includes(item);</span><br><span class="line">    &#125;);</span><br></pre></td></tr></table></figure>
<p><del>只留下主体new Valine 代码</del></p>
<p><code>这样操作会导致读取不到guest</code></p>
<p>应该这样写 ↓</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;script type&#x3D;&quot;text&#x2F;javascript&quot; src&#x3D;&quot;&#x2F;js&#x2F;Valine.min.js&quot;&gt;&lt;&#x2F;script&gt;</span><br><span class="line">&lt;script&gt;</span><br><span class="line">	var GUEST &#x3D; [&#39;nick&#39;, &#39;mail&#39;, &#39;link&#39;];</span><br><span class="line">	var guest &#x3D; &#39;&#123;&#123; theme.valine.guest_info &#125;&#125;&#39;;</span><br><span class="line">    guest &#x3D; guest.split(&#39;,&#39;).filter(item &#x3D;&gt; &#123;</span><br><span class="line">      return GUEST.includes(item);</span><br><span class="line">    &#125;);</span><br><span class="line">    new Valine(&#123;</span><br><span class="line">      el         : &#39;#valine-comments&#39;,</span><br><span class="line">      verify     : &#123;&#123; theme.valine.verify &#125;&#125;,</span><br><span class="line">      notify     : &#123;&#123; theme.valine.notify &#125;&#125;,</span><br><span class="line">      appId      : &#39;&#123;&#123; theme.valine.appid &#125;&#125;&#39;,</span><br><span class="line">      appKey     : &#39;&#123;&#123; theme.valine.appkey &#125;&#125;&#39;,</span><br><span class="line">      placeholder: &#123;&#123; theme.valine.placeholder | json &#125;&#125;,</span><br><span class="line">      avatar     : &#39;&#123;&#123; theme.valine.avatar &#125;&#125;&#39;,</span><br><span class="line">      meta       : guest,</span><br><span class="line">      pageSize   : &#39;&#123;&#123; theme.valine.pageSize &#125;&#125;&#39; || 10,</span><br><span class="line">      visitor    : &#123;&#123; theme.valine.visitor &#125;&#125;,</span><br><span class="line">      lang       : &#39;&#123;&#123; theme.valine.language &#125;&#125;&#39; || &#39;zh-cn&#39;,</span><br><span class="line">      path       : location.pathname,</span><br><span class="line">      recordIP   : &#123;&#123; theme.valine.recordIP &#125;&#125;,</span><br><span class="line">      serverURLs : &#39;&#123;&#123; theme.valine.serverURLs &#125;&#125;&#39;</span><br><span class="line">    &#125;);</span><br><span class="line">&lt;&#x2F;script&gt;</span><br></pre></td></tr></table></figure>
<h2 id="Valine-min-js获取方式"><a href="#Valine-min-js获取方式" class="headerlink" title="Valine.min.js获取方式"></a>Valine.min.js获取方式</h2><p>访问 <a href="https://unpkg.com/valine/dist/Valine.min.js">这里</a> 复制全部代码，新建一个Valine.min.js，放进去 保存 放在 <code>主题\source\js</code>里面</p>
]]></content>
      <categories>
        <category>next</category>
        <category>valine</category>
      </categories>
      <tags>
        <tag>valine</tag>
      </tags>
  </entry>
  <entry>
    <title>vue与button的冲突</title>
    <url>/essay/vue-button.html</url>
    <content><![CDATA[<h2 id="环境："><a href="#环境：" class="headerlink" title="环境："></a>环境：</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">vue.js v2.5.16</span><br></pre></td></tr></table></figure>
<h2 id="问题描述："><a href="#问题描述：" class="headerlink" title="问题描述："></a>问题描述：</h2><figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">button</span>&gt;</span><span class="tag">&lt;/<span class="name">button</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p> 这个标签未设置type属性时，在form表单中会默认为submit属性，也就是表单提交事件。</p>
<p>当vue指定@click事件在这个button上时，就会出现两次请求的触发。</p>
<p>出现同步请求的现象（也就是页面刷新一次）</p>
<a id="more"></a>

<h2 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h2><h3 id="方案一："><a href="#方案一：" class="headerlink" title="方案一："></a>方案一：</h3><p>使用高版本vue.js</p>
<p>实测vue.js : 2.6.11可解决问题，但是仍然有同步请求现象</p>
<h3 id="方案二："><a href="#方案二：" class="headerlink" title="方案二："></a>方案二：</h3><p>给form内的button加上type属性，这个最为方便快捷</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">button</span> <span class="attr">type</span>=<span class="string">&quot;button&quot;</span> @<span class="attr">click</span>=<span class="string">&quot;pageNum=1;findPage()&quot;</span> <span class="attr">class</span>=<span class="string">&quot;btn btn-default&quot;</span>&gt;</span>查询<span class="tag">&lt;/<span class="name">button</span>&gt;</span></span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>vue</category>
      </categories>
      <tags>
        <tag>vue</tag>
      </tags>
  </entry>
  <entry>
    <title>修改Hosts访问GitHub</title>
    <url>/essay/host-github.html</url>
    <content><![CDATA[<p>国内访问GitHub总是会有连接慢、图片加载不出来等等问题，修改hosts即可解决这个问题，我提供的工具仅限于Windows平台。能够从<a href="https://www.ipaddress.com/">IpAddress网站</a>中拿到最新的IP地址，配置到Host中。</p>
<a id="more"></a>

<h1 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h1><ol>
<li>Host文件位置：</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">C:\Windows\System32\drivers\etc\hosts</span><br></pre></td></tr></table></figure>
<ol start="2">
<li>JDK环境</li>
<li>确保你的hosts文件没有处于只读状态。（右键-&gt;属性-&gt;取消只读复选框勾选）</li>
</ol>
<h1 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h1><ul>
<li>cmd脚本</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">@echo off </span><br><span class="line">java -jar github_host.jar</span><br><span class="line">ipconfig &#x2F;flushdns # 刷新DNS缓存，使用最新的IP访问Github</span><br></pre></td></tr></table></figure>
<p>源码地址：<a href="https://github.com/sudatime/github_host">https://github.com/sudatime/github_host</a></p>
<p>下载：<a href="https://github.com/sudatime/github_host/releases">https://github.com/sudatime/github_host/releases</a></p>
]]></content>
      <categories>
        <category>tool</category>
        <category>host</category>
      </categories>
      <tags>
        <tag>host</tag>
      </tags>
  </entry>
  <entry>
    <title>单点登录实现</title>
    <url>/essay/9fd432c.html</url>
    <content><![CDATA[<p><strong>单点登录</strong>（Single Sign On），简称为<strong>SSO</strong>，是比较流行的<strong>企业业务整合</strong>的解决方案之一。</p>
<a id="more"></a>

<h2 id="实现方案"><a href="#实现方案" class="headerlink" title="实现方案"></a>实现方案</h2><p>Oauth2：可以生成一个令牌的，经过<strong>用户验证</strong>（客户端、真实用户）生成令牌。</p>
<h3 id="cookie"><a href="#cookie" class="headerlink" title="cookie"></a>cookie</h3><p>用户访问被保护的资源时要经过网关，网关会从里面得到cookie，再从cookie中取出JTI值，可用JTI值作为键值，从redis里面获取token值，验证token。</p>
<p><img src="/essay/9fd432c/1.png"></p>
<h3 id="完整流程："><a href="#完整流程：" class="headerlink" title="完整流程："></a>完整流程：</h3><ol>
<li><p>用户访问资源的时候，网关取得请求的URL，来判断是否放行。</p>
</li>
<li><p>若用户访问的资源是被保护的，则网关不放行，并从中获取cookie值，如果里面不存在cookie，则跳转去登录页面。</p>
</li>
<li><p>当用户登录的时候，会进入登录服务里面，由于登录服务并没有校验密码的功能，我们需要借助于Oauth2服务。</p>
</li>
<li><p>Oauth2拿到用户名密码之后，会查询数据库来判断用户名密码是否正确，当密码正确时，会发放一个令牌给登录用户。</p>
</li>
<li><p>当登录服务拿到令牌之后，会把token以JTI值为键存入redis，并将JTI值存入cookie中。</p>
</li>
<li><p>再次回到网关，网关会重复第2步，若仍然不存在，则继续进入登录服务。若cookie存在，并成功取到token，当校验通过，则可以访问被保护的资源了</p>
</li>
</ol>
<p><img src="/essay/9fd432c/2.png"></p>
<h3 id="实现代码："><a href="#实现代码：" class="headerlink" title="实现代码："></a>实现代码：</h3><ul>
<li>获取请求的URL</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">ServerHttpRequest request = exchange.getRequest();</span><br><span class="line">String path = request.getURI().getPath();</span><br></pre></td></tr></table></figure>
<ul>
<li>转发：</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//跳转登录页面 - 303</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> Mono&lt;Void&gt; <span class="title">toLoginPage</span><span class="params">(String loginUrl, ServerWebExchange exchange)</span> </span>&#123;</span><br><span class="line">    ServerHttpResponse response = exchange.getResponse();</span><br><span class="line">    response.setStatusCode(HttpStatus.SEE_OTHER);</span><br><span class="line">    response.getHeaders().set(<span class="string">&quot;Location&quot;</span>,loginUrl);</span><br><span class="line">    <span class="keyword">return</span> response.setComplete();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>取cookie</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">HttpCookie httpCookie = request.getCookies().getFirst(<span class="string">&quot;uid&quot;</span>);</span><br></pre></td></tr></table></figure>
<ul>
<li>给request请求添加header</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">request.mutate().header(<span class="string">&quot;Authorization&quot;</span>,<span class="string">&quot;Bearer &quot;</span>+jwt);</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>后端</category>
      </categories>
      <tags>
        <tag>sso</tag>
      </tags>
  </entry>
  <entry>
    <title>地址栏输入url之后经历的过程</title>
    <url>/essay/cf97c711.html</url>
    <content><![CDATA[<h1 id="在地址栏输入URL后，经历了那些过程"><a href="#在地址栏输入URL后，经历了那些过程" class="headerlink" title="在地址栏输入URL后，经历了那些过程"></a>在地址栏输入URL后，经历了那些过程</h1><h2 id="过程"><a href="#过程" class="headerlink" title="过程"></a>过程</h2><ol>
<li>DNS域名解析；</li>
<li>建立TCP连接；</li>
<li>发送HTTP请求；</li>
<li>服务器处理请求；</li>
<li>返回响应结果；</li>
<li>关闭TCP连接；</li>
<li>浏览器解析HTML；</li>
<li>浏览器布局渲染；</li>
</ol>
<a id="more"></a>

<h2 id="DNS域名解析"><a href="#DNS域名解析" class="headerlink" title="DNS域名解析"></a>DNS域名解析</h2><p>DNS是应用层协议，用于将用户提供的主机名解析为ip地址</p>
<p>我们在浏览器输入网址，其实就是要向服务器请求我们想要的页面内容，所以浏览器首先要确认的是域名所对应的服务器在哪里。将域名解析成对应的服务器IP地址这项工作，是由DNS服务器来完成的。</p>
<p>客户端收到你输入的域名地址后，它首先去找本地的hosts文件，检查在该文件中是否有相应的域名、IP对应关系，如果有，则向其IP地址发送请求，如果没有，再去找DNS服务器。一般用户很少去编辑修改hosts文件。</p>
<p>解析过程：</p>
<ol>
<li><p>首先搜索浏览器自身的DNS缓存（缓存命中），如果有，解析结束。浏览器自身的缓存时间比较短，可以通过TTL来进行设置，大概能存储1000条缓存。</p>
</li>
<li><p>浏览器自身缓存没有（缓存未命中）就去操作系统的缓存中查找</p>
</li>
<li><p>当浏览器及系统缓存中均无域名对应IP则进入路由器缓存中检查 host文件</p>
<p><strong>以上三步均为客服端的DNS缓存，都没有找的话就递归地去域名服务器去查找</strong></p>
</li>
<li><p>请求本地域名服务器（LDNS）解析域名</p>
</li>
<li><p>LDNS仍然没有命中，就直接跳到Root Server 域名服务器请求解析</p>
</li>
<li><p>根域名服务器返回给LDNS一个所查询域的主域名服务器（gTLD Server，例如 .com .cn等）</p>
</li>
<li><p>LDNS再发送请求给上一步返回的gTLD</p>
</li>
<li><p>接受请求的gTLD查找并返回这个域名对应的Name Server（网站注册的域名服务器）的地址</p>
</li>
<li><p>Name Server根据映射关系表找到目标ip，返回给LDNS</p>
</li>
<li><p>LDNS缓存这个域名和对应的ip并把解析的结果返回给用户，解析结束！</p>
</li>
</ol>
<p><img src="/essay/cf97c711/dns1.png" alt="dns1"></p>
<p><img src="/essay/cf97c711/dnschax.png" alt="dnschax"></p>
<h2 id="TCP-IP三握四挥"><a href="#TCP-IP三握四挥" class="headerlink" title="TCP/IP三握四挥"></a>TCP/IP三握四挥</h2><p><code>三次握手的目的</code><br>三次握手的最主要目的是保证连接是双工的，可靠更多的是通过重传机制来保证的。<br><code>为什么是三次握手</code><br>为了保证服务端能收接受到客户端的信息并能做出正确的应答而进行前两次(第一次和第二次)握手，为了保证客户端能够接收到服务端的信息并能做出正确的应答而进行后两次(第二次和第三次)握手。<br><code>三次握手的过程（建立连接）</code></p>
<ul>
<li>客户端发送SYN请求，进入SYN_SEND状态</li>
<li>服务端收到SYN请求，并返回一个ACK应答，并发送一个SYN其请求，服务器进入SYN_RECV状态</li>
<li>客户端收到服务端的SYN请求和ACK应答，发送ACK应答，客户端进入ESTABLISH状态，服务端收到应答后进入ESTABLISH。</li>
<li>如果没有收到ACK，数据包根据TCP重传机制进行重传</li>
</ul>
<p><img src="/essay/cf97c711/%E5%BB%BA%E7%AB%8Btcp%E9%93%BE%E6%8E%A5.png" alt="建立tcp链接"></p>
<p><code>四次挥手（断开连接）</code></p>
<ul>
<li>客户端发送FIN包，请求断开连接，客户端进入FIN_WAIT1状态</li>
<li>服务端收到FIN包后返回应答，进入CLOSE_WAIT状态</li>
<li>客户端收到FIN的应答后进入FIN_WAIT2状态</li>
<li>服务端发送FIN请求包，进入LAST_ACK状态</li>
<li>客户端收到FIN请求包后，发送应答进入TIME_WAIT状态</li>
<li>服务器收到ACK应答后，进入close状态</li>
</ul>
<p><img src="/essay/cf97c711/%E5%85%B3%E9%97%ADtcp%E8%BF%9E%E6%8E%A5.png" alt="关闭tcp连接"></p>
<p><code>为什么连接三次就够了，断开为什么需要四次</code></p>
<p>因为连接时，调用socket的connect函数发送SYN包，而服务器端只是accept一下，就一次发送了SYN和ACK标志位，而断开连接时我们都要调用各自的close函数结束这段socket，所以两次close分别触发了两次FIN包，导致没有和ACK合并为一个包，所以断开要4次握手。<br><code>请求头 Connection作用</code><br>请求头 Connection，Connection设置为 keep-alive用于说明 客户端这边设置的是，本次HTTP请求之后并不需要关闭TCP连接，这样可以使下次HTTP请求使用相同的TCP通道，节省TCP建立连接的时间</p>
<h2 id="发起http请求"><a href="#发起http请求" class="headerlink" title="发起http请求"></a>发起http请求</h2><p><code>HTTP请求报文的三个部分</code></p>
<ul>
<li>请求行：用于描述客户端的请求方式，请求的资源名称以及使用的HTTP协议的版本号（例：GET/books/java.html HTTP/1.1）</li>
<li>请求头：用于描述客户端请求哪台主机，以及客户端的一些环境信息等</li>
<li>请求正文：当使用POST, PUT等方法时，通常需要客户端向服务器传递数据</li>
</ul>
<p><img src="/essay/cf97c711/%E6%8A%A5%E6%96%87%E7%BB%93%E6%9E%84.png" alt="报文结构"></p>
<p><code>GET和POST区别</code></p>
<ul>
<li>GET在浏览器回退时是无害的，POST会再次提交请求</li>
<li>GET产生的URL地址可以被BookMark，而POST不可以</li>
<li>GET请求会被浏览器主动cache，POST不会，除非主动设置</li>
<li>GET请求只能进行URL编码，而POST支持多种编码方式</li>
<li>GET请求参数会被完整的保留在浏览器历史记录中，POST参数不会保留</li>
<li>GET请求在URL中传递的参数是有长度限制的，POST没有</li>
<li>GET只接受ASCII字符，POST没有限制</li>
<li>GET比POST更不安全，GET参数都暴露在了URL上</li>
<li>GET参数通过URL传递，POST参数放在Request Body中</li>
<li><strong><em>GET产生一个TCP数据包，POST产生两个TCP数据包</em></strong>（重大区别）</li>
</ul>
<p>GET：浏览器会把http header 和data一并发出去 服务器响应200 ok<br>POST：浏览器先发送header，服务器响应100 继续 浏览器再发送data，服务器响应 200 ok（Firefox只发一次）</p>
<blockquote>
<p>本质上是没有区别的，GET和POST是HTTP协议中的两种发送请求的方法。HTTP是基于TCP/IP的关于数据<br>如何在万维网中如何通信的协议。HTTP的底层是TCP/IP。所以GET和POST的底层也是TCP/IP，也就是说，<br>GET/POST都是TCP链接。GET和POST能做的事情是一样一样的。给GET加上request body，给POST带上<br>url参数，技术上是完全行的通的。 </p>
</blockquote>
<h2 id="服务器响应http请求，浏览器得到html代码"><a href="#服务器响应http请求，浏览器得到html代码" class="headerlink" title="服务器响应http请求，浏览器得到html代码"></a>服务器响应http请求，浏览器得到html代码</h2><p><code>HTTP响应也由三部分组成</code>：</p>
<ul>
<li><p>状态码：表示服务器对请求的处理结果</p>
<p>1xx：信息，请求收到，继续处理</p>
<p>2xx：成功，行为被成功地接受、理解和采纳</p>
<p>3xx：重定向，为完成请求，必须进一步执行的动作</p>
<p>4xx：客户端错误，请求包含语法错误或者请求无法实现</p>
<p>5xx：服务器错误，服务器不能实现一种明显无效的请求</p>
</li>
<li><p>响应头：响应头用于描述服务器的基本信息，以及客户端如何处理数据</p>
</li>
<li><p>实体内容：服务器返回给客户端的数据</p>
</li>
</ul>
<h2 id="浏览器解析html代码，并请求代码中所需的资源"><a href="#浏览器解析html代码，并请求代码中所需的资源" class="headerlink" title="浏览器解析html代码，并请求代码中所需的资源"></a>浏览器解析html代码，并请求代码中所需的资源</h2><ul>
<li>浏览器开始载入html代码，发现<code>&lt;head&gt;</code>标签内有一个<code>&lt;link&gt;</code>标签引用外部CSS文件</li>
<li>浏览器又发出CSS文件的请求，服务器返回这个CSS文件</li>
<li>浏览器继续载入html中<code>&lt;body&gt;</code>部分的代码，并且CSS文件已经拿到手了，可以开始渲染页面了</li>
<li>浏览器在代码中发现一个<code>&lt;img&gt;</code>标签引用了一张图片，向服务器发出请求。此时浏览器不会等到图片下载完，而是继续渲染后面的代码（Connection设置为 keep-alive）</li>
<li>服务器返回图片文件，由于图片占用了一定面积，影响了后面段落的排布，因此浏览器需要回过头来重新渲染这部分代码</li>
<li>浏览器发现了一个包含一行Javascript代码<code>&lt;script&gt;</code>的标签，赶快运行它</li>
<li>Javascript脚本执行（style.display=”none”）这条语句，它命令浏览器隐藏掉代码中的某个<code>&lt;div&gt;</code>，少了一个元素，浏览器不得不重新渲染这部分代码</li>
<li>终于执行到了的到来并没有结束，用户点了一下界面中的“换肤”按钮，Javascript让浏览器换了一下标签的CSS路径；</li>
<li>浏览器召集了在座的各位<code>&lt;div&gt;&lt;span&gt;&lt;ul&gt;&lt;li&gt;</code>们，“大伙儿收拾收拾行李，咱得重新来过……”，浏览器向服务器请求了新的CSS文件，重新渲染页面。</li>
</ul>
<h2 id="浏览器渲染页面"><a href="#浏览器渲染页面" class="headerlink" title="浏览器渲染页面"></a>浏览器渲染页面</h2><ul>
<li>解析html文件构成 DOM树</li>
<li>解析CSS文件构成渲染树</li>
<li>边解析，边渲染</li>
<li>JS 单线程运行，JS有可能修改DOM结构，意味着JS执行完成前，后续所有资源的下载是没有必要的，所以JS是单线程，会阻塞后续资源下载</li>
</ul>
<p><code>JS加载</code></p>
<ul>
<li>不能并行下载和解析（阻塞下载）</li>
<li>当引用了JS的时候，浏览器发送1个js request就会一直等待该request的返回。因为浏览器需要1个稳定的DOM树结构，而JS中很有可能有代码直接改变了DOM树结构，比如使用 document.write 或 appendChild,甚至是直接使用的location.href进行跳转，浏览器为了防止出现JS修改DOM树，需要重新构建DOM树的情况，所以 就会阻塞其他的下载和呈现。</li>
</ul>
<p>参考链接：</p>
<p><a href="https://blog.csdn.net/lc13571525583/article/details/90732553">https://blog.csdn.net/lc13571525583/article/details/90732553</a></p>
<p><a href="https://www.cnblogs.com/xiaoxin-test/p/13559905.html">https://www.cnblogs.com/xiaoxin-test/p/13559905.html</a></p>
]]></content>
  </entry>
  <entry>
    <title>垃圾回收算法</title>
    <url>/essay/ac7099b6.html</url>
    <content><![CDATA[<h1 id="垃圾回收相关算法"><a href="#垃圾回收相关算法" class="headerlink" title="垃圾回收相关算法"></a>垃圾回收相关算法</h1><blockquote>
<p>什么是垃圾？</p>
</blockquote>
<p>垃圾是指在运行程序中没有任何指针指向的对象，这个对象就是需要被回收的垃圾。</p>
<p>如果不及时对内存中的垃圾进行清理，那么，这些垃圾对象所占的内存空间会一直保留到应用程序的结束，被保留的空间无法被其它对象使用，甚至可能导致内存溢出。</p>
<a id="more"></a>

<h1 id="标记阶段"><a href="#标记阶段" class="headerlink" title="标记阶段"></a>标记阶段</h1><p>在堆里存放着几乎所有的Java对象实例，在GC执行垃圾回收之前，首先需要区分出内存中哪些是存活对象，哪些是已经死亡的对象。只有被标记为己经死亡的对象，GC才会在执行垃圾回收时，释放掉其所占用的内存空间，因此这个过程我们可以称为垃圾标记阶段。</p>
<p>那么在JVM中究竟是如何标记一个死亡对象呢？简单来说，当一个对象已经不再被任何的存活对象继续引用时，就可以宣判为已经死亡。</p>
<p>判断对象存活一般有两种方式：<strong>引用计数算法</strong>和<strong>可达性分析算法。</strong></p>
<h2 id="引用计数算法"><a href="#引用计数算法" class="headerlink" title="引用计数算法"></a>引用计数算法</h2><p>对每个对象保存一个整型的引用计数器属性。用于记录对象被引用的情况。</p>
<p>对于一个对象A，只要有任何一个对象引用了A，则A的引用计数器就加1；当引用失效时，引用计数器就减1。只要对象A的引用计数器的值为0，即表示对象A不可能再被使用，可进行回收。</p>
<p><code>优点</code>：实现简单，垃圾对象便于辨识；判定效率高，回收没有延迟性。</p>
<p><code>缺点</code>：它需要单独的字段存储计数器，这样的做法增加了存储空间的开销。</p>
<p>每次赋值都需要更新计数器，伴随着加法和减法操作，这增加了时间开销。<br>引用计数器有一个严重的问题，即<code>无法处理循环引用</code>的情况。这是一条致命缺陷，导致在Java的垃圾回收器中没有使用这类算法。</p>
<blockquote>
<p>循环引用</p>
</blockquote>
<p>当p的指针断开的时候，内部的引用形成一个循环，这就是循环引用，从而造成内存泄漏</p>
<img src="/essay/ac7099b6/循环引用.png" style="zoom: 67%;">

<h2 id="可达性分析算法"><a href="#可达性分析算法" class="headerlink" title="可达性分析算法"></a>可达性分析算法</h2><p>概念：</p>
<p>可达性分析算法：也可以称为 根搜索算法、追踪性垃圾收集</p>
<p>相对于引用计数算法而言，可达性分析算法不仅同样具备实现简单和执行高效等特点，更重要的是该算法可以有效地解决在引用计数算法中循环引用的问题，防止内存泄漏的发生。</p>
<p>相较于引用计数算法，这里的可达性分析就是Java、C#选择的。这种类型的垃圾收集通常也叫作追踪性垃圾收集（Tracing Garbage Collection）</p>
<p>基本思路：</p>
<ul>
<li>可达性分析算法是以根对象集合（GCRoots）为起始点，按照从上至下的方式搜索被根对象集合所连接的目标对象是否可达。</li>
<li>使用可达性分析算法后，内存中的存活对象都会被根对象集合直接或间接连接着，搜索所走过的路径称为引用链（Reference Chain）</li>
<li>如果目标对象没有任何引用链相连，则是不可达的，就意味着该对象己经死亡，可以标记为垃圾对象。</li>
<li>在可达性分析算法中，只有能够被根对象集合直接或者间接连接的对象才是存活对象。</li>
</ul>
<h1 id="清除阶段："><a href="#清除阶段：" class="headerlink" title="清除阶段："></a>清除阶段：</h1><p>当成功区分出内存中存活对象和死亡对象后，GC接下来的任务就是执行垃圾回收，释放掉无用对象所占用的内存空间，以便有足够的可用内存空间为新对象分配内存。目前在JVM中比较常见的三种垃圾收集算法是</p>
<ul>
<li>标记一清除算法（Mark-Sweep）</li>
<li>复制算法（copying）</li>
<li>标记-压缩算法（Mark-Compact）</li>
</ul>
<h2 id="标记-清除算法"><a href="#标记-清除算法" class="headerlink" title="标记-清除算法"></a>标记-清除算法</h2><blockquote>
<p>执行过程</p>
</blockquote>
<p>当堆中的有效内存空间（available memory）被耗尽的时候，就会停止整个程序（也被称为stop the world），然后进行两项工作，第一项则是标记，第二项则是清除</p>
<ul>
<li><strong>标记</strong>：Collector从引用根节点开始遍历，<strong>标记所有被引用的对象</strong>。一般是在对象的Header中记录为可达对象。<ul>
<li><strong>标记的是引用的对象，不是垃圾！！</strong></li>
</ul>
</li>
<li><strong>清除</strong>：Collector对堆内存从头到尾进行线性的遍历，如果发现某个对象在其Header中没有标记为可达对象，则将其回收</li>
</ul>
<img src="/essay/ac7099b6/mark-sweep.png" style="zoom: 50%;">

<blockquote>
<p>什么是清除？</p>
</blockquote>
<p>这里所谓的清除并不是真的置空，而是把需要清除的对象地址保存在空闲的地址列表里。下次有新对象需要加载时，判断垃圾的位置空间是否够，如果够，就存放覆盖原有的地址。</p>
<p>关于空闲列表是在为对象分配内存的时候 提过</p>
<ul>
<li>如果内存规整<ul>
<li>采用指针碰撞的方式进行内存分配</li>
</ul>
</li>
<li>如果内存不规整<ul>
<li>虚拟机需要维护一个列表</li>
<li>空闲列表分配</li>
</ul>
</li>
</ul>
<h3 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h3><ul>
<li>标记清除算法的效率不算高</li>
<li>在进行GC的时候，需要停止整个应用程序，用户体验较差</li>
<li>这种方式清理出来的空闲内存是不连续的，产生内碎片，需要维护一个空闲列表</li>
</ul>
<h2 id="复制算法"><a href="#复制算法" class="headerlink" title="复制算法"></a>复制算法</h2><h3 id="核心思想"><a href="#核心思想" class="headerlink" title="核心思想"></a>核心思想</h3><p>将活着的内存空间分为两块，每次只使用其中一块，在垃圾回收时将正在使用的内存中的存活对象复制到未被使用的内存块中，之后清除正在使用的内存块中的所有对象，交换两个内存的角色，最后完成垃圾回收</p>
<p><img src="/essay/ac7099b6/copying.png"></p>
<p>把可达的对象，直接复制到另外一个区域中复制完成后，A区就没有用了，里面的对象可以直接清除掉，其实里面的新生代里面就用到了复制算法</p>
<p><img src="/essay/ac7099b6/young.png"></p>
<h3 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h3><ul>
<li>没有标记和清除过程，实现简单，运行高效</li>
<li>复制过去以后保证空间的连续性，不会出现“碎片”问题。</li>
</ul>
<h3 id="缺点-1"><a href="#缺点-1" class="headerlink" title="缺点"></a>缺点</h3><ul>
<li>此算法的缺点也是很明显的，就是需要两倍的内存空间。</li>
<li>对于G1这种分拆成为大量region的GC，复制而不是移动，意味着GC需要维护region之间对象引用关系，不管是内存占用或者时间开销也不小</li>
</ul>
<h3 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h3><p>如果系统中的垃圾对象很多，复制算法不会很理想。因为复制算法需要复制的存活对象数量并不会太大，或者说非常低才行（老年代大量的对象存活，那么复制的对象将会有很多，效率会很低）</p>
<p>在新生代，对常规应用的垃圾回收，一次通常可以回收70% - 99% 的内存空间。回收性价比很高。所以现在的商业虚拟机都是用这种收集算法回收新生代。</p>
<blockquote>
<p>为什么新生代要使用复制算法？</p>
</blockquote>
<p>具体问题具体分析，没有最好的算法，只有最合适的算法。</p>
<p>新生代区中的对象98%都是朝生夕死的，使用复制算法很好的解决了碎片化的问题。并且由于需要复制的存活对象不是很多。</p>
<p>恰好符合复制算法的限制。而符合这一标准之后，这就是最快的回收算法了。</p>
<h2 id="标记-整理算法"><a href="#标记-整理算法" class="headerlink" title="标记-整理算法"></a>标记-整理算法</h2><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>复制算法的高效性是建立在存活对象少、垃圾对象多的前提下的。这种情况在新生代经常发生，但是在老年代，更常见的情况是大部分对象都是存活对象。如果依然使用复制算法，由于存活对象较多，复制的成本也将很高。因此，基于老年代垃圾回收的特性，需要使用其他的算法。</p>
<p>标记一清除算法的确可以应用在老年代中，但是该算法不仅执行效率低下，而且在执行完内存回收后还会产生内存碎片，所以JvM的设计者需要在此基础之上进行改进。标记-压缩（Mark-Compact）算法由此诞生。</p>
<p>1970年前后，G.L.Steele、C.J.Chene和D.s.Wise等研究者发布标记-压缩算法。在许多现代的垃圾收集器中，人们都使用了标记-压缩算法或其改进版本。</p>
<h3 id="执行过程"><a href="#执行过程" class="headerlink" title="执行过程"></a>执行过程</h3><p>第一阶段和标记清除算法一样，从根节点开始标记所有被引用对象</p>
<p>第二阶段将所有的存活对象压缩到内存的一端，按顺序排放。之后，清理边界外所有的空间。</p>
<img src="/essay/ac7099b6/mark-compact.png" style="zoom: 67%;">

<h3 id="标清和标整的区别"><a href="#标清和标整的区别" class="headerlink" title="标清和标整的区别"></a>标清和标整的区别</h3><p>标记-压缩算法的最终效果等同于标记-清除算法执行完成后，再进行一次内存碎片整理，因此，也可以把它称为标记-清除-压缩（Mark-Sweep-Compact）算法。</p>
<p>二者的本质差异在于标记-清除算法是一种非移动式的回收算法，标记-压缩是移动式的。是否移动回收后的存活对象是一项优缺点并存的风险决策。可以看到，标记的存活对象将会被整理，按照内存地址依次排列，而未被标记的内存会被清理掉。如此一来，当我们需要给新对象分配内存时，JVM只需要持有一个内存的起始地址即可，这比维护一个空闲列表显然少了许多开销。</p>
<h3 id="标整的优缺点"><a href="#标整的优缺点" class="headerlink" title="标整的优缺点"></a>标整的优缺点</h3><h4 id="优点-1"><a href="#优点-1" class="headerlink" title="优点"></a>优点</h4><ul>
<li>消除了标记-清除算法当中，内存区域分散的缺点，我们需要给新对象分配内存时，JVM只需要持有一个内存的起始地址即可。</li>
<li>消除了复制算法当中，内存减半的高额代价。</li>
</ul>
<h4 id="缺点-2"><a href="#缺点-2" class="headerlink" title="缺点"></a>缺点</h4><ul>
<li>从效率上来说，标记-整理算法要低于复制算法。</li>
<li>移动对象的同时，如果对象被其他对象引用，则还需要调整引用的地址</li>
<li>移动过程中，需要全程暂停用户应用程序。即：STW</li>
</ul>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>效率上来说，复制算法是效率最高的，但是却浪费了太多内存。</p>
<p>而为了尽量兼顾上面提到的三个指标，标记-整理算法相对来说更平滑一些，但是效率上不尽如人意，它比复制算法多了一个标记的阶段，比标记-清除多了一个整理内存的阶段。</p>
<table>
<thead>
<tr>
<th></th>
<th>标记清除</th>
<th>标记整理</th>
<th>复制</th>
</tr>
</thead>
<tbody><tr>
<td><strong>速率</strong></td>
<td>中等</td>
<td>最慢</td>
<td>最快</td>
</tr>
<tr>
<td><strong>空间开销</strong></td>
<td>少（但会堆积碎片）</td>
<td>少（不堆积碎片）</td>
<td>通常需要活对象的2倍空间（不堆积碎片）</td>
</tr>
<tr>
<td><strong>移动对象</strong></td>
<td>否</td>
<td>是</td>
<td>是</td>
</tr>
</tbody></table>
<p>综合我们可以找到，没有最好的算法，只有最合适的算法</p>
<h2 id="分代收集算法"><a href="#分代收集算法" class="headerlink" title="分代收集算法"></a>分代收集算法</h2><p>前面所有这些算法中，并没有一种算法可以完全替代其他算法，它们都具有自己独特的优势和特点。分代收集算法应运而生。</p>
<p>分代收集算法，是基于这样一个事实：不同的对象的生命周期是不一样的。因此，不同生命周期的对象可以采取不同的收集方式，以便提高回收效率。一般是把Java堆分为新生代和老年代，这样就可以根据各个年代的特点使用不同的回收算法，以提高垃圾回收的效率。</p>
<p>在Java程序运行的过程中，会产生大量的对象，其中有些对象是与业务信息相关，比如Http请求中的Session对象、线程、Socket连接，这类对象跟业务直接挂钩，因此生命周期比较长。但是还有一些对象，主要是程序运行过程中生成的临时变量，这些对象生命周期会比较短，比如：string对象，由于其不变类的特性，系统会产生大量的这些对象，有些对象甚至只用一次即可回收。</p>
<p>目前几乎所有的GC都采用分代手机算法执行垃圾回收的</p>
<p>在HotSpot中，基于分代的概念，GC所使用的内存回收算法必须结合年轻代和老年代各自的特点。</p>
<ul>
<li>年轻代（Young Gen）</li>
</ul>
<p>年轻代特点：区域相对老年代较小，对象生命周期短、存活率低，回收频繁。</p>
<p>这种情况复制算法的回收整理，速度是最快的。复制算法的效率只和当前存活对象大小有关，因此很适用于年轻代的回收。而复制算法内存利用率不高的问题，通过hotspot中的两个survivor的设计得到缓解。</p>
<ul>
<li>老年代（Tenured Gen）</li>
</ul>
<p>老年代特点：区域较大，对象生命周期长、存活率高，回收不及年轻代频繁。</p>
<p>这种情况存在大量存活率高的对象，复制算法明显变得不合适。一般是由标记-清除或者是标记-清除与标记-整理的混合实现。</p>
<ul>
<li>Mark阶段的开销与存活对象的数量成正比。</li>
<li>Sweep阶段的开销与所管理区域的大小成正相关。</li>
<li>compact阶段的开销与存活对象的数据成正比。</li>
</ul>
<p>以HotSpot中的CMS回收器为例，CMS是基于Mark-Sweep实现的，对于对象的回收效率很高。而对于碎片问题，CMS采用基于Mark-Compact算法的Serial old回收器作为补偿措施：当内存回收不佳（碎片导致的Concurrent Mode Failure时），将采用serial old执行FullGC以达到对老年代内存的整理。</p>
<p>分代的思想被现有的虚拟机广泛使用。几乎所有的垃圾回收器都区分新生代和老年代</p>
<h2 id="增量收集算法"><a href="#增量收集算法" class="headerlink" title="增量收集算法"></a>增量收集算法</h2><h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><p>上述现有的算法，在垃圾回收过程中，应用软件将处于一种stop the World的状态。在stop the World状态下，应用程序所有的线程都会挂起，暂停一切正常的工作，等待垃圾回收的完成。如果垃圾回收时间过长，应用程序会被挂起很久，将严重影响用户体验或者系统的稳定性。为了解决这个问题，即对实时垃圾收集算法的研究直接导致了增量收集（Incremental Collecting）算法的诞生。</p>
<p>如果一次性将所有的垃圾进行处理，需要造成系统长时间的停顿，那么就可以让垃圾收集线程和应用程序线程交替执行。每次，垃圾收集线程只收集一小片区域的内存空间，接着切换到应用程序线程。依次反复，直到垃圾收集完成。</p>
<p>总的来说，增量收集算法的基础仍是传统的标记-清除和复制算法。<strong>增量收集算法通过对线程间冲突的妥善处理</strong>，允许垃圾收集线程以分阶段的方式完成标记、清理或复制工作</p>
<h3 id="缺点-3"><a href="#缺点-3" class="headerlink" title="缺点"></a>缺点</h3><p>使用这种方式，由于在垃圾回收过程中，间断性地还执行了应用程序代码，所以能减少系统的停顿时间。但是，因为线程切换和上下文转换的消耗，会使得垃圾回收的总体成本上升，造成系统吞吐量的下降。</p>
<h2 id="分区算法"><a href="#分区算法" class="headerlink" title="分区算法"></a>分区算法</h2><p>一般来说，在相同条件下，堆空间越大，一次Gc时所需要的时间就越长，有关GC产生的停顿也越长。为了更好地控制GC产生的停顿时间，将一块大的内存区域分割成多个小块，根据目标的停顿时间，每次合理地回收若干个小区间，而不是整个堆空间，从而减少一次GC所产生的停顿。</p>
<p>分代算法将按照对象的生命周期长短划分成两个部分，分区算法将整个堆空间划分成连续的不同小区间。<br>每一个小区间都独立使用，独立回收。这种算法的好处是可以控制一次回收多少个小区间。</p>
<img src="/essay/ac7099b6/分区算法.png" style="zoom:67%;">

<p>注意，这些只是基本的算法思路，实际GC实现过程要复杂的多，目前还在发展中的前沿GC都是复合算法，并且并行和并发兼备。</p>
]]></content>
      <categories>
        <category>jvm</category>
      </categories>
      <tags>
        <tag>gc</tag>
      </tags>
  </entry>
  <entry>
    <title>新生代分区比例的思考</title>
    <url>/essay/a12043e8.html</url>
    <content><![CDATA[<h2 id="疑问"><a href="#疑问" class="headerlink" title="疑问"></a>疑问</h2><p>为什么年轻代中三个区（Eden，S0，S1）的比例是8:1:1呢？为什么不能是7:2:1？6:2:2？</p>
<a id="more"></a>

<h2 id="堆中区域分布"><a href="#堆中区域分布" class="headerlink" title="堆中区域分布"></a>堆中区域分布</h2><p><img src="/essay/a12043e8/%E5%A0%86%E5%88%86%E5%8C%BA.png"></p>
<p>上图是不考虑细节而画出来的粗略的堆中的区域分布</p>
<ul>
<li><p>Eden：From：to ——&gt;  8:1:1</p>
</li>
<li><p>新生代：老年代  ——&gt;  1 : 2</p>
</li>
</ul>
<h2 id="预备知识"><a href="#预备知识" class="headerlink" title="预备知识"></a>预备知识</h2><p>我们创建的对象，一般都是存放在Eden区的，当我们Eden区满了后，就会触发GC操作，一般被称为 YGC / Minor GC操作</p>
<p>在这期间为了保证引用更新的正确性，Java将暂停所有其他的线程，这种情况被称为“Stop-The-World”</p>
<p><img src="/essay/a12043e8/ygc1.png"></p>
<p>当我们进行一次垃圾收集后，红色的将会被回收，而绿色的还会被占用着，存放在S0(Survivor From)区。同时我们给每个对象设置了一个年龄计数器，一次回收后就是1。</p>
<p>同时Eden区继续存放对象，当Eden区再次存满的时候，又会触发一个MinorGC操作，此时GC将会把 Eden和Survivor From中的对象 进行一次收集，把存活的对象放到 Survivor To区，同时让年龄 + 1</p>
<ul>
<li>这里实际上使用的就是复制算法，将可触及的对象复制到to区，这样YGC会直接清空from区</li>
</ul>
<p><img src="/essay/a12043e8/ygc2.png" alt="ygc2"></p>
<p>我们继续不断的进行对象生成 和 垃圾回收，当Survivor中的对象的年龄达到15的时候，将会触发一次 Promotion晋升的操作，也就是将年轻代中的对象  晋升到 老年代中</p>
<p><img src="/essay/a12043e8/ygc3.png" alt="ygc3"></p>
<p>特别注意，在Eden区满了的时候，才会触发MinorGC，而幸存者区满了后，不会触发MinorGC操作</p>
<ul>
<li><code>如果Survivor区满了后，将会触发一些特殊的规则，也就是可能直接晋升 老年代</code></li>
</ul>
<h2 id="解答"><a href="#解答" class="headerlink" title="解答"></a>解答</h2><p>那么回到最开始的问题，年轻代的比例为什么是8:1:1呢？我不能让Eden区大一点？或者S1或S2大一点？</p>
<p>首先开始解答：</p>
<p>由于S0 和 S1 区使用的是复制算法，则这两个区域的大小肯定是一样的</p>
<blockquote>
<p>假如Eden区域占比极大，假如说是占99%</p>
</blockquote>
<ol>
<li>在YGC之后，会产生幸存对象存到S1区，但是此时s1区太小了，很容易就满了。</li>
<li>而当幸存者区的区域满了之后，每次都有很多对象直接晋升到老年代区域中去。</li>
<li>老年代很快被填满，触发Major GC（因为Major GC一般伴随着Minor GC，也可以看做触发了Full GC）。</li>
<li>老年代的内存空间远大于新生代，进行一次Full GC消耗的时间比Minor GC长得多。频发的Full GC消耗的时间是非常可观的，这一点会影响大型程序的执行和响应速度，更不要说某些连接会因为超时发生连接错误了。</li>
</ol>
<blockquote>
<p>假如Eden区域和幸存者区域占比为4:3:3 或者幸存者区占比更大一点</p>
</blockquote>
<ol>
<li>由于Eden区域占据区域很小，当对象生成过快或者对象过大时。会在Eden区快满的时候YGC。</li>
<li>注意：<code>Survivor区域并不会触发YGC，但是会在YGC时一并清理。</code></li>
<li>空间变小，意味着YGC的频率更快了。则Stop-The-World的情况也会发生的频繁，影响效率。</li>
<li>从复制算法的角度来讲：此算法对于G1这种分拆成为大量region的GC，复制而不是移动，意味着GC需要维护region之间对象引用关系，不管是内存占用或者时间开销也不小。所以复制算法需要复制的存活对象数量并不会太大，或者说非常低才行（老年代大量的对象存活，那么复制的对象将会有很多，效率会很低）。</li>
</ol>
]]></content>
      <categories>
        <category>jvm</category>
      </categories>
  </entry>
  <entry>
    <title>虚拟机搭建hadoop集群</title>
    <url>/essay/203daf3e.html</url>
    <content><![CDATA[<h1 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">centos 8.5.2</span><br><span class="line">hadoop 3.1.3</span><br><span class="line">jdk 1.8.0_212</span><br></pre></td></tr></table></figure>
<p>准备虚拟机hadoop100，hadoop101，hadoop102（hadoop101，hadoop102后续从hadoop100克隆出来）</p>
<a id="more"></a>

<h1 id="系统设置"><a href="#系统设置" class="headerlink" title="系统设置"></a>系统设置</h1><h3 id="关闭防火墙"><a href="#关闭防火墙" class="headerlink" title="关闭防火墙"></a>关闭防火墙</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl stop firewalld</span><br></pre></td></tr></table></figure>
<h3 id="禁止自启防火墙"><a href="#禁止自启防火墙" class="headerlink" title="禁止自启防火墙"></a>禁止自启防火墙</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl disable firewalld.service</span><br></pre></td></tr></table></figure>
<h3 id="创建用户"><a href="#创建用户" class="headerlink" title="创建用户"></a>创建用户</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">useradd sudatime</span><br><span class="line">passwd sudatime</span><br></pre></td></tr></table></figure>
<h3 id="配置-sudatime用户"><a href="#配置-sudatime用户" class="headerlink" title="配置 sudatime用户"></a>配置 sudatime用户</h3><p>配置root 权限，方便后期加 sudo 执行 root 权限的命令</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vim /etc/sudoers</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># Allow root to run any commands anywhere</span></span> </span><br><span class="line">root	ALL=(ALL) 	ALL</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># Allows members of the &#x27;sys&#x27; group to run networking, software,</span></span> </span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># service management apps and more.</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> %sys ALL = NETWORKING, SOFTWARE, SERVICES, STORAGE, DELEGATING, PROCESSES, LOCATE, DRIVERS</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># Allows people in group wheel to run all commands</span></span></span><br><span class="line"><span class="meta">%</span><span class="bash">wheel	ALL=(ALL)	ALL</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># Same thing without a password</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> %wheel	ALL=(ALL)	NOPASSWD: ALL</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># Allows members of the users group to mount and unmount the</span></span> </span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># cdrom as root</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> %users  ALL=/sbin/mount /mnt/cdrom, /sbin/umount /mnt/cdrom</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 一定要在%wheel的下面</span></span><br><span class="line">sudatime ALL=(ALL) NOPASSWD:ALL</span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># Allows members of the users group to shutdown this system</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> %users  localhost=/sbin/shutdown -h now</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># Read drop-in files from /etc/sudoers.d (the # here does not mean a comment)</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash">includedir /etc/sudoers.d</span></span><br></pre></td></tr></table></figure>
<h3 id="目录配置"><a href="#目录配置" class="headerlink" title="目录配置"></a>目录配置</h3><p>在/opt 目录下创建文件夹，并修改所属主和所属组</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 存放hadoop</span></span><br><span class="line">mkdir /opt/module </span><br><span class="line">mkdir /opt/software</span><br></pre></td></tr></table></figure>
<p>修改 module、software 文件夹的所有者和所属组均为 sudatime用户</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">chown sudatime:sudatime /opt/module</span><br><span class="line">chown sudatime:sudatime /opt/software</span><br></pre></td></tr></table></figure>
<p>查看 module、software 文件夹的所有者和所属组</p>
<p><img src="/essay/203daf3e/image-20220314160022827.png"></p>
<h3 id="卸载虚拟机自带的-JDK"><a href="#卸载虚拟机自带的-JDK" class="headerlink" title="卸载虚拟机自带的 JDK"></a>卸载虚拟机自带的 JDK</h3><p>如果没有可以不用卸载</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">rpm -qa | grep -i java | xargs -n1 rpm -e --nodeps</span><br></pre></td></tr></table></figure>
<h3 id="上传资源包"><a href="#上传资源包" class="headerlink" title="上传资源包"></a>上传资源包</h3><p>设置上传目录</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">makedir -p /usr/local/download</span><br></pre></td></tr></table></figure>
<p>上传hadoop-3.1.3.tar.gz，jdk-8u212-linux-x64.tar.gz到 /usr/local/download</p>
<p><img src="/essay/203daf3e/image-20220314160636200.png"></p>
<h3 id="解压资源"><a href="#解压资源" class="headerlink" title="解压资源"></a>解压资源</h3><p>设置jdk目录</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">makedir -p /usr/local/developer/env/Java</span><br></pre></td></tr></table></figure>
<p>解压jdk</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tar -zxvf jdk-8u212-linux-x64.tar.gz -C /usr/<span class="built_in">local</span>/developer/env/Java</span><br></pre></td></tr></table></figure>
<p>解压hadoop</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tar -zxvf hadoop-3.1.3.tar.gz -C /opt/module/</span><br></pre></td></tr></table></figure>
<p>将hadoop的资源目录所有者更改为sudatime，解压之后的所有者是user</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">chowm -R sudatime:sudatime /opt/module/hadoop-3.1.3/</span><br></pre></td></tr></table></figure>
<h3 id="配置环境变量"><a href="#配置环境变量" class="headerlink" title="配置环境变量"></a>配置环境变量</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vim /etc/profile</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#最下面添加</span></span><br><span class="line"><span class="comment">#set java environment</span></span><br><span class="line">JAVA_HOME=/usr/<span class="built_in">local</span>/developer/env/Java/jdk1.8.0_212</span><br><span class="line">PATH=<span class="variable">$PATH</span>:<span class="variable">$JAVA_HOME</span>/bin</span><br><span class="line">CLASSPATH=.:<span class="variable">$JAVA_HOME</span>/lib/dt.jar:<span class="variable">$JAVA_HOME</span>/lib/tools.jar</span><br><span class="line"><span class="built_in">export</span> JAVA_HOME CLASSPATH PATH</span><br><span class="line"></span><br><span class="line"><span class="comment">#HADOOP_HOME</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_HOME=/opt/module/hadoop-3.1.3</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$HADOOP_HOME</span>/bin</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$HADOOP_HOME</span>/sbin</span><br></pre></td></tr></table></figure>
<p>让修改后的文件生效</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">source</span> /etc/profile</span><br></pre></td></tr></table></figure>
<p>测试是否生效</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@hadoop100 ~]<span class="comment"># java -version</span></span><br><span class="line">java version <span class="string">&quot;1.8.0_212&quot;</span></span><br><span class="line">Java(TM) SE Runtime Environment (build 1.8.0_212-b10)</span><br><span class="line">Java HotSpot(TM) 64-Bit Server VM (build 25.212-b10, mixed mode)</span><br><span class="line">[root@hadoop100 ~]<span class="comment"># hadoop version</span></span><br><span class="line">Hadoop 3.1.3</span><br><span class="line">Source code repository https://gitbox.apache.org/repos/asf/hadoop.git -r ba631c436b806728f8ec2f54ab1e289526c90579</span><br><span class="line">Compiled by ztang on 2019-09-12T02:47Z</span><br><span class="line">Compiled with protoc 2.5.0</span><br><span class="line">From <span class="built_in">source</span> with checksum ec785077c385118ac91aadde5ec9799</span><br><span class="line">This <span class="built_in">command</span> was run using /opt/module/hadoop-3.1.3/share/hadoop/common/hadoop-common-3.1.3.jar</span><br></pre></td></tr></table></figure>
<p>关闭虚拟机</p>
<h1 id="克隆虚拟机"><a href="#克隆虚拟机" class="headerlink" title="克隆虚拟机"></a>克隆虚拟机</h1><p><img src="/essay/203daf3e/image-20220314161659576.png"></p>
<p>克隆出来hadoop101和hadoop102</p>
<h2 id="系统设置-1"><a href="#系统设置-1" class="headerlink" title="系统设置"></a>系统设置</h2><h3 id="修改主机名"><a href="#修改主机名" class="headerlink" title="修改主机名"></a>修改主机名</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vim /etc/hostname</span><br><span class="line"></span><br><span class="line">分别修改为 hadoop100，hadoop101，hadoop102</span><br></pre></td></tr></table></figure>
<h3 id="修改静态IP"><a href="#修改静态IP" class="headerlink" title="修改静态IP"></a>修改静态IP</h3><p>以hadoop100为例</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># ifcfg-ensxx 有什么就是什么</span></span><br><span class="line">vim /etc/sysconfig/network-scripts/ifcfg-ens160</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">TYPE=Ethernet</span><br><span class="line">PROXY_METHOD=none</span><br><span class="line">BROWSER_ONLY=no</span><br><span class="line"><span class="comment"># 修改为static</span></span><br><span class="line">BOOTPROTO=static</span><br><span class="line">DEFROUTE=yes</span><br><span class="line">IPV4_FAILURE_FATAL=no</span><br><span class="line">IPV6INIT=yes</span><br><span class="line">IPV6_AUTOCONF=yes</span><br><span class="line">IPV6_DEFROUTE=yes</span><br><span class="line">IPV6_FAILURE_FATAL=no</span><br><span class="line">NAME=ens160</span><br><span class="line">UUID=b6827765-b0c1-48ff-afda-5eefb072de3f</span><br><span class="line">DEVICE=ens160</span><br><span class="line">ONBOOT=yes</span><br><span class="line"><span class="comment"># 修改静态的ip</span></span><br><span class="line">IPADDR=192.168.200.100</span><br><span class="line"><span class="comment"># 设置网关</span></span><br><span class="line">GATEWAY=192.168.200.2</span><br><span class="line"><span class="comment"># 设置DNS解析</span></span><br><span class="line">DNS1=192.168.200.2</span><br></pre></td></tr></table></figure>
<p>注意：网关和DNS解析需要和VM虚拟机设置保持一致，以及IP需要是该网段的子网</p>
<p><img src="/essay/203daf3e/image-20220314162238885.png"></p>
<p><img src="/essay/203daf3e/image-20220314162302197.png"></p>
<h3 id="修改hosts解析"><a href="#修改hosts解析" class="headerlink" title="修改hosts解析"></a>修改hosts解析</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vim /etc/hosts</span><br></pre></td></tr></table></figure>
<p>添加内容 （3台都配置）</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">192.168.200.100 hadoop100</span><br><span class="line">192.168.200.101 hadoop101</span><br><span class="line">192.168.200.102 hadoop102</span><br></pre></td></tr></table></figure>
<p>重启虚拟机</p>
<p>配置完之后需要三台之间能够ping通</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ping hadoop100</span><br><span class="line">ping hadoop101</span><br><span class="line">ping hadoop102</span><br></pre></td></tr></table></figure>
<h1 id="集群搭建"><a href="#集群搭建" class="headerlink" title="集群搭建"></a>集群搭建</h1><h2 id="编写集群分发脚本"><a href="#编写集群分发脚本" class="headerlink" title="编写集群分发脚本"></a>编写集群分发脚本</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="comment">#1. 判断参数个数</span></span><br><span class="line"><span class="keyword">if</span> [ <span class="variable">$#</span> -lt 1 ]</span><br><span class="line"><span class="keyword">then</span></span><br><span class="line"> <span class="built_in">echo</span> Not Enough Arguement!</span><br><span class="line"> <span class="built_in">exit</span>;</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"><span class="comment">#2. 遍历集群所有机器</span></span><br><span class="line"><span class="keyword">for</span> host <span class="keyword">in</span> hadoop100 hadoop101 hadoop102</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line"> <span class="built_in">echo</span> ==================== <span class="variable">$host</span> ====================</span><br><span class="line"> <span class="comment">#3. 遍历所有目录，挨个发送</span></span><br><span class="line"> <span class="keyword">for</span> file <span class="keyword">in</span> <span class="variable">$@</span></span><br><span class="line"> <span class="keyword">do</span></span><br><span class="line"> <span class="comment">#4. 判断文件是否存在</span></span><br><span class="line"> <span class="keyword">if</span> [ -e <span class="variable">$file</span> ]</span><br><span class="line"> <span class="keyword">then</span></span><br><span class="line"> <span class="comment">#5. 获取父目录</span></span><br><span class="line"> pdir=$(<span class="built_in">cd</span> -P $(dirname <span class="variable">$file</span>); <span class="built_in">pwd</span>)</span><br><span class="line"> <span class="comment">#6. 获取当前文件的名称</span></span><br><span class="line"> fname=$(basename <span class="variable">$file</span>)</span><br><span class="line"> ssh <span class="variable">$host</span> <span class="string">&quot;mkdir -p <span class="variable">$pdir</span>&quot;</span></span><br><span class="line"> rsync -av <span class="variable">$pdir</span>/<span class="variable">$fname</span> <span class="variable">$host</span>:<span class="variable">$pdir</span></span><br><span class="line"> <span class="keyword">else</span></span><br><span class="line"> <span class="built_in">echo</span> <span class="variable">$file</span> does not exists!</span><br><span class="line"> <span class="keyword">fi</span></span><br><span class="line"> <span class="keyword">done</span></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure>
<h2 id="修改脚本-xsync-权限"><a href="#修改脚本-xsync-权限" class="headerlink" title="修改脚本 xsync 权限"></a>修改脚本 xsync 权限</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">chmod +x xsync</span><br></pre></td></tr></table></figure>
<p>放到/bin下面供全局调用</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo cp xsync /bin/</span><br></pre></td></tr></table></figure>
<h2 id="SSH免密登录"><a href="#SSH免密登录" class="headerlink" title="SSH免密登录"></a>SSH免密登录</h2><p>hadoop100切换到root用户（hadoop101，hadoop102登录用户为sudatime）</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ssh-keygen -t rsa</span><br></pre></td></tr></table></figure>
<p>然后敲（三个回车），就会生成两个文件 id_rsa（私钥）、id_rsa.pub（公钥）</p>
<p>将公钥拷贝到要免密登录的目标机器上</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ssh-copy-id hadoop100</span><br><span class="line">ssh-copy-id hadoop101</span><br><span class="line">ssh-copy-id hadoop102</span><br></pre></td></tr></table></figure>
<p>拷贝完之后即可实现</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ssh hadoop100</span><br><span class="line">ssh hadoop101</span><br><span class="line">ssh hadoop102</span><br></pre></td></tr></table></figure>
<p>不需要输入密码即可直接登录，exit退出</p>
<h1 id="集群配置"><a href="#集群配置" class="headerlink" title="集群配置"></a>集群配置</h1><h2 id="配置-core-site-xml"><a href="#配置-core-site-xml" class="headerlink" title="配置 core-site.xml"></a>配置 core-site.xml</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> <span class="variable">$HADOOP_HOME</span>/etc/hadoop</span><br><span class="line">vim core-site.xml</span><br></pre></td></tr></table></figure>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 指定 NameNode 的地址 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://hadoop100:8020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 指定 hadoop 数据的存储目录 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/module/hadoop-3.1.3/data<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 配置 HDFS 网页登录使用的静态用户为 sudatime --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.http.staticuser.user<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>sudatime<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--指定hadoop运行时产生的临时文件存放目录--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tem.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/hadoop-3.1.3/temp<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h2 id="配置-hdfs-site-xml"><a href="#配置-hdfs-site-xml" class="headerlink" title="配置 hdfs-site.xml"></a>配置 hdfs-site.xml</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vim hdfs-site.xml</span><br></pre></td></tr></table></figure>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- nn web 端访问地址--&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.http-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop100:9870<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- 2nn web 端访问地址--&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.secondary.http-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop102:9868<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h2 id="配置-yarn-site-xml"><a href="#配置-yarn-site-xml" class="headerlink" title="配置 yarn-site.xml"></a>配置 yarn-site.xml</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vim yarn-site.xml</span><br></pre></td></tr></table></figure>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot;?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">&lt;!-- Site specific YARN configuration properties --&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- 指定 MR 走 shuffle --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- 指定 ResourceManager 的地址--&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop101<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- 环境变量的继承 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.env-whitelist<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CO</span><br><span class="line"> NF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAP</span><br><span class="line"> RED_HOME<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">&lt;!-- 开启日志聚集功能 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log-aggregation-enable<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- 设置日志聚集服务器地址 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log.server.url<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>http://hadoop100:19888/jobhistory/logs<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="comment">&lt;!-- 设置日志保留时间为 7 天 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log-aggregation.retain-seconds<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>604800<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h2 id="配置-workers"><a href="#配置-workers" class="headerlink" title="配置 workers"></a>配置 workers</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vim /opt/module/hadoop-3.1.3/etc/hadoop/workers</span><br></pre></td></tr></table></figure>
<p>添加内容</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hadoop100</span><br><span class="line">hadoop101</span><br><span class="line">hadoop102</span><br></pre></td></tr></table></figure>
<h2 id="在集群上分发配置文件"><a href="#在集群上分发配置文件" class="headerlink" title="在集群上分发配置文件"></a>在集群上分发配置文件</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">xsync /opt/module/hadoop-3.1.3/etc/hadoop/</span><br></pre></td></tr></table></figure>
<h2 id="启动集群"><a href="#启动集群" class="headerlink" title="启动集群"></a>启动集群</h2><p><strong>如果集群是第一次启动</strong>，需要在 hadoop102 节点格式化 NameNode（注意：格式</p>
<p>化 NameNode，会产生新的集群 id，导致 NameNode 和 DataNode 的集群 id 不一致，集群找</p>
<p>不到已往数据。如果集群在运行过程中报错，需要重新格式化 NameNode 的话，一定要先停 </p>
<p>止 namenode 和 datanode 进程，并且要删除所有机器的 data 和 logs 目录，然后再进行格式</p>
<p>化。）</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hdfs namenode -format</span><br></pre></td></tr></table></figure>
<h2 id="启动-HDFS"><a href="#启动-HDFS" class="headerlink" title="启动 HDFS"></a>启动 HDFS</h2><p>在hadoop100中</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sbin/start-dfs.sh</span><br></pre></td></tr></table></figure>
<p>在==hadoop101==中</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sbin/start-yarn.sh</span><br></pre></td></tr></table></figure>
<p>Web 端查看 HDFS 的 NameNode</p>
<p><a href="http://hadoop100:9870/">http://hadoop100:9870/</a></p>
<p>Web 端查看 YARN 的 ResourceManager</p>
<p><a href="http://hadoop101:8088/">http://hadoop101:8088/</a></p>
<h1 id="启动脚本编写"><a href="#启动脚本编写" class="headerlink" title="启动脚本编写"></a>启动脚本编写</h1><p>Hadoop 集群启停脚本（包含 HDFS，Yarn，Historyserver）：dohadoop.sh</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="keyword">if</span> [ <span class="variable">$#</span> -lt 1 ]; <span class="keyword">then</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;No Args Input...&quot;</span></span><br><span class="line">    <span class="built_in">exit</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"><span class="keyword">case</span> <span class="variable">$1</span> <span class="keyword">in</span></span><br><span class="line"><span class="string">&quot;start&quot;</span>)</span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot; =================== 启动 hadoop 集群 ===================&quot;</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot; --------------- 启动 hdfs ---------------&quot;</span></span><br><span class="line">    ssh hadoop100 <span class="string">&quot;/opt/module/hadoop-3.1.3/sbin/start-dfs.sh&quot;</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot; --------------- 启动 yarn ---------------&quot;</span></span><br><span class="line">    ssh hadoop101 <span class="string">&quot;/opt/module/hadoop-3.1.3/sbin/start-yarn.sh&quot;</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot; --------------- 启动 historyserver ---------------&quot;</span></span><br><span class="line">    ssh hadoop100 <span class="string">&quot;/opt/module/hadoop-3.1.3/bin/mapred --daemon start historyserver&quot;</span></span><br><span class="line">    ;;</span><br><span class="line"><span class="string">&quot;stop&quot;</span>)</span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot; =================== 关闭 hadoop 集群 ===================&quot;</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot; --------------- 关闭 historyserver ---------------&quot;</span></span><br><span class="line">    ssh hadoop100 <span class="string">&quot;/opt/module/hadoop-3.1.3/bin/mapred --daemon stop historyserver&quot;</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot; --------------- 关闭 yarn ---------------&quot;</span></span><br><span class="line">    ssh hadoop101 <span class="string">&quot;/opt/module/hadoop-3.1.3/sbin/stop-yarn.sh&quot;</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot; --------------- 关闭 hdfs ---------------&quot;</span></span><br><span class="line">    ssh hadoop100 <span class="string">&quot;/opt/module/hadoop-3.1.3/sbin/stop-dfs.sh&quot;</span></span><br><span class="line">    ;;</span><br><span class="line">*)</span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;Input Args Error...&quot;</span></span><br><span class="line">    ;;</span><br><span class="line"><span class="keyword">esac</span></span><br></pre></td></tr></table></figure>
<p>查看三台服务器 Java 进程脚本</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="keyword">for</span> host <span class="keyword">in</span> hadoop100 hadoop101 hadoop102</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line"> <span class="built_in">echo</span> =============== <span class="variable">$host</span> ===============</span><br><span class="line"> ssh <span class="variable">$host</span> <span class="string">&quot;source /etc/profile;jps&quot;</span></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>hadoop</category>
      </categories>
  </entry>
</search>
