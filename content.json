{"meta":{"title":"SODA","subtitle":"你可长点心吧！点心？什么点心？","description":"","author":"sudatime","url":"http://blog.sodarain.top","root":"/"},"pages":[{"title":"404","date":"2020-08-10T07:00:30.515Z","updated":"2020-08-10T07:00:30.515Z","comments":false,"path":"/404.html","permalink":"http://blog.sodarain.top/404.html","excerpt":"","text":"404 Not Found 对不起，您所访问的页面不存在或者已删除 点击此处返回首页 我的Github：https://github.com/sudatime/"},{"title":"关于","date":"2020-08-09T12:29:00.000Z","updated":"2020-08-10T03:50:24.462Z","comments":true,"path":"about/index.html","permalink":"http://blog.sodarain.top/about/index.html","excerpt":"","text":"兴趣使然~"},{"title":"分类","date":"2020-08-10T00:43:13.000Z","updated":"2020-08-10T06:01:29.780Z","comments":true,"path":"categories/index.html","permalink":"http://blog.sodarain.top/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2020-08-10T00:43:09.000Z","updated":"2020-08-10T06:01:59.215Z","comments":true,"path":"tags/index.html","permalink":"http://blog.sodarain.top/tags/index.html","excerpt":"","text":""},{"title":"yourdiy","date":"2020-08-09T12:29:08.000Z","updated":"2020-08-09T12:29:08.843Z","comments":true,"path":"yourdiy/index.html","permalink":"http://blog.sodarain.top/yourdiy/index.html","excerpt":"","text":""}],"posts":[{"title":"爬取武生院教务处通知","slug":"爬取教务处通知","date":"2020-08-10T13:37:20.950Z","updated":"2020-08-10T13:55:08.053Z","comments":true,"path":"2020/08/10/posts/wsy-crawler.html/","link":"","permalink":"http://blog.sodarain.top/2020/08/10/posts/wsy-crawler.html/","excerpt":"记录一下之前因为某些特殊原因而要去爬取武生院网站通知的代码，防止后面有别的需要而忘记使用方法。","text":"记录一下之前因为某些特殊原因而要去爬取武生院网站通知的代码，防止后面有别的需要而忘记使用方法。 1.Jsoup介绍jsoup 是一款Java 的HTML解析器，可直接解析某个URL地址、HTML文本内容。它提供了一套非常省力的API，可通过DOM，CSS以及类似于jQuery的操作方法来取出和操作数据。 –来源百度百科 2.环境采用Springboot 2.3.0搭建环境 依赖如下： 1234567891011&lt;!--起步依赖--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!--此为核心包 jsoup爬虫--&gt;&lt;dependency&gt; &lt;groupId&gt;org.jsoup&lt;/groupId&gt; &lt;artifactId&gt;jsoup&lt;/artifactId&gt; &lt;version&gt;1.11.3&lt;/version&gt;&lt;/dependency&gt; 3.核心代码12345678910111213141516171819202122public boolean getNotice(Integer tbodyIndex, Integer trNum) throws Exception &#123; //获取document对象 Document document = Jsoup.connect(URL).get(); //获取第7个tbody的内容 Elements tbody = document.select(&quot;tbody&quot;).eq(tbodyIndex); //System.out.println(tbody.toString()); List&lt;Article&gt; articles = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; trNum; i++) &#123; Elements tr = tbody.select(&quot;tr&quot;).eq(i); Elements td1 = tr.select(&quot;td&quot;).eq(0); Elements td2 = tr.select(&quot;td&quot;).eq(2); String href = URL + td1.select(&quot;a&quot;).attr(&quot;href&quot;); int index = href.indexOf(&quot;id&quot;); //截取id的数字字段 String id = href.substring(index + 3, index + 7); String body = td1.select(&quot;a&quot;).text(); String date = td2.text(); Article article = new Article(Integer.parseInt(id), body, href, DateUtils.parseString2Date(date)); articles.add(article); &#125; return sendMessage(articles);&#125; 3.1 思路1Document document = Jsoup.connect(URL).get(); 这行代码能够访问指定的URL路径来获取返回的静态页面 通过分析得到的html可以得知我们想要的新闻通知区域在第7个tbody中 打印输出的tbody，可以发现数据都存放在tr标签里面，分了三个td小标签 我们只取我们想要的数据： 第一个td里面是文章链接，不带域名的。 第二个td里面是文章后面的gif图片，没啥用 第三个td里面是日期 所以我们可以使用 12Elements td1 = tr.select(&quot;td&quot;).eq(0);Elements td2 = tr.select(&quot;td&quot;).eq(2); 来获取链接和日期 使用Article对象来进行封装。得到文章对象之后，要做什么处理就方便了。 tips：意外收获写完之后想继续爬取其他模块的，意外的发现其他模块结构类似，只是tbody和tr值不同，所以封装成一个方法。 1234567891011121314151617181920//新闻通知boolean news = getNotice(6, 9);//教务管理boolean manage = getNotice(11, 6);//教学研究boolean research = getNotice(13, 6);//学籍管理boolean schoolRoll = getNotice(15, 6);//实践教学boolean practice = getNotice(21, 6);//质量管理boolean quality = getNotice(23, 6);//下载专区boolean download = getNotice(25, 6);//工作例会boolean work = getNotice(29, 6);//考务管理boolean exam = getNotice(31, 6);//学习动态boolean study = getNotice(33, 6);","categories":[{"name":"crawler","slug":"crawler","permalink":"http://blog.sodarain.top/categories/crawler/"}],"tags":[{"name":"crawler","slug":"crawler","permalink":"http://blog.sodarain.top/tags/crawler/"}]},{"title":"Hello World","slug":"hello-world","date":"2020-08-10T06:19:36.545Z","updated":"2020-08-10T13:49:16.469Z","comments":true,"path":"2020/08/10/posts/4a17b156.html/","link":"","permalink":"http://blog.sodarain.top/2020/08/10/posts/4a17b156.html/","excerpt":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub.","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[{"name":"初始化","slug":"初始化","permalink":"http://blog.sodarain.top/categories/%E5%88%9D%E5%A7%8B%E5%8C%96/"}],"tags":[]}],"categories":[{"name":"crawler","slug":"crawler","permalink":"http://blog.sodarain.top/categories/crawler/"},{"name":"初始化","slug":"初始化","permalink":"http://blog.sodarain.top/categories/%E5%88%9D%E5%A7%8B%E5%8C%96/"}],"tags":[{"name":"crawler","slug":"crawler","permalink":"http://blog.sodarain.top/tags/crawler/"}]}